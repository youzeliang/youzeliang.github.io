{"posts":[{"title":"2018年总结","text":"帝都的生活&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;依稀记得在18年初的时候，毅然决定从重庆离职，离开这个舒适区，因为我明白，在这边待越久，差距就会越来越大，等到过完年来帝都搬砖。来到这边才感知和重庆的天壤之别。每天早上13号线挤得不要不要的，但是9点后出门的话人就会少很多。正是因为这边上班晚，所以下班就迟了。加班也是常态。其实正常的工作日，加上通勤的时间，自己的时间久真的不太多。周末，和朋友们去过故宫，是挺大挺庄严的。但其实这些建筑之类的，去过一次也就够了。相比于去过的圆明园，更加喜欢这种自然风的恬静。北方是山也不算高，从故宫后面的景山看整个故宫挺震撼的。以及珍藏奇珍异宝的国家博物馆，逛了足足半天。只能说中外文物意义非凡，而且看着古代匠人的艺术感挺强的，因为不懂技术的我其实很想多认识一些“艺术”朋友。当深夜行走在奥体公园的时候，雨滴在五彩斑斓的灯光勾勒下仿佛也有一种彩虹的错觉。团建的时候开过的卡丁卡，到现在也还记得速度下的刺激。盛夏时节去十渡也有一种暴晒的感觉，当然对比重庆来说还是要好很多。在帝都工作是很忙，忙里偷闲也不缺乏去看看其他不一样的世界。由于一天都是坐办公室内，再加上每天良好的伙食不知不觉中就长胖了，意识到每天不到3000的步数会导致我的身体体能下降。本着在学校练出的毅力办了健身卡，3个月就再也没去过了。很大一部分原因是公司项目真的很忙吧。4月的时候竟然还在北京见到了雪，虽然不足为奇，但感受到南北方的气候的初步差异。不久后就到了5月，答辩的日子。也没有留恋学校的日子， 所以呆了10天就走了。在这期间很感谢我的导师zy。毕业不是再见，是更好的遇见。北京的空气是真的干，动不动就是静电电你。还有就是抗寒能力不错的我在刺骨的冬天也真的觉得冷哇，不敢拿身体开玩笑。 帝都的工作&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从到这边来就感受到了和重庆的技术有这天壤之别，技术层出不穷，但就国内而言前沿的技术还是先在北上广这些城市试用。互联网的人来人往，流动性大。但其实对于加班这点来看，确实会因为菜的原因加班，再就是就算不加班，也不喜欢早走，因为还可以在公司继续学习，可能氛围比在家好些。因为各种原因，在10月的时候换到了现在这家公司。说实话挺感谢我对面的同事zjf,虽然在技术成长的方面靠自己，但是在其他事情上，比如业务还是很耐心的给我讲，挺好的一个人。以及旁边同事就比我大一届，如果我和他是同届也被他甩了几条街了吧。当然要学习的还有很多很多，在工作中也有很多时候效率低下，开发相关知识肯定是基础，然后也一个人的思维能力可能就真的是发展的天花板。这点还要不断加强练习。很快就在这边呆了一年了，还是先干好手头上的事情。来这边你会知道，优秀的人比你还努力很多倍。不过好在现在终于算稳定了吧，从实习开始主语言就从c#换成后面的Java和js并行。然后换到了现在的golang。 其他原本搭建这个博客是为了更好地将自己的吸收转为输出，但写着写着回过头来看就觉得是太简单的，没啥必要记录。以及自己掌握的东西还不够，怕误导其他人。所以就先决定再沉淀一段时间。回头看看，今年好像就做了这些数字相关的吧。 参加3场技术沙龙 在帝都的这一年，参加了3场感兴趣的技术沙龙，但也有其他原因错失了我想去的。参加这些技术分享会的动机很单纯，就是去学习其他前沿技术。有以下几点好处 认识一些周末不打游戏，不陪妹子的人。对技术充满热情的人。 不同公司会有一定得局限性，比如上家公司我做的那个项目es索引都才几个，其他公大公司都是搜索一个团队，对于海量的数据，如何如何处理。也正是我去了es社区的分享后很想做es方面的工作。但是现在这个机器人团队也挺好的。 因为目前很多知识都还是属于懵懂阶段，对眼界的开阔的一定帮助。 认识一些大牛，其实并不是为了大牛能够帮你解决疑难问题，有的时候你加上别人，看看别人的朋友圈，说不定也能掌握业内的一些动向。 读完14本书 只能说通勤的时间很充裕 看完28部电影 当然几乎都是电脑上看的。相比去年的110部很满足了。 明年争取减少到10部","link":"/2018/12/31/2018%E6%80%BB%E7%BB%93/"},{"title":"2019年总结","text":"今年的最后一段时间是在罗振宇的跨年演讲中度过的，当然不是在现场。 2019是一个有意思的一年，如在北京待的越久，似乎就越不愿意离开了。在这里认识了更多厉害的人，就会看到自己的渺小。自己的认知也在逐渐走向远方，看到更远的视野。在这一年里，美国不断打压中国，我所在的公司也在美国的”名单”里，以及看到各大公司裁员，这似乎就有一种焦虑，被时代驱逐前行的我们，是容不得“舒适”的环境。但你的性格，眼界格局，认知等或许就已经决定了在这个格局变化里，下一个地方会何去何从。有庆幸，自己身处在这行业里，不说那些伟大的事情(普通人完全是扯淡)，但能凭借自己的能力，也能自立自足。但又有些不甘，不甘的是野心和努力不成正比吧。或许还是对自己不够狠。不甘中又有一丝惧怕，似乎看到了所谓的35岁后的自己。或许努力生活的人，都自在执着属性吧。 社会是多元化的，一朵朵海浪中荡漾着不同光芒的思想 感谢 从2017年末yqj就开始鼓励我，今年也是不例外。总是交流了一些超越我现在年龄阶段认知的一些思想，她自己也工作了4-5年后去港大上学了。优秀的人是真的没有停止下来。是最最感激的人之一了 然后就是qmj这个本该3月就该见一面认识的，话说都认识了好久了，一个很乐观，阳光的一个人，交流起来也挺有意思的。以积极向上，玩耍的心态工作(或许没有)生活，同样很感谢 zs这个每天都是打了鸡血的人，太拼了同时也太强了。说实话也影响了我很多，他的成长还是看在眼里的，就是有时候做事有点怪 还有其他一些人 然后回顾下回想一下2019的flag 早睡早起 上半年大概还能做到，然后到下半年的时候就逐渐又回到了之前的状态了，主要是真的早起动力不足哇。 阅读20本+ 书籍 回顾了下，2019年看完了34本书，其中数学(主要是科普类的了，因为再看一些类似于刷题之类的没啥意义了)书籍占了近40%吧，有历史(对，开始看自己以前不喜欢的历史了)，经济，当然还有一些技术类的书籍。总之来看，普遍是一些实用类的，反正是不会看文学类的书籍 参加不少于5场有价值的线下技术会议 大概4场吧，虽然有自己想深入去了解的方向，但是自制力是真的不够，时间眨眼就过去了。至少也算是开拓了眼界，认识到了一些厉害的人。这大概也是鞭挞前进的动力吧 看电影少于20部 好像不知不觉看了60部,这过分了 输出20篇有质量的博客 不到一半吧，还是需要继续沉淀 脱单 这真的是太难了,所以这是要继续作为2020年的目标么 投入一定时间在学习英语上 至少看一些技术文档优先于官网的，以及中途尝试翻译了一些英语技术文章，还有一篇得到了国外的一个技术人员的认可。大部分的时间通过英语文章来了解国际新闻，这当然国内的微博热搜也是一种途径 至少一次一个人的旅行 真没想到这也没完成，那就2020年换公司了来吧 一场音乐会 倒不是有这细胞，只是作为程序员感觉要多接触其他不同方面的东西，这让我想起了最近看的一个知乎问题，作为程序员你失去了什么，专注在自己喜欢的领域里是值得肯定的，但是圈子外面的世界也会是很精彩的 开始了解经济,股票 今年的收益率还是行了吧，投入的钱不多 做饭，少点外卖 这，上半年还在坚持做，但是到了10月份，就几乎没有了。一是隔壁租的其他人用厨房的频率高了，又不想你等我，我等你的这种 跑完60个5km，5个10km 大概在9月份吧，就完成了。本来以为今年有机会去参加半马的(不过这不在flag之内，看明年锻炼的情况)，但是看着锻炼的最长距离感觉还不行。而且主要目的又不是非要去参加半马。锻炼意志力了就行，身体锻炼是其次 2019过得并没有像自己想象中的样子，尽量在2020年重新拾起一些东西吧，勇敢大步向前走，去自己想去的公司。2020年的flag就不先公开了，希望在技术上像贝聿铭先生说的那样，”我一直沉浸在如何解决我自己的问题之中”,你成长的速度必须足够快，才能抓住一些你要抓住的东西以及未来想抓住的东西 未来可期","link":"/2020/01/01/2019%E5%B9%B4%E6%80%BB%E7%BB%93/"},{"title":"2020年总结","text":"终于、拖到了现在来整理年终总结（其实早就写得差不多）了。原计划是在年前换完工作然后就写这篇总结的，但是又有一些小插曲，所以也不得不将选择的时机放在年后了。大概也有前年出差的那段时间令我不是很愉快，具体的事情也就没有必要在这里写了。成年人的世界里没有容易的，需要做的事情就是要不断让自己成长。有一天能够有更多的主动选择权，而不是被动的选择。 读书本来立的flag，阅读量是要有50本的。但实际读过的书比去年都还少了，不管是技术类的还是非技术类的书籍。这一点有一小部分原因是加班居多 ？但是终于把2019年给2020年立的flag坚持读英语&amp;&amp;背英语单词，完成度90%差不多吧，还是有慢慢在坚持（但是2021开端又停下来了，摸狗头）原本计划的是练一练口语，出国玩的时候也会方便一些（不如找一个英语还可以的女朋友，是真的对英语好的人莫名有好感，做梦？）。以及在看一些技术文档的时候，可以更好的看原汁原味的信息。 关于健康从最开始的疫情笼罩下，开始自己做饭。也解锁了不少菜谱。详情可以点击这里 香糯软滑的香菇鸡肉粥是真的超级香。比起2019年在吃(点外卖)这一块儿的账单，确实是少了不少，还是坚信自己动手丰衣足食。 健康不单单是吃这一块儿。良好的身体素质也会显得额外重要。不然怎么修福报(996)，2020年期间，犹豫上半年是基本上没咋锻炼(老生常谈的话题了，疫情)，在5月起就开始了户外锻炼。还是以跑步为主，隔几个周去奥森。以及平时晚上的时候在公司的健身区那一块儿锻炼。慢慢，5km也终于能够破20min了，10km也能破44min。我也不知道这水平是啥样，反正没去对比。还是想的是有一天能够参加半马就可以了，成绩也不至于太难看就行了。全马我就不了，这玩意没必要追求这么高。为忙碌的工作之余加强身体的锻炼就行了。 关于家人原本是计划在2020年的4月或者是10月的样子带家人来北京玩一趟的，因为趁我还在北京，以及我对朋友说过，老舍先生的《四世同堂》里说过“春天要住杭州 ，夏天住济南 ，秋天住北平”，然后想到今年不太可能，我就计划在国庆的时候回家看一看家人，以及把侄女和我妈带到成都去逛了一圈。大概是吧，工作了后发现时间大部分都不太算属于自己的，特别是工作的属性带有“一线城市”&amp;&amp;“互联网”这两个属性。尽管还有点小，很多东西仅局限于表面。看到的一些东西可能就是花花绿绿的。并不知道代表的是啥。但是我还是对我侄女保持“我知道的东西我会带她们玩的过程中科普给她们”，一方面是有个简单的初步认识，另外一个方面万一也能激起其兴趣呢。 技能陆陆续续阅读了部分源代码，大部分都是go语言相关的，当然还有一部分框架相关的。已经有提过pr（不过还是规范上的问题），希望在这一块儿，能在2021继续进行下去。主要是觉得一毕业后的简历，都要抹平大学竞赛所获得过的奖。所以自从成为了打工人后的简历尤其的平常（说好的为开源做贡献和打比赛，我承认太难了，而我又太菜了）而且源代码又有太多值得学习的地方 开源精神良好 弥补在技能上的不足 作为一个coder的兴趣 希望提升自身的 reputation（任重而道远） 不过这一块儿的水还是很深，需要花的时间太多，而又没有在自己blog上好好写下一些技术文章，主要也是觉得目前所掌握的不够深度，2021慢慢写起来吧。 选择身边的人陆续有去发展迅猛的公司，也有人选择离开北京去成都生活。勇于去改变的生活是极好的。前不久和朋友去北京天文馆(这是2021，主要是觉得比较符合这里提到的，所以额外加了一点)。看到宇宙之浩大“无论是否相信平行宇宙的存在，我们能看到的始终只有一条时间线，当我们选择了 B后，我们就永远不会知道 A 的结果是什么。同时，比起承认自身能力的不足，我们更倾向于把失利归咎于关键节点上错误的选择，那么客观的 review 选择就更是难上加难，只能进行简单的分析来做一些预测。” 关于工作部门领导，以及同事。这些实在是换的勤，人员流失大。先不管这些，主要也是对物流行业确实提不上兴趣，从内心来看还是倾向于去做c端的东西。以及预料到了会在2020年下半年加班比较多，倒也不是排斥加班，主要也是要有成长吧。很多时候我周末如果不去约同学吃饭，以及不出去玩。大概有一半的时间我会选择去公司学习，一方面是因为公司的气氛好一些。到了下半年就果然无止境的加班了，基本上从6月起就是单休的样子了，这也为我积攒了部分假期。还是期望后期去一个真的想去的公司和方向吧。 失败与展望今年感觉过得挺失败的，部分焦虑与部分乐观依然并存。这里的失败，指的是一些行动力的低下。比如每年结束&amp;&amp;第二年开始的时候都会展望比较好的flag，唯一可能就是保持一年2次回家看家人和经常关注侄女的成长。眼看毕业3年就快过去了，但是能拿得手的东西其实没啥。倒是有在年初的时候计划未来要去哪一个城市并且位置付出了行动。这篇文章中不会列出详细计划，因为觉得主要要是要加强自我行动力。关于2021，希望可以在修福报的同时还可以解锁一些其他的事情，生活并不是只有工作。","link":"/2021/01/01/2020%E5%B9%B4%E6%80%BB%E7%BB%93/"},{"title":"go panic探索","text":"panic 发生之后，如果 Go 不做任何特殊处理，默认行为是打印堆栈，退出程序。 panic 到底是什么？ panic( ) 函数内部会产生一个关键的数据结构体 _panic ，并且挂接到 goroutine 之上； panic( ) 函数内部会执行 _defer 函数链条，并针对 _panic 的状态进行对应的处理； 什么叫做 panic( ) 的对应的处理？ 循环执行 goroutine 上面的 _defer 函数链，如果执行完了都还没有恢复 _panic 的状态，那就没得办法了，退出进程，打印堆栈。如果在 goroutine 的 _defer 链上，有个朋友 recover 了一下，把这个 _panic 标记成恢复，那事情就到此为止，就从这个 _defer 函数执行后续正常代码即可，走 deferreturn 的逻辑。 recover 函数 recover 对应了 runtime/panic.go 中的 gorecover 函数实现。 12345678910func gorecover(argp uintptr) interface{} { // 只处理 gp._panic 链表最新的这个 _panic； gp := getg() p := gp._panic if p != nil &amp;&amp; !p.recovered &amp;&amp; argp == uintptr(p.argp) { p.recovered = true return p.arg } return nil} 这个函数可太简单了： 取出当前 goroutine 结构体； 取出当前 goroutine 的 _panic 链表最新的一个 _panic，如果是非 nil 值，则进行处理； 该 _panic 结构体的 recovered 赋值 true，程序返回； 这就是 recover 函数的全部内容，只给 _panic.recovered 赋值而已，不涉及代码的神奇跳转。而 _panic.recovered 的赋值是在 panic 函数逻辑中发挥作用。 panic函数 panic 的实现在一个叫做 gopanic 的函数，位于 runtime/panic.go 文件。panic 机制最重要最重要的就是 gopanic 函数了，所有的 panic 细节尽在此。为什么 panic 会显得晦涩，主要有两个点： 嵌套 panic 的时候，gopanic 会有递归执行的场景； 程序指令跳转并不是常规的函数压栈，弹栈，在 recovery 的时候，是直接修改指令寄存器的结构体，从而直接越过了 gopanic 后面的逻辑，甚至是多层 gopanic 递归的逻辑； 一切秘密都在下面这个函数： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// runtime/panic.gofunc gopanic(e interface{}) { // 在栈上分配一个 _panic 结构体 var p _panic // 把当前最新的 _panic 挂到链表最前面 p.link = gp._panic gp._panic = (*_panic)(noescape(unsafe.Pointer(&amp;p))) for { // 取出当前最近的 defer 函数； d := gp._defer if d == nil { // 如果没有 defer ，那就没有 recover 的时机，只能跳到循环外，退出进程了； break } // 进到这个逻辑，那说明了之前是有 panic 了，现在又有 panic 发生，这里一定处于递归之中； if d.started { if d._panic != nil { d._panic.aborted = true } // 把这个 defer 从链表中摘掉； gp._defer = d.link freedefer(d) continue } // 标记 _defer 为 started = true （panic 递归的时候有用） d.started = true // 记录当前 _defer 对应的 panic d._panic = (*_panic)(noescape(unsafe.Pointer(&amp;p))) // 执行 defer 函数 reflectcall(nil, unsafe.Pointer(d.fn), deferArgs(d), uint32(d.siz), uint32(d.siz)) // defer 执行完成，把这个 defer 从链表里摘掉； gp._defer = d.link // 取出 pc，sp 寄存器的值； pc := d.pc sp := unsafe.Pointer(d.sp) // 如果 _panic 被设置成恢复，那么到此为止； if p.recovered { // 摘掉当前的 _panic gp._panic = p.link // 如果前面还有 panic，并且是标记了 aborted 的，那么也摘掉； for gp._panic != nil &amp;&amp; gp._panic.aborted { gp._panic = gp._panic.link } // panic 的流程到此为止，恢复到业务函数堆栈上执行代码； gp.sigcode0 = uintptr(sp) gp.sigcode1 = pc // 注意：恢复的时候 panic 函数将从此处跳出，本 gopanic 调用结束，后面的代码永远都不会执行。 mcall(recovery) throw(&quot;recovery failed&quot;) // mcall should not return } } // 打印错误信息和堆栈，并且退出进程； preprintpanics(gp._panic) fatalpanic(gp._panic) // should not return *(*int)(nil) = 0 // not reached} 上面逻辑可以拆分为循环内和循环外两部分去理解： 循环内：程序执行 defer，是否恢复正常的指令执行，一切都在循环内决定； 循环外：一旦走到循环外，说明 _panic 没人处理，程序即将退出； for 循环内 循环内的事情拆解成： 遍历 goroutine 的 defer 链表，获取到一个 _defer 延迟函数； 获取到 _defer 延迟函数，设置标识 d.started，绑定当前 d._panic（用以在递归的时候判断）； 执行 _defer 延迟函数； 摘掉执行完的 _defer 函数； 判断 _panic.recovered 是否设置为 true，进行相应操作； 如果是 true 那么重置 pc，sp 寄存器（一般从 deferreturn 指令前开始执行），goroutine 投递到调度队列，等待执行； 重复以上步骤； 问题一：为什么 recover 一定要放在 defer 里面才生效？ 因为，这是唯一的修改 _panic.recovered 字段的时机 ！ 为什么 recover 已经放在 defer 里面，但是进程还是没有恢复？ 划重点：在 gopanic 里，只遍历执行当前 goroutine 上的 _defer 函数链条。所以，如果挂在其他 goroutine 的 defer 函数做了 recover ，那么没有丝毫用途。 例 12345678func main() { // g1 go func() { // g2 defer func() { recover() }() }() panic(&quot;test&quot;)} 因为，panic 和 recover 在两个不同的 goroutine，_panic 是挂在 g1 上的，recover 是在 g2 的 _defer 链条里。gopanic 遍历的是 g1 的 _defer 函数链表，跟 g2 八杆子打不着，g2 的 recover 自然拿不到 g1 的 _panic 结构，自然也不能设置 recovered 为 true ，所以程序还是崩了。 recover 函数在 gopanic 函数中，在循环执行 defer 函数的时候，如果发现 _panic.recovered 字段被设置成 true 的时候，调用 mcall(recovery) 来执行所谓的恢复。 看一眼 recovery 函数的实现，这个函数极其简单，就是恢复 pc，sp 寄存器，重新把 Goroutine 投递到调度队列中。 1234567891011// runtime/panic.gofunc recovery(gp *g) { // 取出栈寄存器和程序计数器的值 sp := gp.sigcode0 pc := gp.sigcode1 // 重置 goroutine 的 pc，sp 寄存器； gp.sched.sp = sp gp.sched.pc = pc // 重新投入调度队列 gogo(&amp;gp.sched)} 总结 panic() 会退出进程，是因为调用了 exit 的系统调用； recover() 所在的 defer 函数必须和 panic 都是挂在同一个goroutine 上，不能跨协程，因为 gopanic 只会执行当前 goroutine 的延迟函数； 参考深度细节 | Go 的 panic 的秘密都在这源码剖析panic与recover","link":"/2021/09/20/%20go%20panic%E6%8E%A2%E7%B4%A2/"},{"title":"Golang Context包 详解","text":"context 主要用来在 goroutine 之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v 等。 context 用来解决 goroutine 之间退出通知、元数据传递的功能。 控制并发有两种经典的方式，一种是WaitGroup，另外一种就是Context Value函数并没有任何保证，编译器不会检查传进来的参数是否是合理。 Context 接口Context接口定义 123456789type Context interface { Deadline() (deadline time.Time, ok bool) Done() &lt;-chan struct{} Err() error Value(key any) any} Context 核心方法Context 接口中有四个核心方法：Deadline()、Done()、Err()、Value()。 Deadl() Deadline() (deadline time.Time, ok bool) 方法返回 Context 的截止时间，表示在这个时间点之后，Context 会被自动取消。如果 Context 没有设置截止时间，该方法返回一个零值 time.Time 和一个布尔值 false。 123456deadline, ok := ctx.Deadline()if ok { // Context 有截止时间} else { // Context 没有截止时间} Done() Done() 方法返回一个只读通道，当 Context 被取消时，该通道会被关闭。可以通过监听这个通道来检测 Context 是否被取消。如果 Context 永不取消，则返回 nil。 123456select {case &lt;-ctx.Done(): // Context 已取消default: // Context 尚未取消} Err() Err() 方法返回一个 error 值，表示 Context 被取消时产生的错误。如果 Context 尚未取消，该方法返回 nil。 123if err := ctx.Err(); err != nil { // Context 已取消，处理错误} Value() Value(key any) any 方法返回与 Context 关联的键值对，一般用于在 Goroutine 之间传递请求范围内的信息。如果没有关联的值，则返回 nil。 1234value := ctx.Value(key)if value != nil { // 存在关联的值} 添加值 context.WithValue() 1ctx := context.WithValue(parentCtx, &quot;username&quot;, &quot;Rolle&quot;) 取消Context context.WithCancel() context.WithCancel(parent Context) (ctx Context, cancel CancelFunc) 函数接收一个父 Context，返回一个新的子 Context 和一个取消函数，当取消函数被调用时，子 Context 会被取消，同时会向子 Context 关联的 Done() 通道发送取消信号，届时其衍生的子孙 Context 都会被取消。这个函数适用于手动取消操作的场景。 12ctx, cancelFunc := context.WithCancel(parentCtx) defer cancelFunc() 取消原因 context.WithCancelCause() 与 context.Cause() context.WithCancelCause(parent Context) (ctx Context, cancel CancelCauseFunc) 函数是 Go 1.20 版本才新增的，其功能类似于 context.WithCancel()，但是它可以设置额外的取消原因，也就是 error 信息，返回的 cancel 函数被调用时，需传入一个 error 参数。 12ctx, cancelFunc := context.WithCancelCause(parentCtx)defer cancelFunc(errors.New(&quot;原因&quot;)) context.Cause(c Context) error 函数用于返回取消 Context 的原因，即错误值 error。如果是通过 context.WithCancelCause() 函数返回的取消函数 cancelFunc(myErr) 进行的取消操作，我们可以获取到 myErr 的值。否则，我们将得到与 c.Err() 相同的返回值。如果 Context 尚未被取消，将返回 nil。 1err := context.Cause(ctx) context.WithDeadline() context.WithDeadline(parent Context, d time.Time) (Context, CancelFunc) 函数接收一个父 Context 和一个截止时间作为参数，返回一个新的子 Context。当截止时间到达时，子 Context 其衍生的子孙 Context 会被自动取消。这个函数适用于需要在特定时间点取消操作的场景。 123deadline := time.Now().Add(time.Second * 2)ctx, cancelFunc := context.WithTimeout(parentCtx, deadline)defer cancelFunc() context.WithTimeout() context.WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) 函数和 context.WithDeadline() 函数的功能是一样的，其底层会调用 WithDeadline() 函数，只不过其第二个参数接收的是一个超时时间，而不是截止时间。这个函数适用于需要在一段时间后取消操作的场景。 12ctx, cancelFunc := context.WithTimeout(parentCtx, time.Second * 2)defer cancelFunc() Context 的使用场景传递共享数据编写中间件函数，用于向 HTTP 处理链中添加处理请求 ID 的功能。 123456789101112131415161718192021type key intconst ( requestIDKey key = iota)func WithRequestId(next http.Handler) http.Handler { return http.HandlerFunc(func(rw http.ResponseWriter, req *http.Request) { // 从请求中提取请求ID和用户信息 requestID := req.Header.Get(&quot;X-Request-ID&quot;) // 创建子 context，并添加一个请求 Id 的信息 ctx := context.WithValue(req.Context(), requestIDKey, requestID) // 创建一个新的请求，设置新 ctx req = req.WithContext(ctx) // 将带有请求 ID 的上下文传递给下一个处理器 next.ServeHTTP(rw, req) })} 传递取消信号、结束任务启动一个协程，接受到取消信号就停止工作 123456789101112131415161718192021222324252627282930package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;time&quot;)func main() { ctx, cancelFunc := context.WithCancel(context.Background()) go Working(ctx) time.Sleep(3 * time.Second) cancelFunc() // 等待一段时间，以确保工作协程接收到取消信号并退出 time.Sleep(1 * time.Second)}func Working(ctx context.Context) { for { select { case &lt;-ctx.Done(): fmt.Println(&quot;done...&quot;) return default: fmt.Println(&quot;ing...&quot;) } }} 在上面的示例中，创建了一个 Working 函数，它会不断执行工作任务。使用 context.WithCancel 创建了一个上下文 ctx 和一个取消函数 cancelFunc。然后，启动了一个工作协程，并将上下文传递给它。在主函数中，需要等待一段时间（3 秒）模拟业务逻辑的执行。然后，调用取消函数 cancelFunc，通知工作协程停止工作。工作协程在每次循环中都会检查上下文的状态，一旦接收到取消信号，就会退出循环。最后，等待一段时间（1 秒），以确保工作协程接收到取消信号并退出。 超时控制模拟耗时操作，超时控制 123456789101112131415161718192021222324252627package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;time&quot;)func main() { // 使用 WithTimeout 创建一个带有超时的上下文对象 ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second) defer cancel() // 在另一个 goroutine 中执行耗时操作 go func() { // 模拟一个耗时的操作，例如数据库查询 time.Sleep(5 * time.Second) cancel() }() select { case &lt;-ctx.Done(): fmt.Println(&quot;操作已超时&quot;) case &lt;-time.After(10 * time.Second): fmt.Println(&quot;操作完成&quot;) }} 执行结果 1操作已超时 在上面的例子中，首先使用 context.WithTimeout() 创建了一个带有 3 秒超时的上下文对象 ctx, cancel := context.WithTimeout(ctx, 3*time.Second)。接下来，在一个新的 goroutine 中执行一个模拟的耗时操作，例如等待 5 秒钟。当耗时操作完成后，调用 cancel() 方法来取消超时上下文。最后，在主 goroutine 中使用 select 语句等待超时上下文的完成信号。如果在 3 秒内耗时操作完成，那么会输出 “操作完成”。如果超过了 3 秒仍未完成，超时上下文的 Done() 通道会被关闭，输出 “操作已超时”。 同时启动多个 goroutine 进行任务处理时，可以使用 Context 来控制这些 goroutine 的执行。在每个 goroutine 中，都可以检测 Context 对象是否被取消，如果是，则退出 goroutine 的执行，否则继续执行。 12345678910111213141516171819202122232425262728293031package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;sync&quot;)func worker(ctx context.Context, wg *sync.WaitGroup) { defer wg.Done() for { select { default: fmt.Println(&quot;work&quot;) case &lt;-ctx.Done(): return } }}func main() { parent := context.Background() ctx, cancel := context.WithCancel(parent) var wg sync.WaitGroup for i := 0; i &lt; 3; i++ { wg.Add(1) go worker(ctx, &amp;wg) } cancel() wg.Wait()} 什么是WaitGroup它是一种控制并发的方式，它的这种方式是控制多个goroutine同时完成。 12345678910111213141516func main() { var wg sync.WaitGroup wg.Add(2) go func() { time.Sleep(2*time.Second) fmt.Println(&quot;first&quot;) wg.Done() }() go func() { time.Sleep(2*time.Second) fmt.Println(&quot;second&quot;) wg.Done() }() wg.Wait() fmt.Println(&quot;all done&quot;)} 一定要例子中的2个goroutine同时做完，才算是完成 可能会有这么一种场景：需要我们主动的通知某一个goroutine结束。比如开启一个后台goroutine一直做事情，比如监控，定时任务等现在不需要了，就需要通知这个goroutine结束 1234567891011121314151617181920212223func main() { stop := make(chan bool) go func() { for { select { case &lt;-stop: fmt.Println(&quot;break&quot;) return default: fmt.Println(&quot;watch ing&quot;) time.Sleep(1 * time.Second) } } }() time.Sleep(5 * time.Second) fmt.Println(&quot;stop&quot;) stop &lt;- true fmt.Println(5 * time.Second)} 定义一个stop的chan，通知他结束后台goroutine。实现也非常简单，在后台goroutine中，使用select判断stop是否可以接收到值，如果可以接收到，就表示可以退出停止了；如果没有接收到，就会执行default里的监控逻辑，继续监控，只到收到stop的通知。有了以上的逻辑，就可以在其他goroutine种，给stop chan发送值了，例子中是在main goroutine中发送的，控制让这个监控的goroutine结束。 如果有一层层的无穷尽的goroutine，不太好控制 1234567891011121314151617181920func main() { ctx, cancel := context.WithCancel(context.Background()) go func(ctx context.Context) { for { select { case &lt;-ctx.Done(): fmt.Println(&quot;stop,break...&quot;) return default: fmt.Println(&quot;goroutine watching...&quot;) time.Sleep(2 * time.Second) } } }(ctx) time.Sleep(10 * time.Second) fmt.Println(&quot;all done&quot;) cancel() // 为了检测监控过是否停止，如果没有监控输出，就表示停止了 time.Sleep(5 * time.Second)} 重写，就是把原来的chan stop 换成Context，使用Context跟踪goroutine，以便进行控制，比如结束等。context.Background() 返回一个空的Context，这个空的Context一般用于整个Context树的根节点。然后使用context.WithCancel(parent)函数，创建一个可取消的子Context，然后当作参数传给goroutine使用，这样就可以使用这个子Context跟踪这个goroutine。在goroutine中，使用select调用&lt;-ctx.Done()判断是否要结束，如果接受到值的话，就可以返回结束goroutine了；如果接收不到，就会继续进行监控。那么是如何发送结束指令的呢？这就是示例中的cancel函数啦，它是我们调用context.WithCancel(parent)函数生成子Context的时候返回的，第二个返回值就是这个取消函数，它是CancelFunc类型的。我们调用它就可以发出取消指令，然后我们的监控goroutine就会收到信号，就会返回结束。 Context控制多个goroutine1234567891011121314151617181920212223func main() { ctx, cancel := context.WithCancel(context.Background()) go watch(ctx,&quot;【监控1】&quot;) go watch(ctx,&quot;【监控2】&quot;) go watch(ctx,&quot;【监控3】&quot;) time.Sleep(10 * time.Second) fmt.Println(&quot;可以了，通知监控停止&quot;) cancel() // 为了检测监控过是否停止，如果没有监控输出，就表示停止了 time.Sleep(5 * time.Second)}func watch(ctx context.Context, name string) { for { select { case &lt;-ctx.Done(): fmt.Println(name,&quot;监控退出，停止了...&quot;) return default: fmt.Println(name,&quot;goroutine监控中...&quot;) time.Sleep(2 * time.Second) } }} 启动了3个监控goroutine进行不断的监控，每一个都使用了Context进行跟踪，当使用cancel函数通知取消时，这3个goroutine都会被结束。这就是Context的控制能力，它就像一个控制器一样，按下开关后，所有基于这个Context或者衍生的子Context都会收到通知，这时就可以进行清理操作了，最终释放goroutine，这就优雅的解决了goroutine启动后不可控的问题。 如果Context取消的时候，我们就可以得到一个关闭的chan，关闭的chan是可以读取的，所以只要可以读取的时候，就意味着收到Context取消的信号了，以下是这个方法的经典用法。 12345678910111213func Stream(ctx context.Context, out chan&lt;- Value) error { for { v, err := DoSomething(ctx) if err != nil { return err } select { case &lt;-ctx.Done(): return ctx.Err() case out &lt;- v: } } } WithValue传递元数据1234567891011121314151617181920212223242526var key string=&quot;name&quot;func main() { ctx, cancel := context.WithCancel(context.Background()) // 附加值 valueCtx:=context.WithValue(ctx,key,&quot;【监控1】&quot;) go watch(valueCtx) time.Sleep(10 * time.Second) fmt.Println(&quot;可以了，通知监控停止&quot;) cancel() // 为了检测监控过是否停止，如果没有监控输出，就表示停止了 time.Sleep(5 * time.Second)}func watch(ctx context.Context) { for { select { case &lt;-ctx.Done(): // 取出值 fmt.Println(ctx.Value(key),&quot;监控退出，停止了...&quot;) return default: // 取出值 fmt.Println(ctx.Value(key),&quot;goroutine监控中...&quot;) time.Sleep(2 * time.Second) } }} 通过传递参数的方式，把name的值传递给监控函数。在这个例子里，我们实现一样的效果，但是通过的是Context的Value的方式。可以使用context.WithValue方法附加一对K-V的键值对，这里Key必须是等价性的，也就是具有可比性；Value值要是线程安全的。这样我们就生成了一个新的Context，这个新的Context带有这个键值对，在使用的时候，可以通过Value方法读取ctx.Value(key)。记住，使用WithValue传值，一般是必须的值，不要什么值都传递。 1234567891011121314151617181920212223package mainimport ( &quot;context&quot; &quot;fmt&quot;)func main() { ctx := context.Background() process(ctx) ctx = context.WithValue(ctx, &quot;traceId&quot;, &quot;rolle&quot;) process(ctx)}func process(ctx context.Context) { traceId, ok := ctx.Value(&quot;traceId&quot;).(string) if ok { fmt.Printf(&quot;process over. trace_id=%s\\n&quot;, traceId) } else { fmt.Printf(&quot;process over. no trace_id\\n&quot;) }} 运行结果 12process over. no trace_idprocess over. trace_id=rolle Context 使用原则 不要把Context放在结构体中，要以参数的方式传递 以Context作为参数的函数方法，应该把Context作为第一个参数，放在第一位。 给一个函数方法传递Context的时候，不要传递nil，如果不知道传递什么，就使用context.TODO Context的Value相关方法应该传递必须的数据，不要什么数据都使用这个传递 Context是线程安全的，可以放心的在多个goroutine中传递 超时控制 通过context的WithTimeout设置一个有效时间为800毫秒的context。 该context会在耗尽800毫秒后或者方法执行完成后结束，结束的时候会向通道ctx.Done发送信号。 有人可能要问，你这里已经设置了context的有效时间，为什么还要加上这个time.After呢？ 这是因为该方法内的context是自己申明的，可以手动设置对应的超时时间，但是在大多数场景，这里的ctx是从上游一直传递过来的，对于上游传递过来的context还剩多少时间，我们是不知道的，所以这时候通过time.After设置一个自己预期的超时时间就很有必要了。注意，这里要记得调用cancel()，不然即使提前执行完了，还要傻傻等到800毫秒后context才会被释放。总结 上面的超时控制是搭配使用了ctx.Done和time.After。Done通道负责监听context啥时候完事，如果在time.After设置的超时时间到了，你还没完事，那我就不等了，执行超时后的逻辑代码。 12345678910111213141516func AsyncCall() { ctx, cancel := context.WithTimeout(context.Background(), time.Duration(time.Millisecond*800)) defer cancel() go func(ctx context.Context) { // 发送HTTP请求 }() select { case &lt;-ctx.Done(): fmt.Println(&quot;call successfully!!!&quot;) return case &lt;-time.After(time.Duration(time.Millisecond * 900)): fmt.Println(&quot;timeout!!!&quot;) return }} 使用通道123456789101112131415161718func AsyncCall() { ctx := context.Background() done := make(chan struct{}, 1) go func(ctx context.Context) { // 发送HTTP请求 done &lt;- struct{}{} }() select { case &lt;-done: fmt.Println(&quot;call successfully!!!&quot;) return case &lt;-time.After(time.Duration(800 * time.Millisecond)): fmt.Println(&quot;timeout!!!&quot;) return }} 这里主要利用通道可以在协程之间通信的特点，当调用成功后，向done通道发送信号。 监听Done信号，如果在time.After超时时间之前接收到，则正常返回，否则走向time.After的超时逻辑，执行超时逻辑代码。 这里使用的是通道和time.After组合，也可以使用通道和time.NewTimer组合。 子父context1234567891011121314151617181920212223242526package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;time&quot;)func main() { ctx := context.Background() before := time.Now() preCtx, _ := context.WithTimeout(ctx, 100*time.Millisecond) go func() { childCtx, _ := context.WithTimeout(preCtx, 300*time.Millisecond) select { case &lt;-childCtx.Done(): after := time.Now() fmt.Println(&quot;child during:&quot;, after.Sub(before).Milliseconds()) } }() select { case &lt;-preCtx.Done(): after := time.Now() fmt.Println(&quot;pre during:&quot;, after.Sub(before).Milliseconds()) }} 举一个例子来说明一下 Context 中的级联退出。下面的代码中 childCtx 是 preCtx 的子 Context，其设置的超时时间为 300ms。但是 preCtx 的超时时间为 100 ms，因此父 Context 退出后，子 Context 会立即退出，实际的等待时间只有 100ms。 当把 preCtx 的超时时间修改为 500ms 时： 1preCtx ,_:= context.WithTimeout(ctx,500*time.Millisecond) 从新的输出中可以看出，子协程的退出不会影响父协程的退出。 从上面这个例子可以看出，父 Context 的退出会导致所有子 Context 的退出，而子 Context 的退出并不会影响父 Context。 参考link","link":"/2021/03/11/Golang%20Context%E5%8C%85%20%E8%AF%A6%E8%A7%A3/"},{"title":"2024年总结","text":"终于、拖到了现在来整理年终总结（其实早就写得差不多）了。原计划是在年前换完工作然后就写这篇总结的，但是又有一些小插曲，所以也不得不将选择的时机放在年后了。大概也有前年出差的那段时间令我不是很愉快，具体的事情也就没有必要在这里写了。成年人的世界里没有容易的，需要做的事情就是要不断让自己成长。有一天能够有更多的主动选择权，而不是被动的选择。 读书本来立的flag，阅读量是要有50本的。但实际读过的书比去年都还少了，不管是技术类的还是非技术类的书籍。这一点有一小部分原因是加班居多 ？但是终于把2019年给2020年立的flag坚持读英语&amp;&amp;背英语单词，完成度90%差不多吧，还是有慢慢在坚持（但是2021开端又停下来了，摸狗头）原本计划的是练一练口语，出国玩的时候也会方便一些（不如找一个英语还可以的女朋友，是真的对英语好的人莫名有好感，做梦？）。以及在看一些技术文档的时候，可以更好的看原汁原味的信息。 关于健康从最开始的疫情笼罩下，开始自己做饭。也解锁了不少菜谱。详情可以点击这里 香糯软滑的香菇鸡肉粥是真的超级香。比起2019年在吃(点外卖)这一块儿的账单，确实是少了不少，还是坚信自己动手丰衣足食。 健康不单单是吃这一块儿。良好的身体素质也会显得额外重要。不然怎么修福报(996)，2020年期间，犹豫上半年是基本上没咋锻炼(老生常谈的话题了，疫情)，在5月起就开始了户外锻炼。还是以跑步为主，隔几个周去奥森。以及平时晚上的时候在公司的健身区那一块儿锻炼。慢慢，5km也终于能够破20min了，10km也能破44min。我也不知道这水平是啥样，反正没去对比。还是想的是有一天能够参加半马就可以了，成绩也不至于太难看就行了。全马我就不了，这玩意没必要追求这么高。为忙碌的工作之余加强身体的锻炼就行了。 关于家人原本是计划在2020年的4月或者是10月的样子带家人来北京玩一趟的，因为趁我还在北京，以及我对朋友说过，老舍先生的《四世同堂》里说过“春天要住杭州 ，夏天住济南 ，秋天住北平”，然后想到今年不太可能，我就计划在国庆的时候回家看一看家人，以及把侄女和我妈带到成都去逛了一圈。大概是吧，工作了后发现时间大部分都不太算属于自己的，特别是工作的属性带有“一线城市”&amp;&amp;“互联网”这两个属性。尽管还有点小，很多东西仅局限于表面。看到的一些东西可能就是花花绿绿的。并不知道代表的是啥。但是我还是对我侄女保持“我知道的东西我会带她们玩的过程中科普给她们”，一方面是有个简单的初步认识，另外一个方面万一也能激起其兴趣呢。 技能陆陆续续阅读了部分源代码，大部分都是go语言相关的，当然还有一部分框架相关的。已经有提过pr（不过还是规范上的问题），希望在这一块儿，能在2021继续进行下去。主要是觉得一毕业后的简历，都要抹平大学竞赛所获得过的奖。所以自从成为了打工人后的简历尤其的平常（说好的为开源做贡献和打比赛，我承认太难了，而我又太菜了）而且源代码又有太多值得学习的地方 开源精神良好 弥补在技能上的不足 作为一个coder的兴趣 希望提升自身的 reputation（任重而道远） 不过这一块儿的水还是很深，需要花的时间太多，而又没有在自己blog上好好写下一些技术文章，主要也是觉得目前所掌握的不够深度，2021慢慢写起来吧。 选择身边的人陆续有去发展迅猛的公司，也有人选择离开北京去成都生活。勇于去改变的生活是极好的。前不久和朋友去北京天文馆(这是2021，主要是觉得比较符合这里提到的，所以额外加了一点)。看到宇宙之浩大“无论是否相信平行宇宙的存在，我们能看到的始终只有一条时间线，当我们选择了 B后，我们就永远不会知道 A 的结果是什么。同时，比起承认自身能力的不足，我们更倾向于把失利归咎于关键节点上错误的选择，那么客观的 review 选择就更是难上加难，只能进行简单的分析来做一些预测。” 关于工作部门领导，以及同事。这些实在是换的勤，人员流失大。先不管这些，主要也是对物流行业确实提不上兴趣，从内心来看还是倾向于去做c端的东西。以及预料到了会在2020年下半年加班比较多，倒也不是排斥加班，主要也是要有成长吧。很多时候我周末如果不去约同学吃饭，以及不出去玩。大概有一半的时间我会选择去公司学习，一方面是因为公司的气氛好一些。到了下半年就果然无止境的加班了，基本上从6月起就是单休的样子了，这也为我积攒了部分假期。还是期望后期去一个真的想去的公司和方向吧。 失败与展望今年感觉过得挺失败的，部分焦虑与部分乐观依然并存。这里的失败，指的是一些行动力的低下。比如每年结束&amp;&amp;第二年开始的时候都会展望比较好的flag，唯一可能就是保持一年2次回家看家人和经常关注侄女的成长。眼看毕业3年就快过去了，但是能拿得手的东西其实没啥。倒是有在年初的时候计划未来要去哪一个城市并且位置付出了行动。这篇文章中不会列出详细计划，因为觉得主要要是要加强自我行动力。关于2021，希望可以在修福报的同时还可以解锁一些其他的事情，生活并不是只有工作。","link":"/2024/01/01/2024%E5%B9%B4%E6%80%BB%E7%BB%93/"},{"title":"MySQL基础","text":"基础知识 mysql默认的引擎是InnoDB(MySQL5.5.5版本起) 三大范式 属性具有原子性，不可再分解； 不存在部分依赖； 不存在传递依赖； MySQL InnoDB 概览InnoDB的数据存储在表空间，表空间是由InnoDB管理的一个黑盒子,由一系列的数据文件组成。InnoDB采用MVCC来支持高并发 MySQL执行 Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 连接器 先连接上数据库，这个时候接待的就是连接器，连接器负责根客户端建立连接，获取权限，维持和管理连接 查询缓存 MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。 可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。(MySQL8.0没有查询缓存) 分析器 分析语法是否正确 优化器 优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join： select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20; 既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。 也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。 执行器 如检查权限等，执行SQL IO成本 IO成本就是寻址时间和上线文切换所需要的时间，最主要是用户态和内核态的上下文切换。用户态是无法直接访问磁盘等硬件上的数据的，只能通过操作系统去调内核态的接口，用内核态的线程去访问。 这里的上下文切换指的是同进程的线程上下文切换，所谓上下文就是线程运行需要的环境信息。首先，用户态线程需要一些中间计算结果保存CPU寄存器，保存CPU指令的地址到程序计数器（执行顺序保证），还要保存栈的信息等一些线程私有的信息。 然后切换到内核态的线程执行，就需要把线程的私有信息从寄存器，程序计数器里读出来，然后执行读磁盘上的数据。读完后返回，又要把线程的信息写进寄存器和程序计数器。 切换到用户态后，用户态线程又要读之前保存的线程执行的环境信息出来，恢复执行。这个过程主要是消耗时间资源。 MySQL更新当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做 分析SQL 123set @@profiling=1;select ....show profiles; 查看当前会话所产生的所有 profiles的耗时","link":"/2019/01/11/MySQL%E5%9F%BA%E7%A1%80/"},{"title":"记一次MySQL死锁排查过程","text":"背景大概说一下业务场景，需要定时计算一些数据，从其他系统、接口拉取达到的数据比较多，然后经计算后的值存储在本系统中。拉取的数据量可能有万左右，然后以主键存在的数据是需要更新的。不存在则插入。每次做全量更新/插入。 起因最开始采用的方法是先查询，数据存在则更新数据，不存在则插入数据。但是数据要求的时效性比较高。于是定时任务在做任务处理的时候频率就比较高了。就出现了单位时间内对数据库的读写高，于是就换了一个方法。用INSERT … ON DUPLICATE KEY UPDATE。 对数据库的读写次数虽然比之前少了，但是又引发了一个新的问题，因为更新、插入的数据量多，所以导致与一条INSERT … ON DUPLICATE KEY UPDATE的执行时间有点长，大概5s，去研究了下。实际上一次批量插入几千条条数据。为了解决这个问题，就分组批量查询，分为了每 50 条数据一组，这样每条sql 执行的时间也就短了。 随之又出现了另外一个问题，随着数据量的增加，一次循环拉取的数据经计算,写入,更新等。时间大于定时任务所处理的时间，这样就导致与上一个定时任务还没处理完的时候，下一个定时任务又进来处理数据了。 于是选择的做法是在每处理一组数据的时候，把 redis 的key 延长一点时间。然后整组数据处理完的时候，再删除 redis 的 值。等下一次定时任务抢到锁了再进来处理。 想到的第二个方案是，直接插入数据库，主键冲突就抛错，根据指定的错来更新值","link":"/2019/09/11/MySQL%E6%AD%BB%E9%94%81/"},{"title":"count(*) 的实现方式","text":"InnoDB引擎在执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数 MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高； 那为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。这里，用一个算 count(*) 的例子来为你解释一下。 假设表 t 中现在有 10000 条记录，我们设计了三个用户并行的会话。 会话 A 先启动事务并查询一次表的总行数； 会话 B 启动事务，插入一行后记录后，查询表的总行数； 会话 C 先启动一个单独的语句，插入一行记录后，查询表的总行数。 我们假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的。 会话A 会话B 会话C begin select count (*) from t insert into t (写入一行数据) begin insert into t(写入一行数据) select count(*) from t(返回10000) select count(*) from t(返回10002) select count(*) from t(返回10001) 在最后一个时刻，三个会话A，B，C会同时查询表t的总行数，但拿到的结果却不同 这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。 InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。 如果你用过 show table status 命令的话，就会发现这个命令的输出结果里面也有一个 TABLE_ROWS 用于显示这个表当前有多少行，这个命令执行挺快的，那这个 TABLE_ROWS 能代替 count(*) 吗？ 索引统计的值是通过采样来估算的。实际上，TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。所以，show table status 命令显示的行数也不能直接使用。 总结一下 MyISAM 表虽然 count(*) 很快，但是不支持事务； show table status 命令虽然返回很快，但是不准确； InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。 对于 count(字段) 来说： 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加； 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。 按照效率排序的话，count(字段)&lt;count(主键id)&lt;count(1)≈&lt;count(*) 尽量使用count(*) 参考极客时间MySQL实战45讲","link":"/2018/03/11/MySQL%E7%9A%84count%E8%A7%A3%E8%AF%BB/"},{"title":"String、StringBuffer、StringBuilder三者之间的区别","text":"吧啦吧啦，今天在公司做算法题的时候，不仅就想写下了 String是不可变类，所以任何对String的操作都将引发新的String对象的生成。但是StringBuffer是可变类，任何对StringBuffer所指代的字符串改变都不会产生新的对象。 新引入的StingBuilder类不是线程安全，但其在单线程中的性能比StringBuffer高。 下面是一点小例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103import java.util.ArrayList;import java.util.Iterator;import java.util.List;/** * 从JDK1.5中,有了StringBuilder。 */public class DifferenceStringBufferAndStringBuilder { private static final String base = &quot;String&quot;; private static final int count = 3000000; public static void main(String[] args) { stringTest(); stringBufferTest(); stringBuilderTest(); addToStringBuilder(); addToStringBuffer(); } /** * string执行性能测试 */ public static void stringTest() { long begin, end; begin = System.currentTimeMillis(); String test = new String(base); // 在这里为什么要缩150，因为其实时间是很长的 for (int i = 0; i &lt; count / 150; i++) { test = test + &quot;add&quot;; } end = System.currentTimeMillis(); System.out.println((end - begin) + &quot;millis has elapsed when used String&quot;); } /** * stringBuffer */ public static void stringBufferTest() { long begin, end; begin = System.currentTimeMillis(); StringBuffer stringBuffer = new StringBuffer(base); for (int i = 0; i &lt; count; i++) { stringBuffer.append(&quot;add&quot;); } end = System.currentTimeMillis(); System.out.println((end - begin) + &quot;millis has elapsed when used StringBuffer&quot;); } /** * stingBuilder */ public static void stringBuilderTest() { long begin, end; begin = System.currentTimeMillis(); StringBuilder stringBuilder = new StringBuilder(base); for (int i = 0; i &lt; count; i++) { stringBuilder.append(&quot;add&quot;); } end = System.currentTimeMillis(); System.out.println((end - begin) + &quot;mills has elapsed when used StringBuilder&quot;); } /** *转换为StringBuilder */ public static String appendItemsToStringBuilder(List list){ StringBuilder stringBuilder = new StringBuilder(); for (Iterator i = list.iterator();i.hasNext();){ stringBuilder.append(i.next()).append(&quot;&quot;); } return stringBuilder.toString(); } public static void addToStringBuilder(){ List list = new ArrayList(); list.add(&quot;l&quot;); list.add(&quot;y&quot;); list.add(&quot;z&quot;); System.out.println(DifferenceStringBufferAndStringBuilder.appendItemsToStringBuilder(list)); } public static String appendItemsToStringBuffer(List list){ StringBuffer stringBuffer = new StringBuffer(); for (Iterator i = list.iterator();i.hasNext();){ stringBuffer.append(i.next()).append(&quot;&quot;); } return stringBuffer.toString(); } public static void addToStringBuffer(){ List list = new ArrayList(); list.add(&quot;l&quot;); list.add(&quot;y&quot;); list.add(&quot;z&quot;); System.out.println(DifferenceStringBufferAndStringBuilder.appendItemsToStringBuffer(list)); }} 最后输出的是 123451127millis has elapsed when used String86millis has elapsed when used StringBuffer35mills has elapsed when used StringBuilderlyzlyz 所以根据结果来看，采用String对象时，哪怕是次数是其他对象的1/150,执行时间上也比其他对象高很多，而采用StringBuffer对象和采用StringBuilder对象也有明显的差距。所以如果是在单线程下运行，就不必考虑到线程同步的问题，优先采用StringBuilder类，当然，如果是要保证线程安全的话，就要考虑到StringBuffer了。 除了对多线程的支持不一样的话，其实这两个类没啥区别的，上面不就很好的说明了嘛。","link":"/2017/11/23/String%E3%80%81StringBuffer%E3%80%81StringBuilder%E4%B8%89%E8%80%85%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"合适以及为何使用最少使用(LFU)缓存与Golang中的实现","text":"[译]合适以及为何使用最少使用(LFU)缓存与Golang中的实现在过去的这些年，参与计算机科学和工程师的人们一直在努力优化各种性质。我们生活在一个资源有限的世界里，人们一直致力于优化成本和速度的方法。 在软件工程方面而言，我认为，最流行的改善性能的就是缓存了。在许多app都有缓存，依赖于软件方面的存储，缓存背后的想法非常简单。为了加载较快，存储数据经常被用到。 事实上，缓存必须在两个方面很快 确保尽可能多的文件请求(缓存命中)，而不是通过网络或者主内存(没有命中) 使用它的开销应该比较小，测试人员决定何时更换文件 在这篇文章中，我们将会关注第二部分。对最不常用的缓存采取特定的实现方法，并使成员资格测试和驱逐算法具有良好的性能。并且，我们还将介绍基础知识并探究这种缓存方案可用的地方。 基础LFU是一种缓存算法。只要达到缓存的容量限制，就会删除缓存中最不常用项。这意味着对于缓存中的每个项目，我们必须跟踪它的使用频率。一旦超过了容量，讲运用驱逐算法，从缓存中挑选和过期（移除）项目。 如果你之前实现过LFU缓存，你可能已经考虑使用最小堆数据结构。因为它对数时间复杂度处理插入，删除和更新。在这篇文章中，我们将介绍另一种实现它的方法。 但在我们进入实施之前，让我们看看LFU在哪些情况下比替代品更好。 LFU闪耀点想象一下CDN上的资产缓存，其中资产根据使用模式进行缓存。因此，当用户在网页上请求加载一些图片时，此CDN会将其添加到缓存中，以便其他用户更快获取它。 例如,一个这样的图像(资产)是网站的标志，你能想象一天有多少次谷歌的标识被要求在他们的所有产品上。我真的很想找到这个数字，但就目前而言，我们可能会认同这个数字是庞大的。 这种资产缓存是LFU缓存的完美用例。LFU缓存逐出算法永远不会驱逐频繁访问的资产。事实上，在这样的缓存中，谷歌的微标几乎将永远缓存，相比之下。如果由于Reddit，Slashdot和Hackernews首页上的新产品的新登录页面而有任何图像将会访问，一旦超级风暴过去，资产将被驱逐得更快，因为访问频率将急剧下降，尽管在过去几天他们已经被访问过很多次。 正如你可能已经注意到的那样，在缓存对象的访问模式不经常更改的情况下。这种缓存逐出的方法非常有效。虽然LRU缓存将驱逐最近无法访问的资产，但LFU驱逐方法将在炒作结束后逐出不再需要的资产。 实现LFU缓存现在，让我们来了解它，如我们之前所说的。我们不是将min-heap视为可能支持LFU缓存的可能数据结构，而是考虑采用更好的方法。 事实上，在2010年，一组研究人员Ketan Shah教授，Anirban Mitra和Dhruv Matani发表了一篇题为“用户实现LFU缓存驱逐方案的O(1)算法”的文章（你可以点击这里查看），在这文章中他们解释LFU缓存的实现，其运行的时间复杂度为O（1）,用于其所有操作，包括插入，访问，和删除(驱逐)。 在此，我将向你展示如何实现此缓存并引导你完成实现。 数据结构不，它不会是某种科学怪人的红黑树，事实上，它是两个双向链表和一个哈希表。是的，就是这样。 为了能够理解LFU实现的基本原理，让我们将链表和哈希表看做图形。在我们查看实际图形之前，我们需要了解如何使用哈希表和链接列表。 哈希表将使用通过哈希算法处理的密匙存储所有项目(为了我们的目的，我们 可以保持简单)，值将是实际项目。 链表有点复杂，第一个将是”频率列表“，它将具有所有访问频率。此列表中的每一个节点都有一个项目列表。该列表将包含已使用相应频率访问的所有项目。此外，项目列表中的每一个项目都会在频率列表中指向其祖先。 如果我们查看上面的图形例子，我们可以注意到项A，B，C和D已被访问过一次。E和F项已被访问过4次，依据类推。蓝线是项列表中的每个项都与频率列表中的祖先有关的指针。 那么，如果再次访问项E会发生会发生什么？让我们完成以下步奏：1. 从哈希表中检索项很容易（并且很好地扩展）O（1）。 2. 我们将访问项的frequencyParent指针，从中我们可以检查列表中的下一个频率是什么。3. 如果存在新频率(列如8)，我们将其作为频率节点8下的项目列表的第一项。4. 如果新频率不存在，我们将创建频率节点8并将节点8添加E到项列表中. 就是这样，检索项并刷新项的频率是O（1）,在我们开始实现访问算法前，让我们首先建立我们需要的基本类型。 类型如我们之前所说，我们需要对所需的类型进行建模，这些类型将成为我们缓存的主干。 第一个结构将是CacheItem,这将是将存储在缓存中的实际项目。 1234567type CacheItem struct { key string // Key of entry value interface{} // Value of item frequencyParent *list.Element // Pointer to parent in cacheList} 它包含我们可以在哈希表中查找它的键，值是实际的缓存项，以及指向频率列表中的frequencyParent指针。 下一个结构是FrequencyItem，它表示频率列表中的每一个项。它包含一组条目，这些条目将是一组CacheItem指针，我们将使用map来存储它，以便我们可以将其视为一个集合，它只包含唯一的项。 123456type FrequencyItem struct { entries map[*CacheItem]byte // Set of entries freq int // Access frequency} 我们需要具有平滑运行缓存的最后一个结构就是Cache本身。 12345678type Cache struct { bykey map[string]*CacheItem // Hashmap containing *CacheItems for O(1) access freqs *list.List // Linked list of frequencies capacity int // Max number of items size int // Current size of cache} Cache将包含hash键，称为bykey(命名来自上面链接的文件)，频率列表称为freqs，缓存的最大容量称为容量，缓存的大小表示任何给定缓存的项目数时刻。 New, set &amp; get让我们看看使缓存工作所需的前三个函数。第一个是一个小构造函数： 1234567891011func New() *Cache { cache := new(Cache) cache.bykey = make(map[string]*CacheItem) cache.freqs = list.New() cache.size = 0 cache.capacity = 100 return &amp;c} 构造函数New将创建一个新的Cache结构，并将所有默认值设置为它。如果你想知道list.New（）是如何工作的：对于频率列表，我们将使用Go的容器/列表包，其中包含一个整洁的链表实现。你可以查看其文档以获取更多详细信息。 将在Cache上实现的第二个函数是Set函数： 12345678910111213141516func (cache *Cache) Set(key string, value interface{}) { if item, ok := cache.bykey[key]; ok { item.value = value // Increment item access frequency here } else { item := new(CacheItem) item.key = key item.value = value cache.bykey[key] = item cache.size++ // Eviction, if needed // Increment item access frequency }} 该函数将缓存键和实际值/项缓存为参数。然后，它检查项目是否已经缓存。如果它被缓存，它只会更新项目的值。否则，它将创建一个新的CacheItem，它将封装实际值，它将设置密钥，它将把项添加到bykey哈希表，它将增加缓存的大小。 现在，在两个逻辑分支中，我为缺失的部分添加了一些注释：1。缓存必须知道如何增加aCacheItem的访问频率，但我们还没有实现它; 2.如果大小达到容量，缓存必须知道如何根据访问频率逐出项目。 我们将保留这些注释，直到我们实现增量和逐出函数。 Cache将接收的第三个函数是Get - 通过哈希表中的键访问项目并返回它： 12345678910func (cache *Cache) Get(key string) interface{} { if e, ok := cache.bykey[key]; ok { // Increment acess frequency here return e.value } return nil} 这里也没有魔法 - 我们检查bykey散列表是否包含带有key参数的值，如果存在则返回它。否则，我们返回零。在这里，就像在Set中一样，我们将保留占位符注释，一旦我们实现它就必须添加频率增量函数调用。 更新访问频率正如我们已经看到的，对于缓存的每个访问操作，我们必须更新所访问项的访问频率。 让我们看一下我们的Increment函数必须采取的步骤。首先，对于要过期的项目，我们将不得不决定该项目是否已经是哈希表和频率列表的一部分。如果是，我们将不得不在频率列表中找到它的新频率值和下一个频率位置（节点）。 其次，我们必须弄清楚对于新频率，频率列表中是否已经存在节点。如果有，我们将不得不将该项添加到其条目列表中并分配其新的访问频率（即当前访问频率+ 1）。如果没有，我们将不得不在频率列表中创建一个新的频率节点（并设置其所有合理的默认值），然后将该项添加到其条目列表中 第三，一旦我们检测到FrequencyParent，我们的函数就必须将新的父项设置为正在递增的项，并将其添加到父项的列表中。 作为最后一步，增量函数将从旧频率节点（frequencyParent）的条目中删除该项目。 这是Golang代码： 1234567891011121314151617181920212223242526272829303132func (cache *Cache) increment(item *CacheItem) { currentFrequency := item.frequencyParent var nextFrequencyAmount int var nextFrequency *list.Element if currentFrequency == nil { nextFrequencyAmount = 1 nextFrequency = cache.freqs.Front() } else { nextFrequencyAmount = currentFrequency.Value.(*FrequencyItem).freq + 1 nextFrequency = currentFrequency.Next() } if nextFrequency == nil || nextFrequency.Value.(*FrequencyItem).freq != nextFrequencyAmount { newFrequencyItem := new(FrequencyItem) newFrequencyItem.freq = nextFrequencyAmount newFrequencyItem.entries = make(map[*CacheItem]byte) if currentFrequency == nil { nextFrequency = cache.freqs.PushFront(newFrequencyItem) } else { nextFrequency = cache.freqs.InsertAfter(newFrequencyItem, currentFrequency) } } item.frequencyParent = nextFrequency nextFrequency.Value.(*FrequencyItem).entries[item] = 1 if currentFrequency != nil { cache.remove(currentFrequency, item) }} 让我们回顾一下频率和条目列表的原始图表，并逐步增加E项目。 我们的增量函数将采用的第一步是分配一个指向节点4（frequencyParent）及其值（即4）的指针。由于节点4存在于列表中，它将在频率列表中找到下一个节点，在我们的例子中是节点7。 一旦它确定E节点的新频率应为5而不是7，它将在节点4和7之间的列表中追加一个新的频率节点： 将5节点添加到列表后，该函数将设置节点正常运行所需的默认值。然后它会将E的指针设置为新的frequencyParent（5节点）： 作为最后一步，它将采用具有指针* CacheItem类型的项目，并将其添加到条目列表，同时从先前的frequencyParent的条目列表中删除它： 让我们看看从FrequencyItem的条目列表中删除CacheItem的步骤是什么。 删除条目一旦我们知道列表中我们想要删除它的节点，我们就可以从条目列表中删除该项，如果条目变空，还可以从频率列表中完全删除FrequencyItem： 123456789func (cache *Cache) Remove(listItem *list.Element, item *CacheItem) { frequencyItem := listItem.Value.(*FrequencyItem) delete(frequencyItem.entries, item) if len(frequencyItem.entries) == 0 { cache.freqs.Remove(listItem) }} 驱逐拼图的最后一部分是逐出，或者换句话说，一旦缓存达到其最大容量，就删除最不常用的项目。 我们必须知道我们想要驱逐多少项。通常，我们的缓存将具有低限和高限，因此当达到上限时，我们将删除项目直到下限。在我们的例子中，我们将驱逐任意数量的项目，Evict函数将作为参数。 该功能将从开始到结束开始“遍历”频率列表。由于频率列表是按升序排列的，因此它将开始从第一个频率节点开始删除条目，直到它删除与传入的任意数字一样多的项目。 如果频率节点由于逐出而不包含条目，则Evict函数也必须从频率列表中移除频率节点。它将通过调用Remove函数来实现。这样，驱逐就不会留下任何垃圾。 这是我们上面描述的代码： 12345678910111213141516func (cache *Cache) Evict(count int) { for i := 0; i &lt; count; { if item := cache.freqs.Front(); item != nil { for entry, _ := range item.Value.(*FrequencyItem).entries { if i &lt; count { delete(cache.bykey, entry.key) cache.Remove(item, entry) cache.size-- i++ } } } }} 回到Set and Get在本文开头，我们实现了Set和Get函数。那时我们没有的东西是Evict和increment函数，所以我们可以相应地使用它们。让我们添加他们的调用。 增加访问频率在Get函数中，如果我们在bykey哈希表中找到一个项目，我们需要在继续返回其值之前增加它的访问频率： 12345678910111213141516171819202122232425262728293031func (cache *Cache) Get(key string) interface{} { if e, ok := cache.bykey[key]; ok { cache.increment(e) return e.value } return nil}``通过此更改，Cache将在返回之前增加该特定项的频率。但是，我们忘了什么吗？此外，Set函数在实际缓存它们时访问缓存的项目。这意味着当一个项被缓存时，它将立即被添加到频率列表中，值为1的节点下：```gofunc (cache *Cache) Set(key string, value interface{}) { if item, ok := cache.bykey[key]; ok { item.value = value cache.increment(item) } else { item := new(CacheItem) item.key = key item.value = value cache.bykey[key] = item cache.size++ // Eviction, if needed cache.increment(item) }} 在驱逐后Set函数允许我们的LFU Cache用户在其中缓存更多项目。任何缓存的一个关键组件是，当新项目添加到缓存时，它应该知道如何逐出项目（释放空间）。对于LFU缓存，当缓存达到容量时，需要删除最不常用的项。 让我们首先添加一个函数，如果缓存达到其最大容量，它将返回一个bool： 12345func (cache *Cache) atCapacity() bool { return cache.size &gt;= cache.capacity} 功能很简单：检查Cache的当前大小是大于还是等于容量。 现在，让我们在Set函数中使用它。一旦我们在缓存中设置了新项目，我们就必须检查缓存是否已达到其容量，然后从中删除多个项目。 为简单起见，我们每次达到最大容量时只会删除10个项目： 123456789101112131415161718func (cache *Cache) Set(key string, value interface{}) { if item, ok := cache.bykey[key]; ok { item.value = value cache.increment(item) } else { item := new(CacheItem) item.key = key item.value = value cache.bykey[key] = item cache.size++ if cache.atCapacity() { cache.Evict(10) } cache.increment(item) }} 通过此更改，如果在任何时候添加项目达到缓存的容量，缓存将驱逐最不常用的项目。 通过此更改，如果在任何时候添加项目达到缓存的容量，缓存将驱逐最不常用的项目。 如果您想查看本文的完整代码，可以查看这 关于缩放和时间复杂性的评论LFU是一个有趣的驱逐计划，特别是与LRU相比，在我看来，由于其非常规性质。虽然其应用受到限制，但由于该方法的扩展能力，本文中使用的论文中解释的算法和后备数据结构非常吸引人。 如果我们重新阅读本文开头提到的论文，我们将看到虽然LFU不是新闻，但它传统上是使用min-heap实现的，它具有插入，查找和删除的对数时间。有趣的是，在本文中，作者解释说，他们提出的方法对于每个操作（插入，查找和删除）都具有O（1）时间复杂度，因为操作基于哈希表。此外，链接列表不会增加任何时间复杂度，因为我们不会在任何时候遍历列表 - 我们只是在需要时添加或删除其中的节点（这是一个O（1）操作）。 总结在本文中，我们了解了LFU缓存的基础知识。我们确定了最重要的绩效指标（命中率，成员资格和驱逐速度）。我们看到虽然它不是最广泛使用的缓存方案，但在某些用例中肯定会非常高效。 然后我们继续实施它，使用一种在时间复杂度方面可以很好地扩展的方法。我们看到了实施驱逐和频率增量算法的复杂性。最后，我们进一步探讨了我们用于实现它的方法如何扩展。 如果您想阅读有关该主题的更多信息，请参阅以下几个链接，以丰富您对LFU缓存和缓存的了解： “An O(1) algorithm for implementing the LFU cache eviction scheme”- Prof. Ketan Shah, Anirban Mitra, Dhruv Matani “Caching in theory and practice”- Pavel Panchekha “LFU (Least Frequently Used) Cache Implementation”- Geeks for Geeks 本文翻译自–原文","link":"/2019/06/04/%5B%E8%AF%91%5D%E5%90%88%E9%80%82%E4%BB%A5%E5%8F%8A%E4%B8%BA%E4%BD%95%E4%BD%BF%E7%94%A8%E6%9C%80%E5%B0%91%E4%BD%BF%E7%94%A8(LFU)%E7%BC%93%E5%AD%98%E4%B8%8EGolang%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"title":"golang-defer","text":"defer的使用特点其实其中一点特性我理解起来就有点像java中的finally的用法 关于官方解释 123A defer statement defers the execution of a function until the surrounding function returns.The deferred call's arguments are evaluated immediately, but the function call is not executed until the surrounding function returns. 这里提到了defer调用的参数会立即计算，但在周围函数返回之前不会执行函数调用。 以及延迟函数调用被压入堆栈。当函数返回时，其延迟调用以后进先出顺序执行。 它有如何特点 所在的函数中，它在 return 或 panic 或 执行完毕 后被调用 多个 defer，它们的被调用顺序，为栈的形式。先进后出，先定义的后被调用 看下面几个例子： 在计算defer语句时，将计算延迟函数的参数。在此示例中，在延迟Println调用时计算表达式“i”。函数返回后，延迟调用将打印“0”。 123456func a() { i := 0 defer fmt.Println(i) i++ return} 在周围函数返回后，延迟函数调用以后进先出顺序执行。 12345func b() { for i := 0; i &lt; 4; i++ { defer fmt.Print(i) }} //将会打印3210 然后不免在使用过程中会遇到这些坑 坑1. defer在匿名返回值和命名返回值函数中的不同表现 12345678910111213141516func returnValues() int { var result int defer func() { result++ fmt.Println(&quot;defer&quot;) }() return result}func namedReturnValues() (result int) { defer func() { result++ fmt.Println(&quot;defer&quot;) }() return result} &nbsp;&nbsp;上面的方法会输出0，下面的方法输出1。上面的方法使用了匿名返回值，下面的使用了命名返回值，除此之外其他的逻辑均相同，为什么输出的结果会有区别呢？ &nbsp;&nbsp;要搞清这个问题首先需要了解defer的执行逻辑，defer语句在方法返回“时”触发，也就是说return和defer是“同时”执行的。以匿名返回值方法举例，过程如下。 将result赋值给返回值（可以理解成Go自动创建了一个返回值retValue，相当于执行retValue = result） 然后检查是否有defer，如果有则执行 返回刚才创建的返回值（retValue） 在这种情况下，defer中的修改是对result执行的，而不是retValue，所以defer返回的依然是retValue。在命名返回值方法中，由于返回值在方法定义时已经被定义，所以没有创建retValue的过程，result就是retValue，defer对于result的修改也会被直接返回。 坑2. 判断执行没有err之后，再defer释放资源 一些获取资源的操作可能会返回err参数，我们可以选择忽略返回的err参数，但是如果要使用defer进行延迟释放的的话，需要在使用defer之前先判断是否存在err，如果资源没有获取成功，即没有必要也不应该再对资源执行释放操作。如果不判断获取资源是否成功就执行释放操作的话，还有可能导致释放方法执行错误。 正确做法 1234567resp, err := http.Get(url)// 先判断操作是否成功if err != nil { return err}// 如果操作成功，再进行Close操作defer resp.Body.Close() 坑3. 调用os.Exit时defer不会被执行当发生panic时，所在goroutine的所有defer会被执行，但是当调用os.Exit()方法退出程序时，defer并不会被执行。 123456func deferExit() { defer func() { fmt.Println(&quot;defer&quot;) }() os.Exit(0)} 上面的defer并不会输出。 坑4.非引用传参给defer调用的函数，且为非闭包函数，值不会受后面的改变影响 1234567func defer0() { a := 1 // a 作为演示的参数 defer fmt.Println(a) // 非引用传参，非闭包函数中，a 的值 不会 受后面的改变影响 a = a + 2}// 控制台输出 1 坑5. 传递引用给defer调用的函数，即使不使用闭包函数，值也会受后面的改变影响 1234567891011func myPrintln(point *int) { fmt.Println(*point) // 输出引用所指向的值}func defer1() { a := 3 // &amp;a 是 a 的引用。内存中的形式： 0x .... ---&gt; 3 defer myPrintln(&amp;a) // 传递引用给函数，即使不使用闭包函数，值 会 受后面的改变影响 a = a + 2}// 控制台输出 5 坑6. 传递值给defer调用的函数，且非闭包函数，值不会受后面的改变影响 1234567891011func p(a int) { fmt.Println(a)}func defer2() { a := 3 defer p(a) // 传递值给函数，且非闭包函数，值 不会 受后面的改变影响 a = a + 2}// 控制台输出： 3 坑7. defer调用闭包函数，且内调用外部非传参进来的变量，值会受后面的改变影响 12345678910// 闭包函数内，事实是该值的引用func defer3() { a := 3 defer func() { fmt.Println(a) // 闭包函数内调用外部非传参进来的变量，事实是该值的引用，值 会 受后面的改变影响 }() a = a + 2 // 3 + 2 = 5}// 控制台输出： 5 坑8. defer调用闭包函数，若内部使用了传参参数的值。使用的是值 123456789101112131415func defer5() { a := []int{1,2,3} for i:=0;i&lt;len(a);i++ { // 闭包函数内部使用传参参数的值。内部的值为传参的值。同时引用是不同的 defer func(index int) { // index 有一个新地址指向它 fmt.Println(a[index]) // index == i }(i) // 后进先出，3 2 1 }}// 控制台输出： // 3// 2// 1 坑9. defer所调用的非闭包函数，参数如果是函数，会按顺序先执行（函数参数） 123456789101112131415161718192021func calc(index string, a, b int) int { ret := a + b fmt.Println(index, a, b, ret) return ret}func defer6() { a := 1 b := 2 // calc 充当了函数中的函数参数。即使在 defer 的函数中，它作为函数参数，定义的时候也会首先调用函数进行求值 // 按照正常的顺序，calc(&quot;10&quot;, a, b) 首先被调用求值。calc(&quot;122&quot;, a, b) 排第二被调用 defer calc(&quot;1&quot;, a, calc(&quot;10&quot;, a, b)) defer calc(&quot;12&quot;,a, calc(&quot;122&quot;, a, b))}// 控制台输出：/**10 1 2 3 // 第一个函数参数122 1 2 3 // 第二个函数参数12 1 3 4 // 倒数第一个 calc1 1 3 4 // 倒数第二个 calc*/ 注意 defer 不影响 return的值 参考1 参考2","link":"/2019/01/11/defer/"},{"title":"gin源码阅读","text":"整体结构认识 gin框架处理请求的入口函数ServeHTTP： 12345678910111213// gin.gofunc (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { // 这里使用了对象池 c := engine.pool.Get().(*Context) // Get对象后做初始化 c.writermem.reset(w) c.Request = req c.reset() engine.handleHTTPRequest(c) // 处理HTTP请求的函数 engine.pool.Put(c) // 处理完请求后将对象放回池子} 为减少gc重复回收， 这里使用sync.pool管理自定义Context对象 将请求reqeust数据copy到Context对象中， 通过Context进行管理 调用engine.handleHTTPRequest 进行路由分发 在这里引入自定义的Context对象， 其主要是用来管理数据流转过程时的，上下文数据， 比如response， request， 请求参数params,路径fullpath, 查询缓存, 错误管理， 主要的目的是:避免重复复制数据。 保证数据的一致性。这是gin最重要的数据结构体 处理 handleHTTPRequest 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162func (engine *Engine) handleHTTPRequest(c *Context) { httpMethod := c.Request.Method rPath := c.Request.URL.Path unescape := false if engine.UseRawPath &amp;&amp; len(c.Request.URL.RawPath) &gt; 0 { rPath = c.Request.URL.RawPath unescape = engine.UnescapePathValues } if engine.RemoveExtraSlash { rPath = cleanPath(rPath) } // Find root of the tree for the given HTTP method // 根据请求方法找到对应的路由树 t := engine.trees for i, tl := 0, len(t); i &lt; tl; i++ { if t[i].method != httpMethod { continue } root := t[i].root // Find route in tree 在路由树中根据path查找 value := root.getValue(rPath, c.params, unescape) if value.params != nil { c.Params = *value.params } if value.handlers != nil { // 更新Context对象属性，将路由地址管理的多个路由函数都交给Context管理 c.handlers = value.handlers c.fullPath = value.fullPath // 执行函数链条,递归执行。 这里的Next特别有意思 c.Next() c.writermem.WriteHeaderNow() return } if httpMethod != &quot;CONNECT&quot; &amp;&amp; rPath != &quot;/&quot; { if value.tsr &amp;&amp; engine.RedirectTrailingSlash { redirectTrailingSlash(c) return } if engine.RedirectFixedPath &amp;&amp; redirectFixedPath(c, root, engine.RedirectFixedPath) { return } } break } if engine.HandleMethodNotAllowed { for _, tree := range engine.trees { if tree.method == httpMethod { continue } if value := tree.root.getValue(rPath, nil, unescape); value.handlers != nil { c.handlers = engine.allNoMethod serveError(c, http.StatusMethodNotAllowed, default405Body) return } } } c.handlers = engine.allNoRoute serveError(c, http.StatusNotFound, default404Body)} 核心代码 12345// 根据路径，请求参数，找到对应的 路由处理函数value := root.getValue(rPath, c.Params, unescape)// 递归的执行关联的handler方法c.Next() c.Next()方法，这个方法的核心，主要是方便接入中间件(Middleware)，使得代码模块化操作。 看下Next的具体实现 12345678func (c *Context) Next() { c.index++ for c.index &lt; int8(len(c.handlers)) { // 执行关联的中间件方法或者 实际路由处理函数 c.handlers[c.index](c) c.index++ }} 这里的Next设计非常有意思。以下是我给出的一个例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport &quot;fmt&quot;// 洋葱模型type Context struct { handles []func(c *Context) index int8 // 代表上面func的索引}func (this *Context) Use(f func(c *Context)) { this.handles = append(this.handles, f)}func (this *Context) Get(path string, f func(c *Context)) { this.handles = append(this.handles, f)}func (this *Context) Next() { this.index++ this.handles[this.index](this)}func (this *Context) Run() { this.handles[0](this) // 执行第一个函数}func Middleware1() func(c *Context) { return func(c *Context) { fmt.Println(&quot;middleware start&quot;) c.Next() fmt.Println(&quot;middleware end&quot;) }}func Middleware2() func(c *Context) { return func(c *Context) { fmt.Println(&quot;middleware2 start&quot;) c.Next() fmt.Println(&quot;middleware2 end&quot;) }}func main() { c := &amp;Context{} c.Use(Middleware1()) c.Use(Middleware2()) c.Get(&quot;/&quot;, func(c *Context) { fmt.Println(&quot;Get handle func &quot;) }, ) c.Run()} 创建一个Context结构体 调用Use方法，将中间件函数添加到handles中 调用Get方法，将路由函数添加到handles中 调用Run方法，执行第一个函数 执行第一个函数，打印middleware start，然后调用Next方法 Next方法中，index++，此时index为1，然后执行handles[1]，也就是第二个函数 执行第二个函数，打印middleware2 start，然后调用Next方法 Next方法中，index++，此时index为2，然后执行handles[2]，也就是第三个函数 执行第三个函数，打印Get handle func 执行完毕，返回到第二个函数，打印middleware2 end 返回到第一个函数，打印middleware end 其调用关系实现了Next方法的伪代码，加深理解： 处理函数有先后执行关系， 并且处理函数可以通过调用Abort方法， 提前返回，不用递归调用到实际处理函数。这些中间件，可以方便的使我们的业务代码接入权限校验auth，日志管理等其他功能模块。 路由匹配路由匹配是由节点的 getValue方法实现的。getValue根据给定的路径(键)返回nodeValue值，保存注册的处理函数和匹配到的路径参数数据。 gin框架涉及中间件相关有4个常用的方法，它们分别是c.Next()、c.Abort()、c.Set()、c.Get()。 中间件的注册 gin框架中的中间件设计很巧妙，从最常用的r := gin.Default()的Default函数开始看，它内部构造一个新的engine之后就通过Use()函数注册了Logger中间件和Recovery中间件： 123456func Default() *Engine { debugPrintWARNINGDefault() engine := New() engine.Use(Logger(), Recovery()) // 默认注册的两个中间件 return engine} Use() 函数 123456func (engine *Engine) Use(middleware ...HandlerFunc) IRoutes { engine.RouterGroup.Use(middleware...) // 实际上还是调用的RouterGroup的Use函数 engine.rebuild404Handlers() engine.rebuild405Handlers() return engine} 注册中间件其实就是将中间件函数追加到group.Handlers中： 12345// Use adds middleware to the group, see example code in GitHub.func (group *RouterGroup) Use(middleware ...HandlerFunc) IRoutes { group.Handlers = append(group.Handlers, middleware...) return group.returnObj()} 而我们注册路由时会将对应路由的函数和之前的中间件函数结合到一起： 123456func (group *RouterGroup) handle(httpMethod, relativePath string, handlers HandlersChain) IRoutes { absolutePath := group.calculateAbsolutePath(relativePath) handlers = group.combineHandlers(handlers) // 将处理请求的函数与中间件函数结合 group.engine.addRoute(httpMethod, absolutePath, handlers) return group.returnObj()} 12345678910111213package mainimport &quot;github.com/gin-gonic/gin&quot;func main() { r := gin.Default() r.GET(&quot;/ping&quot;, func(c *gin.Context) { c.JSON(200, gin.H{ &quot;message&quot;: &quot;success&quot;, }) }) r.Run() // listen and serve on 0.0.0.0:8080} 所以其实gin的中间件，其实就是Gin定义的一个HandlerFunc先看r.Run() 12345678func (engine *Engine) Run(addr ...string) (err error) { defer func() { debugPrintError(err) }() address := resolveAddress(addr) debugPrint(&quot;Listening and serving HTTP on %s\\n&quot;, address) err = http.ListenAndServe(address, engine) return} Gin 提供了gin.BasicAuth 生成基本认证的中间件 12345r := gin.Default()r.Use(gin.BasicAuth(gin.Accounts{ &quot;admin&quot;: &quot;123456&quot;,})) 比如访问的时候 需要用户名和密码 也可对特定的URL进行认证，也就是像这样 123456789101112func main() { r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) { c.JSON(200, &quot;首页&quot;) }) adminGroup := r.Group(&quot;/admin&quot;) adminGroup.Use(gin.BasicAuth(gin.Accounts{ &quot;admin&quot;: &quot;123456&quot;, }))}","link":"/2022/05/05/gin%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"title":"elasticsearch社区分享会","text":"在前段时间加班的时候错过了两场我想去的技术会，这次终于没落空了。大佬也多，涨了不少姿势。特此记录一下分享，由于全凭记忆叙述，可能就没啥顺序而言的还原出之前的收获。 确实目前项目中目前涉及到了elasticsearch不多，索引都才几个。看到别人分享的都是2千，4-5千的索引量。而且数据量大的话才更能体现出elasticsearch的作用。 周金阳 果壳网/在行 算法工程师 算法果然是大佬，让es与深度学习结合起来在搜索这块已经走在很多公司的前面了吧。 使用 ES 来构建一个简易却行之有效的个性化推荐系统，以及一些高级搜索排序的实践。 搜索排序主要是分享一些机器学习工具与 ES 配合的实践心得。 思考一个问题，如果是这样的你会选择怎么排序 1234{ &quot;title&quot;:&quot;引力波&quot; &quot;content&quot;:&quot;引力波引力波引力波&quot;} 1234{ &quot;title&quot;:&quot;引力波,一个世纪的求索&quot; &quot;content&quot;:&quot;在物理学中，引力波是指时空弯曲中的涟漪，通过波的形式从辐射源向外传播，这种波以引力辐射的形式传输能量。在1916年，爱因斯坦基于广义相对论预言了引力波的存在。引力波的存在是广义相对论洛伦兹不变性的结果，因为它引入了相互作用的传播速度有限的概念。相比之下，引力波不能够存在于牛顿的经典引力理论当中，因为牛顿的经典理论假设物质的相互作用传播是速度无限的。&quot;} 若输入的值和被检索到的结果呈线性变化g(q,x)很明显，第一个是用户测试的或者是胡乱写的，当用户输入“引力波”的时候，如何控制类似于这种情况让正常的显示在前。这种情况，就可以加一些其他的限制条件f(x),比如1得出来的期望值为15.42,2得出来的期望值为87.93，这样关于g(q,x) -&gt; f(x)*g(q,x) 当然如果要做的好的话需要优化的还有很多，比如用BiLSTM+CNN 期望后期会用到这些吧，毕竟我觉得这是偏离业务而且是和大数据接轨的之一。 其中，在使用es的时候有一些规范和约束， 业务索引尽量自定义id，数据敏感业务自备插入修改时间 一个索引一个type 控制单次搜索结果条数，总条数由es限制。控制请求超时时间 关于es的使用也有在调用链日志 一个节点一个主分片，0副本， 批量写入，控制单批写入字节数 在生产阶段，调用链日志写入慢，kafka会出现大量堆积等现象，关于如何解决。有以下方案， 索引写入时会伴随着id校验，请求体解析，分词等操作，都会带来一定的cpu开销。原先的索引结构中存在部分多余字段，无需进行分词，取消后可以减轻cpu压力。 使用es自动生成id，省去id检查步骤。调整translog合并时间，半小时一次，防止过多merge任务导致cpu开销过大。 在业务索引随着场景变化，写入量逐渐增多，集群cpu load变高，原来单个主分片写入出现瓶颈遇到这种情况 可以重建索引，主分片改为2个，分别分布在两台机器，达到负载均衡效果，数据需要迁移。 在提及到es时，不得不说也是和spark相关。这里就不展开讲了，下次深入了解的时候再学习。 番外大公司都是搜索是一个团队，虽然我业务写的也不好，但是我更倾向于这种方向。分享者都很强，有开发相关的以及运维，技术演变快，找准自己的一个兴趣点，专研下去。","link":"/2018/09/11/elasticsearch%E7%A4%BE%E5%8C%BA%E5%88%86%E4%BA%AB%E4%BC%9A/"},{"title":"golang 切片","text":"切片结构12345type slice struct { array unsafe.Pointer len int cap int} 12a = make([]int, 0)unsafe.Sizeof(a) // 24 切片组成元素： 指针：指向底层数组 长度：切片中元素的长度，不能大于容量 容量：指针所指向的底层数组的总容量 初始化方式 使用make12slice := make([]int, 5) // 初始化长度和容量都为 5 的切片slice := make([]int, 5, 10) // 初始化长度为 5, 容量为 10 的切片 使用 make 关键字创建切片时，很多工作都需要运行时的参与；调用方必须在 make 函数中传入一个切片的大小以及可选的容量，[cmd/compile/internal/gc.typecheck1](https://github.com/golang/go/blob/b7d097a4cf6b8a9125e4770b54d33826fa803023/src/cmd/compile/internal/gc/typecheck.go#L327-L2126) 会对参数进行校验： 123456789101112131415161718192021222324252627282930313233func typecheck1(n *Node, top int) (res *Node) { switch n.Op { ... case OMAKE: args := n.List.Slice() i := 1 switch t.Etype { case TSLICE: if i &gt;= len(args) { yyerror(&quot;missing len argument to make(%v)&quot;, t) return n } l = args[i] i++ var r *Node if i &lt; len(args) { r = args[i] } ... if Isconst(l, CTINT) &amp;&amp; r != nil &amp;&amp; Isconst(r, CTINT) &amp;&amp; l.Val().U.(*Mpint).Cmp(r.Val().U.(*Mpint)) &gt; 0 { yyerror(&quot;len larger than cap in make(%v)&quot;, t) return n } n.Left = l n.Right = r n.Op = OMAKESLICE } ... }} 上述函数不仅会检查 len 是否传入，还会保证传入的容量 cap 一定大于或者等于 len，除了校验参数之外，当前函数会将 OMAKE 节点转换成 OMAKESLICE，随后的中间代码生成阶段在 [cmd/compile/internal/gc.walkexpr](https://github.com/golang/go/blob/4d5bb9c60905b162da8b767a8a133f6b4edcaa65/src/cmd/compile/internal/gc/walk.go#L439-L1532) 函数中的 [OMAKESLICE](https://github.com/golang/go/blob/4d5bb9c60905b162da8b767a8a133f6b4edcaa65/src/cmd/compile/internal/gc/walk.go#L1315) 分支依据两个重要条件对这里的 OMAKESLICE 进行转换： 切片的大小和容量是否足够小； 切片是否发生了逃逸，最终在堆上初始化 虽然大多的错误都可以在编译期间被检查出来，但是在创建切片的过程中如果发生了以下错误就会直接导致程序触发运行时错误并崩溃： 内存空间的大小发生了溢出； 申请的内存大于最大可分配的内存； 传入的长度小于 0 或者长度大于容量； [runtime.makeslice](https://draveness.me/golang/tree/runtime.makeslice) 在最后调用的 [runtime.mallocgc](https://draveness.me/golang/tree/runtime.mallocgc) 是用于申请内存的函数，这个函数的实现比较复杂，如果遇到了比较小的对象会直接初始化在 Go 语言调度器里面的 P 结构中，而大于 32KB 的对象会在堆上初始化 为啥是32kb 界限的选择是基于一些性能和内存管理的考虑。 小于等于32KB的对象被认为是比较小的，可以在 P 结构中进行初始化。这样做有以下几个优点： 减少对堆的访问：将对象初始化在 P 结构中可以避免频繁地访问堆，减少内存的分配和释放操作，提高程序的性能。 提高局部性：将对象与对应的 P 结构关联起来，可以提高数据的局部性，减少内存访问的延迟，进一步提升性能。 大于32KB的对象被认为是较大的对象，其内存需求比较高。将这些对象直接初始化在堆上有以下几个优点： 堆的管理更加灵活：堆提供了更加灵活的内存管理机制，可以根据需要动态分配和释放内存，适应各种大小的对象。 避免过度占用 P 结构：将大对象初始化在堆上可以避免过度占用 P 结构的内存空间，保持 P 结构的高效利用。 使用简短定义 1slice := []int{1, 2, 3} 使用数组来初始化切片 123arr := [5]int{1, 2, 3, 4, 5}slice := arr[0:3] // 左闭右开区间，最终切片为 [1,2,3]cap(slice) // 长度为5,更通用的规则是：一个切片的容量可以被看作是透过这个窗口最多可以看到的底层数组中元素的个数。注意，切片代表的窗口是无法向左扩展的。 使用切片来初始化切片12sliceA := []int{1, 2, 3, 4, 5}sliceB := sliceA[0:3] // 左闭右开区间，sliceB 最终为 [1,2,3] 扩容例子 注意点 多个切片共享一个底层数组的情况，对底层数组的修改，将影响上层多个切片的值 多个切片共享一个底层数组的情况，对底层数组的修改，原有的切片发生了扩容 底层数组被重新创建 ，和原来的切片已经没有关系了 扩容的slice还和类型(其实是类型占的字节)有关 1234567891011121314e := []int32{1,2,3} fmt.Println(&quot;cap of e before:&quot;,cap(e)) e = append(e,4) fmt.Println(&quot;cap of e after:&quot;,cap(e)) f := []int{1,2,3} fmt.Println(&quot;cap of f before:&quot;,cap(f)) f = append(f,4) fmt.Println(&quot;cap of f after:&quot;,cap(f)) cap of e before: 3cap of e after: 8cap of f before: 3cap of f after: 6 1234567891011121314151617181920package mainimport ( &quot;fmt&quot;)func main() { slice := []int{1, 2, 3, 4, 5} newSlice := slice[0:3] fmt.Println(&quot;before modifying underlying array:&quot;) fmt.Println(&quot;slice: &quot;, slice) fmt.Println(&quot;newSlice: &quot;, newSlice) fmt.Println() newSlice[0] = 6 // 如果是newSlice append几个元素进去，则slice的值为 6，1，2，3，4，5 fmt.Println(&quot;after modifying underlying array:&quot;) fmt.Println(&quot;slice: &quot;, slice) fmt.Println(&quot;newSlice: &quot;, newSlice)} 以上代码预期输出如下： 1234567before modify underlying array:slice: [1 2 3 4 5]newSlice: [1 2 3]after modify underlying array:slice: [6 2 3 4 5]newSlice: [6 2 3] 使用 copy 方法可以避免共享同一个底层数组 1234567891011121314151617181920package mainimport ( &quot;fmt&quot;)func main() { slice := []int{1, 2, 3, 4, 5} newSlice := make([]int, len(slice)) copy(newSlice, slice) fmt.Println(&quot;before modifying underlying array:&quot;) fmt.Println(&quot;slice: &quot;, slice) fmt.Println(&quot;newSlice: &quot;, newSlice) fmt.Println() newSlice[0] = 6 fmt.Println(&quot;after modifying underlying array:&quot;) fmt.Println(&quot;slice: &quot;, slice) fmt.Println(&quot;newSlice: &quot;, newSlice)} 以上代码预期输出如下： 1234567before modifying underlying array:slice: [1 2 3 4 5]newSlice: [1 2 3 4 5]after modifying underlying array:slice: [1 2 3 4 5]newSlice: [6 2 3 4 5] 扩容分析通过 append 关键字被转换的控制流了解了在切片容量足够时如何向切片中追加元素，但是当切片的容量不足时就会调用 [runtime.growslice](https://github.com/golang/go/blob/440f7d64048cd94cba669e16fe92137ce6b84073/src/runtime/slice.go#L76-L191) 函数为切片扩容，扩容就是为切片分配一块新的内存空间并将原切片的元素全部拷贝过去，我们分几部分分析该方法： 1234567891011121314151617181920func growslice(et *_type, old slice, cap int) slice { // …… newcap := old.cap doublecap := newcap + newcap if cap &gt; doublecap { newcap = cap } else { if old.cap &lt; 1024 { newcap = doublecap } else { for newcap &lt; cap { newcap += newcap / 4 } } } // …… capmem = roundupsize(uintptr(newcap) * ptrSize) newcap = int(capmem / ptrSize)} 后半部分还对 newcap 作了一个内存对齐，这个和内存分配策略相关。进行内存对齐之后，新 slice 的容量是要 大于等于 老 slice 容量的 2倍或者1.25倍。 123456789package mainimport &quot;fmt&quot;func main() { s := []int{1,2} s = append(s,4,5,6) fmt.Printf(&quot;len=%d, cap=%d&quot;,len(s),cap(s))} 运行结果是： 1len=5, cap=6 （如果按照1.25倍的说法就是5，8，但实际上是错误的） 这个函数的参数依次是 元素的类型，老的 slice，新 slice 最小求的容量。 例子中 s 原来只有 2 个元素，len 和 cap 都为 2，append 了三个元素后，长度变为 5，容量最小要变成 5，即调用 growslice 函数时，传入的第三个参数应该为 5。即 cap=5。而一方面，doublecap 是原 slice容量的 2 倍，等于 4。满足第一个 if 条件，所以 newcap 变成了 5。 接着调用了 roundupsize 函数，传入 40。（代码中ptrSize是指一个指针的大小，在64位机上是8） 再看内存对齐，搬出 roundupsize 函数的代码： 1234567891011121314func roundupsize(size uintptr) uintptr { if size &lt; _MaxSmallSize { if size &lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]]) } else { //…… } } //……}const _MaxSmallSize = 32768const smallSizeMax = 1024const smallSizeDiv = 8 最终返回 1class_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]] 这是 Go 源码中有关内存分配的两个 slice。class_to_size通过 spanClass获取 span划分的 object大小。而 size_to_class8 表示通过 size 获取它的 spanClass。 123var size_to_class8 = [smallSizeMax/smallSizeDiv + 1]uint8{0, 1, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31}var class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} 传进去的 size 等于 40。所以 (size+smallSizeDiv-1)/smallSizeDiv = 5；获取 size_to_class8 数组中索引为 5 的元素为 4；获取 class_to_size 中索引为 4 的元素为 48。最终，新的 slice 的容量为 6： 1newcap = int(capmem / ptrSize) // 6 预估容量（预估”元素个数”） 注意：(官方代码在2020-09-25 换成了 if old.cap &lt; 1024{} ) 如果新申请容量（cap）大于旧容量（old.cap）的两倍，则最终容量（newcap）是新申请的容量（cap）； 如果旧切片的长度小于 1024，则最终容量是旧容量的 2 倍，即“newcap=doublecap”； (注意1.18后时256) 如果旧切片的长度大于或等于 1024，则最终容量从旧容量开始循环增加原来的 1/4，直到最终容量大于或等于新申请的容量为止；(注意1.18后时256，&gt;=512) 如果最终容量计算值溢出，即超过了 int 的最大范围，则最终容量就是新申请容量。 分配内存 = 预估容量 * 元素类型大小 申请分配内存是语言自身实现的内存管理模块向操作系统申请(合适的内存规格:8,16,32,48,64,80,96,112……字节，64位下每个元素占16字节。32位下占8字节,其中查看类型占多少字节用unsafe.Sizeof()来判断，但是又如何得知当前平台是在处于多少为的系统。可以用以下来判断(比如int在64为下占8个字节，string在64为下占10个字节) 132 &lt;&lt; (^uint(0) &gt;&gt; 63) ^uint(0)在32位系统上返回的是0XFFFFFFFF, 也就是2^32, 在64位系统上返回的是0xFFFFFFFFFFFFFFFF, 也就是2^64 申请分配内存会匹配到最接近的规格 确认了最新容量后，则进行内存对齐。通过对元素的大小（et.size）的判断，对了内存对齐。通过数组class_to_size拿到对齐的值。 newCap = 申请分配内存 / 元素类型大小 在1.22版本后切片的扩容机制变更为 初始化变量：函数接受两个参数，newLen 表示切片的新长度，oldCap 表示切片的旧容量。开始时将 newcap 初始化为 oldCap。 判断是否需要直接扩容至新长度：首先计算 doublecap，即旧容量的两倍。如果新长度大于 doublecap，则直接返回新长度，因为此时直接扩容到新长度即可。 阈值判断：定义了一个阈值常量 threshold，其值为 256。如果旧容量小于该阈值，那么新容量直接设置为 doublecap。 循环计算新容量：对于大于等于阈值的旧容量，采用一种新的扩容策略，即每次增加 newcap 的 1.25 倍，直到 newcap 大于等于 newLen。 溢出检查：通过将 newcap 强制转换为 uint 类型进行溢出检查。如果 newcap 溢出，则直接返回新长度。 返回新容量：最后返回新容量，如果新容量小于等于 0，则返回新长度，以防溢出。 这个机制在处理切片扩容时，尤其是针对大容量的切片，可以更加有效地管理内存，避免频繁的内存分配和拷贝操作，从而提高性能。 拷贝切片当我们使用 copy(a, b) 的形式对切片进行拷贝时，编译期间的 [cmd/compile/internal/gc.copyany](https://github.com/golang/go/blob/bf4990522263503a1219372cd8f1ee9422b51324/src/cmd/compile/internal/gc/walk.go#L2980-L3040) 函数也会分两种情况进行处理，如果当前 copy 不是在运行时调用的，copy(a, b) 会被直接转换成下面的代码： 之后，向 Go 内存管理器申请内存，将老 slice 中的数据复制过去，并且将 append 的元素添加到新的底层数组中。最后，向 growslice 函数调用者返回一个新的 slice，这个 slice 的长度并没有变化，而容量却增大了。 1234567n := len(a)if n &gt; len(b) { n = len(b)}if a.ptr != b.ptr { memmove(a.ptr, b.ptr, n*sizeof(elem(a))) } 例子 12345arr := [10]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}var sl []int = arr[1:4]var s2 []int = arr[7:]fmt.Println(len(sl),cap(sl)) // 3,9 fmt.Println(len(s2),cap(s2)) // 3,3 一个切片的容量可以被看作是透过这个窗口最多可以看到的底层数组中元素的个数。注意，切片代表的窗口是无法向左扩展的。(前面提到的) 使用技巧12345a = a[:len(a)-1] // 删除尾部1个元素a = a[:len(a)-N] // 删除尾部N个元素a = a[1:] // 删除开头1个元素a = a[N:] // 删除开头N个元素a = append(a[:i], a[j:]...) // cut i ~ j 假设切片里存放的是指针对象，那么下面删除末尾的元素后，被删除的元素依然被切片底层数组引用，从而导致被自动垃圾回收器回收（这要依赖回收器的实现方式）： 保险的方式是先将需要自动内存回收的元素设置为nil，保证自动回收器可以发现需要回收的对象，然后再进行切片的删除操作： 123var a []*int{ ... }a[len(a)-1] = nil // GC回收最后一个元素内存a = a[:len(a)-1] // 从切片删除最后一个元素 同理截掉切片[i,j）之间的元素： 1a = append(a[:i], a[j:]...) 上面的Cut如果元素是指针的话，会存在内存泄露，所以我们要对删除的元素设置nil，等待GC。 12345copy(a[i:], a[j:])for k, n := len(a)-j+i, len(a); k &lt; n; k++ { a[k] = nil // or the zero value of T}a = a[:len(a)-j+i] Delete（GC） 123copy(a[i:], a[i+1:])a[len(a)-1] = nil // or the zero value of Ta = a[:len(a)-1] 切片使用不当对内存的泄露 应该将原切片拷到一个新的切片操作，比如使用切片的前5个slice12345func getMessageType(msg []byte) []byte { msgType := make([]byte, 5) copy(msgType, msg) return msgType} 分组切片 12345678910func chunk(actions []int, batchSize int) [][]int { var batches [][]int for batchSize &lt; len(actions) { actions, batches = actions[batchSize:], append(batches, actions[0:batchSize:batchSize]) } batches = append(batches, actions) return batches} 同时数组可以作为 map 的 k（键），而切片不行 它的大小和类型在编译时就已经确定了。 append函数的常见操作 删除位于索引 i 的元素：a = append(a[:i], a[i+1:]…) 切除切片 a 中从索引 i 至 j 位置的元素：a = append(a[:i], a[j:]…) 为切片 a 扩展 j 个元素长度：a = append(a, make([]T, j)…) 索引 i 的位置插入切片 b 的所有元素：a = append(a[:i], append(b, a[i:]…)…) 并发安全slice 是非协程安全的数据类型，如果创建多个 goroutine 对 slice 进行并发读写，会造成丢失。看一段代码 123456789101112131415161718192021package mainimport ( &quot;fmt&quot; &quot;sync&quot;)func main () { a := make([]int, 0) var wg sync.WaitGroup for i := 0; i &lt; 10000; i++ { wg.Add(1) go func(i int) { a = append(a, i) wg.Done() }(i) } wg.Wait() fmt.Println(len(a))}// 9403 9876 9985 9491 ... 多次执行，每次得到的结果都不一样，总之一定不会是想要的 10000 个。想要解决这个问题，按照协程安全的编程思想来考虑问题可以考虑使用 channel 本身的特性(阻塞)来实现安全的并发读写。 123456789101112131415161718192021func main() { a := make([]int, 0) buffer := make(chan int) go func() { for v := range buffer { a = append(a, v) } }() var wg sync.WaitGroup for i := 0; i &lt; 10000; i++ { wg.Add(1) go func(i int) { buffer &lt;- i wg.Done() }(i) } wg.Wait() fmt.Println(len(a))}// 10000 slice 坑bar 执行了 append 函数之后，最终也修改了 foo 的最后一个元素，这是一个在实践中非常常见的陷阱。 12345foo := []int{0, 0, 0, 42, 100}bar := foo[1:4]bar = append(bar, 99)fmt.Println(&quot;foo:&quot;, foo) // foo: [0 0 0 42 99]fmt.Println(&quot;bar:&quot;, bar) // bar: [0 0 42 99] bar 的 cap 容量会到原始切片的末尾，所以当前 bar 的 cap 长度为 4。 如果要解决这样的问题，其实可以在截取时指定容量： 12345foo := []int{0,0,0,42,100}bar := foo[1:4:4]bar = append(bar, 99)fmt.Println(&quot;foo:&quot;, foo) // foo: [0 0 0 42 100]fmt.Println(&quot;bar:&quot;, bar) // bar: [0 0 42 99] foo[1:4:4] 这里，第三个参数 4 代表 cap 的位置一直到下标 4，但是不包括下标 4。 所以当前 bar 的 Cap 变为了 3，和它的长度相同。当 bar 进行 append 操作时，将发生扩容，它会指向与 foo 不同的底层数据空间。由于bar的容量足够，它将继续使用foo的底层数数组，所以foo也被修改成了[0, 0, 0, 42, 99]。 切片中的三种特殊状态切片的三种特殊状态 —— 「零切片」、「空切片」和「nil 切片」。 空切片和 nil 切片的区别在于，空切片指向的地址不是nil，指向的是一个内存地址，但是它没有分配任何内存空间，即底层元素包含0个元素。 不管是使用 nil 切片还是空切片，对其调用内置函数 append，len 和 cap 的效果都是一样的。 通过 unsafe.Pointer 来转换 Go 语言的任意变量类型。 12345678910111213141516171819var s1 []intvar s2 = []int{}var s3 = make([]int, 0)var s4 = *new([]int)var a1 = *(*[3]int)(unsafe.Pointer(&amp;s1))var a2 = *(*[3]int)(unsafe.Pointer(&amp;s2))var a3 = *(*[3]int)(unsafe.Pointer(&amp;s3))var a4 = *(*[3]int)(unsafe.Pointer(&amp;s4))fmt.Println(a1)fmt.Println(a2)fmt.Println(a3)fmt.Println(a4)---------------------[0 0 0][824634355296 0 0][824634355296 0 0][0 0 0] 其中输出为 [0 0 0] 的 s1 和 s4 变量就是「 nil 切片」，s2 和 s3 变量就是「空切片」。824634199592 这个值是一个特殊的内存地址，所有类型的「空切片」都共享这一个内存地址。 空切片指向的 zerobase 内存地址是一个神奇的地址 「 nil 切片」和 「空切片」在使用上有什么区别么？ 最好办法是不要创建「 空切片」，统一使用「 nil 切片」，同时要避免将切片和 nil 进行比较来执行某些逻辑。这是官方的标准建议。（正确选择 var res []int ） 1234567891011121314151617181920package mainimport &quot;fmt&quot;func main() { var s1 []int // nil 切片 var s2 = []int{} // 空切片 fmt.Println(s1 == nil) fmt.Println(s2 == nil) fmt.Printf(&quot;%#v\\n&quot;, s1) fmt.Printf(&quot;%#v\\n&quot;, s2)}-------truefalse[]int(nil)[]int{} 「空切片」和「 nil 切片」有时候会隐藏在结构体中，这时候它们的区别就被太多的人忽略了，看个例子 123456789101112type Something struct { values []int}var s1 = Something{}var s2 = Something{[]int{}}fmt.Println(s1.values == nil)fmt.Println(s2.values == nil)--------truefalse 「空切片」和「 nil 切片」还有一个极为不同的地方在于 JSON 序列化 1234567891011121314type Something struct { Values []int}var s1 = Something{}var s2 = Something{[]int{}}bs1, _ := json.Marshal(s1)bs2, _ := json.Marshal(s2)fmt.Println(string(bs1))fmt.Println(string(bs2))---------{&quot;Values&quot;:null}{&quot;Values&quot;:[]} 注意，对于切片的判断最好使用len()==0 参考 why-go-vet-report-uint0-might-be-too-small-for-shift-of-63 slice类型存什么？make和new？slice和数组？扩容规则？ 切片(slice)性能及陷阱 切片的容量是怎样增长的 3.2 切片 深度解析 Go 语言中「切片」的三种特殊状态","link":"/2020/10/11/golang%E5%88%87%E7%89%87/"},{"title":"golang 中获取字符串个数","text":"golang 中获取字符串个数在 golang 中不能直接用 len 函数来统计字符串长度，查看了下源码发现字符串是以 UTF-8 为格式存储的，说明 len 函数是取得包含 byte 的个数 123// string is the set of all strings of 8-bit bytes, conventionally but not// necessarily representing UTF-8-encoded text. A string may be empty, but// not nil. Values of string type are immutable. 举个例子，”Hello, 世界“(因为，对比所以用了中文) 123s := &quot;Hello, 世界&quot;fmt.Println(len(s)) // 13fmt.Println([]byte(s)) // [72 101 108 108 111 44 32 228 184 150 231 149 140] 既然是以 byte 存储的，那自然就想到了取 byte 的长度 1234- bytes.Count() - strings.Count() - 将字符串转换为 []runee 后调用 len 函数- 使用 utf8.RuneCountInString() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package mainimport ( &quot;bytes&quot; &quot;fmt&quot; &quot;strings&quot; &quot;testing&quot; &quot;unicode/utf8&quot;)/*在 golang 中不能直接用 len 函数来统计字符串长度，查看了下源码发现字符串是以 UTF-8 为格式存储的，说明 len 函数是取得包含 byte 的个数*/func main() { s := &quot;hello, 世界&quot; fmt.Println(len(s)) // 13 fmt.Println([]byte(s)) // [72 101 108 108 111 44 32 228 184 150 231 149 140] fmt.Print(f1(s))}func f1(s string) int { return bytes.Count([]byte(s), nil) - 1}func f2(s string) int { return strings.Count(s, &quot;&quot;) - 1}func f3(s string) int { return len([]rune(s))}func f4(s string) int { return utf8.RuneCountInString(s)}var s = &quot;Hello, 世界&quot;func Benchmark1(b *testing.B) { for i := 0; i &lt; b.N; i++ { f1(s) }}func Benchmark2(b *testing.B) { for i := 0; i &lt; b.N; i++ { f2(s) }}func Benchmark3(b *testing.B) { for i := 0; i &lt; b.N; i++ { f3(s) }}func Benchmark4(b *testing.B) { for i := 0; i &lt; b.N; i++ { f4(s) }} 在 golang ldea配置中我没有看到 benchamark配置，总说包不对，在命令行中输入 1go test stringCount_test.go -bench &quot;.*&quot; 得到以下结果 1234Benchmark1-12 100000000 17.7 ns/opBenchmark2-12 100000000 14.0 ns/opBenchmark3-12 100000000 14.5 ns/opBenchmark4-12 100000000 13.1 ns/op 最快的是utf8.RuneCountInString() 参考","link":"/2018/04/01/golang%20%E4%B8%AD%E8%8E%B7%E5%8F%96%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AA%E6%95%B0/"},{"title":"Go字符串","text":"修改字符串要修改字符串，需要先将其转换成[]rune或[]byte，完成后再转换为string。无论哪种转换，都会重新分配内存，并复制字节数组。 1234567891011func changeString() { s1 := &quot;hello&quot; // 强制类型转换 byteS1 := []byte(s1) byteS1[0] = 'H' fmt.Println(string(byteS1)) s2 := &quot;博客&quot; runeS2 := []rune(s2) runeS2[0] = '狗' fmt.Println(string(runeS2)) } 先将这段内存拷贝到堆或者栈上； 将变量的类型转换成 []byte 后并修改字节数据； 将修改后的字节数组转换回 string； 1234// string is the set of all strings of 8-bit bytes, conventionally but not// necessarily representing UTF-8-encoded text. A string may be empty, but// not nil. Values of string type are immutable.type string string string是8位字节的集合，通常但不一定代表UTF-8编码的文本。string可以为空，但不能为nil。string的值是不能改变的 Go源代码为 UTF-8 编码格式的，源代码中的字符串直接量是 UTF-8 文本。所以Go语言中字符串是UTF-8编码格式的。 123// rune is an alias for int32 and is equivalent to int32 in all ways. It is// used, by convention, to distinguish character values from integer values.type rune = int32 rune是int32的别名，在所有方面都等同于int32，按照约定，它用于区分字符值和整数值。 rune一个值代表的就是一个Unicode字符，因为一个Go语言中字符串编码为UTF-8，使用1-4字节就可以表示一个字符，所以使用int32类型范围可以完美适配。 见坑 字符串拼接 优先使用 strings.Builder 而不是 += 子字符串操作及内存泄露字符串的切分也会跟切片的切分一样，可能会造成内存泄露。例子：有一个handleLog的函数，接收一个string类型的参数log，假设log的前4个字节存储的是log的message类型值，需要从log中提取出message类型，并存储到内存中。下面是相关代码： 12345678func (s store) handleLog(log string) error { if len(log) &lt; 4 { return errors.New(&quot;log is not correctly formatted&quot;) } message := log[:4] s.store(message) // Do something} 使用log[:4]的方式提取出了message，假设参数log是一个包含成千上万个字符的字符串。当使用log[:4]操作时，实际上是返回了一个字节切片，该切片的长度是4，而容量则是log字符串的整体长度。那么实际上存储的message不是包含4个字节的空间，而是整个log字符串长度的空间。所以就有可能会造成内存泄露。如下图所示： 那怎么避免呢？使用拷贝。将uuid提取后拷贝到一个字节切片中，这时该字节切片的长度和容量都是4。如下： 123456789func (s store) handleLog(log string) error { if len(log) &lt; 4 { return errors.New(&quot;log is not correctly formatted&quot;) } message := string([]byte(log[:4])) s.store(message) // Do something} 字符串的长度内建的 len()函数返回byte的数量，而不是像Python中计算好的unicode字符串中字符的数量。要在Go中得到相同的结果，可以使用“unicode/utf8”包中的 RuneCountInString()函数。 1234567package mainimport(&quot;fmt&quot;&quot;unicode/utf8&quot;)func main(){ data :=&quot;♥&quot; fmt.Println(utf8.RuneCountInString(data))//prints: 1} 理论上说 RuneCountInString()函数并不返回字符的数量，因为单个字符可能占用多个rune。","link":"/2019/02/11/go_string/"},{"title":"golang逃逸分析","text":"堆内存与栈内存Go 程序会在 2 个地方为变量分配内存，一个是全局的堆(heap)空间用来动态分配内存，另一个是每个 goroutine 的栈(stack)空间。与 Java、Python 等语言类似，Go 语言实现垃圾回收(Garbage Collector)机制，因此，Go 语言的内存管理是自动的，通常开发者不需要关心内存分配在栈上，还是堆上。但是从性能的角度出发，在栈上分配内存和在堆上分配内存，性能差异是非常大的。 栈 栈的内存是由编译器自动进行分配和释放的，栈区往往存储着函数参数、局部变量和调用函数帧，它们随着函数的创建而分配，随着函数的退出而销毁。 Go应用程序运行时，每个 goroutine 都维护着一个自己的栈区，这个栈区只能自己使用不能被其他 goroutine 使用。（所以不需要加锁）栈是调用栈（call stack）的简称。一个栈通常又包含了许多栈帧（stack frame），它描述的是函数之间的调用关系 堆 堆区的内存一般由编译器和工程师自己共同进行管理分配，交给 Runtime GC 来释放。在堆上分配时，必须找到一块足够大的内存来存放新的变量数据。后续释放时，垃圾回收器扫描堆空间寻找不再被使用的对象。（所有有时候会有加锁的操作防止数据竞争） 在函数中申请一个对象，如果分配在栈中，函数执行结束时自动回收，如果分配在堆中，则在函数结束后某个时间点进行垃圾回收。 在栈上分配和回收内存的开销很低，在栈上分配内存，消耗的仅是将数据拷贝到内存的时间，而内存的 I/O 通常能够达到 30GB/s，因此在栈上分配内存效率是非常高的。 在堆上分配内存，一个很大的额外开销则是垃圾回收。Go 语言使用的是标记清除算法，并且在此基础上使用了三色标记法和写屏障技术，提高了效率。 函数参数是值传递的，且在调用的时立即执行值拷贝的。所以无论传递什么参数都会被copy到函数的参数变量的内存地址中，堆或者栈上，具体是堆还是栈上涉及到逃逸问题 什么是逃逸分析逃逸分析是编译器用于决定变量分配到堆上还是栈上的一种行为。 确定一个变量是在堆上还是在栈上 ？ 是否有在其他地方（非局部）被引用。只要有可能被引用了，那么它一定分配到堆上。否则分配到栈上。 即使没有被外部引用，但对象过大，无法存放在栈区上。依然有可能分配到堆上。 比如这样的例子 123456789101112func main() { var i int fmt.Printf(&quot;main: %p\\n&quot;, &amp;i) foo(i)}func foo(i int) { fmt.Printf(&quot;foo : %p\\n&quot;, &amp;i)}// 输出的变量地址不一样main: 0xc0000382b0foo : 0xc0000382b8 所以对于复杂结构应该尽量的传递指针减少copy时的开销。 指针传递的同时也带来变量逃逸，和GC压力，也是一把双刃剑，好在大部分情况下不需要特别的对GC进行调优。所以，在make it simple的理念下，在需要时再针对性调优是个不错的选择。 什么时候我们应该传递值，什么时候应该传递指针，这主要取决于copy开销和是否需要在函数内部对变量值进行更改。 指针逃逸指针逃逸应该是最容易理解的一种情况了，即在函数中创建了一个对象，返回了这个对象的指针。这种情况下，函数虽然退出了，但是因为指针的存在，对象的内存不能随着函数结束而回收，因此只能分配在堆上。 12345678910111213141516171819// main.gopackage mainimport &quot;fmt&quot;type Demo struct { name string}func createDemo(name string) *Demo { d := new(Demo) // 局部变量 d 逃逸到堆 d.name = name return d}func main() { demo := createDemo(&quot;demo&quot;) fmt.Println(demo)} 这个例子中，函数 createDemo 的局部变量 d 发生了逃逸。d 作为返回值，在 main 函数中继续使用，因此 d 指向的内存不能够分配在栈上，随着函数结束而回收，只能分配在堆上。 编译时可以借助选项 -gcflags=-m，查看变量逃逸的情况： 1go run -gcflags '-m' main.go 加 -l 了是为了不让Go 编译时自动内敛函数 1go run - gcflags '-m -l' escape . go 12# command-line-arguments./main.go:13:18: moved to heap: userInfo GetUserInfo函数里面的变量 userInfo 逃到堆上了（分配到堆内存空间上了）。GetUserInfo 函数的返回值为 *UserData 指针类型，然后 将值变量userInfo 的地址返回，此时编译器会判断该值可能会在函数外使用，就将其分配到了堆上，所以变量userInfo就逃逸了。 interface{} 动态类型逃逸在 Go 语言中，空接口即 interface{} 可以表示任意的类型，如果函数参数为 interface{}，编译期间很难确定其参数的具体类型，也会发生逃逸。 1234func main() { demo := createDemo(&quot;demo&quot;) fmt.Println(demo)} demo 是 main 函数中的一个局部变量，该变量作为实参传递给 fmt.Println()，但是因为 fmt.Println() 的参数类型定义为 interface{}，因此也发生了逃逸。 对于 Go 语言来说，运行时(runtime) 尝试在 goroutine 需要的时候动态地分配栈空间，goroutine 的初始栈大小为 2 KB。当 goroutine 被调度时，会绑定内核线程执行，栈空间大小最也不会超过操作系统的限制。对 Go 编译器而言，超过一定大小的局部变量将逃逸到堆上，不同的 Go 版本的大小限制可能不一样。 当切片占用内存超过一定大小，或无法确定当前切片长度时，对象占用内存将在堆上分配。 发生逃逸的几种情况 在某个函数中new或字面量创建出的变量，将其指针作为函数返回值，则该变量一定发生逃逸（构造函数返回的指针变量一定逃逸）； 被已经逃逸的变量引用的指针，一定发生逃逸； 被指针类型的slice、map和chan引用的指针，一定发生逃逸；一个典型的例子就是 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。 slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。 slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。 必然不会逃逸 指针被未发生逃逸的变量引用； 仅仅在函数内对变量做取址操作，而未将指针传出； 可能发生逃逸，也可能不会发生逃逸： 将指针作为入参传给别的函数；这里还是要看指针在被传入的函数中的处理过程，如果发生了上边的三种情况，则会逃逸；否则不会逃逸； 一些例子例1 12345678910111213package maintype S struct{}func main() { var x S y := &amp;x _ = *identity(y)}func identity(z *S) *S { return z} 1234 go run -gcflags '-m -l' main.go# command-line-arguments./main.go:10:15: leaking param: z to result ~r0 level=0 第一行是z变量是流经某个函数的意思，仅作为函数的输入，并且直接返回，在 identity()中也没有使用到 z的引用，所以变量没有逃逸。第二行， x在 main()函数中声明，所以是在 main()函数中的栈中的，也没有逃逸。 当然要是上面的例子，打印出 *identity(y) 的返回值，那肯定就是逃逸了。比如 例2 123456789101112131415package mainimport &quot;fmt&quot;type S struct{}func main() { var x S y := &amp;x c := *identity(y) fmt.Println(c)}func identity(z *S) *S { return z} 123456 go run -gcflags '-m -l' main.go# command-line-arguments./main.go:13:15: leaking param: z to result ~r0 level=0./main.go:11:13: ... argument does not escape./main.go:11:14: c escapes to heap 那是否是不引用返回值就不逃逸了呢。不，一样的逃逸的，看下面这个例子 例3 12345678910package maintype S struct{}func main() { var x S _ = *ref(x)}func ref(z S) *S { return &amp;z } 1234 go run -gcflags '-m -l' main.go# command-line-arguments./main.go:9:10: moved to heap: z ref()的参数 z是通过值传递的，所以 z是 main()函数中 x的一个值拷贝，而 ref()返回了 z的引用，所以 z不能放在 ref()的栈中，实际上被分配到了堆上。 例4 12345678910111213package maintype S struct{ M *int }func main() { var i int refStruct(&amp;i)}func refStruct(y *int) (z S) { z.M = y return z} 1234 go run -gcflags '-m -l' main.go# command-line-arguments./main.go:9:16: leaking param: y to result z level=0 这个 y没有逃逸的原因是， main()中带着 i的引用调用了 refStruct()并直接返回了，从来没有超过 main()函数的调用栈 例5 12345678910package maintype S struct{ M *int }func main() { var x S var i int ref(&amp;i, &amp;x)}func ref(y *int, z *S) { z.M = y } 1234# command-line-arguments./main.go:10:10: leaking param: y./main.go:10:18: z does not escape./main.go:7:6: moved to heap: i y和 z没有逃逸很好理解，但问题在于 y还被赋值到函数 ref()的输入 z的成员了，而Go的逃逸分析不能跟踪变量之间的关系，不知道 i变成了 x的一个成员，分析结果说 i是逃逸的，但本质上 i是没逃逸的 例6 interface类型逃逸 123456789package mainimport &quot;fmt&quot;func main() { str := &quot;str&quot; fmt.Printf(&quot;%p&quot;, &amp;str)} 1234# command-line-arguments./main.go:6:2: moved to heap: str./main.go:7:12: ... argument does not escape str也逃逸到了堆上，在堆上进行内存分配，这是因为访问str的地址，因为入参是interface类型，所以变量str的地址以实参的形式传入fmt.Printf后被装箱到一个interface{}形参变量中，装箱的形参变量的值要在堆上分配，但是还要存储一个栈上的地址，也就是str的地址，堆上的对象不能存储一个栈上的地址，所以str也逃逸到堆上，在堆上分配内存。 例7 闭包发生的逃逸 123456789101112func Increase() func() int { n := 0 return func() int { n++ return n }}func main() { in := Increase() fmt.Println(in()) // 1} 123456# command-line-arguments./main.go:6:2: moved to heap: n./main.go:7:9: func literal escapes to heap./main.go:15:13: ... argument does not escape./main.go:15:16: in() escapes to heap 函数也是一个指针类型，所以匿名函数当作返回值时也发生了逃逸，在匿名函数中使用外部变量n，这个变量n会一直存在直到in被销毁，所以n变量逃逸到了堆上。 例8 变量大小不确定以及栈空间不足引发逃逸 先使用ulimit -a查看操作系统的栈空间： 123456789-t: cpu time (seconds) unlimited-f: file size (blocks) unlimited-d: data seg size (kbytes) unlimited-s: stack size (kbytes) 8192-c: core file size (blocks) 0-v: address space (kbytes) unlimited-l: locked-in-memory size (kbytes) unlimited-u: processes 2784-n: file descriptors 256 我的电脑是mac，栈大小是8192 1234567891011121314151617181920212223242526272829303132333435package mainimport ( &quot;math/rand&quot;)func LessThan8192() { nums := make([]int, 8191) // &lt; 64KB for i := 0; i &lt; len(nums); i++ { nums[i] = rand.Int() }}func MoreThan8192(){ nums := make([]int, 8192) // = 64KB for i := 0; i &lt; len(nums); i++ { nums[i] = rand.Int() }}func NonConstant() { number := 10 s := make([]int, number) for i := 0; i &lt; len(s); i++ { s[i] = i }}func main() { NonConstant() MoreThan8192() LessThan8192()} 123456go run -gcflags '-m -l' main.go# command-line-arguments./main.go:8:14: make([]int, 100) does not escape./main.go:15:14: make([]int, 1000000) escapes to heap./main.go:23:11: make([]int, number) escapes to heap 当栈空间足够时，不会发生逃逸，但是当变量过大时，已经完全超过栈空间的大小时，将会发生逃逸到堆上分配内存。同样当我们初始化切片时，没有直接指定大小，而是填入的变量，这种情况为了保证内存的安全，编译器也会触发逃逸，在堆上进行分配内存。 例10 1234567891011121314151617package mainimport &quot;fmt&quot;type A struct { s string}// 这是上面提到的 &quot;在方法内把局部变量指针返回&quot; 的情况func foo(s string) *A { a := new(A) a.s = s return a //返回局部变量a,在C语言中妥妥野指针，但在go则ok，但a会逃逸到堆}func main() { a := foo(&quot;hello&quot;) b := a.s + &quot; world&quot; c := b + &quot;!&quot; fmt.Println(c)} 例11 变量类型不确定发生的逃逸 123456789package mainimport &quot;fmt&quot;func main() { a := 123 fmt.Println(a)} 123456go run -gcflags '-m -l' main.go# command-line-arguments./main.go:8:13: ... argument does not escape./main.go:8:14: a escapes to heap 变量a逃逸到了堆上。但是我们并没有外部引用，为什么也会有逃逸呢？为了看到更多细节，可以在语句中再添加一个-m参数。 12345678910111213 go run -gcflags '-m -m -l' main.go# command-line-arguments./main.go:7:14: a escapes to heap:./main.go:7:14: flow: {storage for ... argument} = &amp;{storage for a}:./main.go:7:14: from a (spill) at ./main.go:7:14./main.go:7:14: from ... argument (slice-literal-element) at ./main.go:7:13./main.go:7:14: flow: {heap} = {storage for ... argument}:./main.go:7:14: from ... argument (spill) at ./main.go:7:13./main.go:7:14: from fmt.Println(... argument...) (call parameter) at ./main.go:7:13./main.go:7:13: ... argument does not escape./main.go:7:14: a escapes to heap a逃逸是因为它被传入了fmt.Println的参数中，这个方法参数自己发生了逃逸。因为fmt.Println的函数参数为interface类型，编译期不能确定其参数的具体类型，所以将其分配于堆上。 源码位置 这里就暂时不贴了，可以链接过去直接看 大概就是说 片段中通过定义 labelState 常量和 func 方法来标记不需要增加循环深度的标签，并且给它们赋予 nonlooping 状态。 paramTag 函数，用于向函数参数添加逃逸分析信息。该函数首先获取参数名称，然后检查是否需要为当前函数生成诊断信息，以及该函数是否包含主体语句。 如果函数没有主体语句，则假定 uintptr 参数必须在调用期间保持活动状态，并设置 pragma 表示此信息。接着，如果参数类型不包含指针，则返回空字符串；否则，创建一个新的泄漏对象（leaks object）来表示参数可能逃逸的位置。如果函数被标记为“noescape”，则将堆位置添加到泄漏对象中；否则，在启用诊断的情况下生成一个警告并将堆位置添加到泄漏对象中。对于具有主体的函数，paramTag 函数从旧位置检索参数的现有逃逸分析信息，优化它，并将其分配给 leaks 变量。如果启用了诊断且参数没有逃逸，则会产生警告。如果参数逃逸到结果参数，则将显示带有逃逸级别的警告。最后，函数将泄漏对象编码为字符串并返回。 所以分析了这么多，函数传递指针真的比传值效率高吗？ 传递指针可以减少底层值的拷贝，可以提高效率，但是如果拷贝的数据量小，由于指针传递会产生逃逸，可能会使用堆，也可能会增加GC的负担，所以传递指针不一定是高效的。 如果想要减少垃圾回收的时间，提高程序性能，那就要尽量避免在堆上分配空间 总结一下 函数返回变量的指针时，这个变量会逃逸 当觉得栈上的空间不够时，会分配在堆上 在切片上存储指针或带指针的值的时候，对应的变量会逃逸 chan里面的元素是指针的时候，也会发生逃逸 map的value是指针的时候，也会发生逃逸 在interface类型上调用方法，也会发生逃逸 当给一个slice分配一个动态的空间容量时，也会发生逃逸 函数或闭包外声明指针，在函数或闭包内分配，也会发生逃逸 函数外初始化变量，函数内使用变量，然后返回函数，也会发生逃逸 被已经逃逸的指针引用的指针，也会发生逃逸 逃逸分析在编译阶段完成的 注意 go run -gcflags ‘-m -m -l’ xx.main 不一定100%对，详情参考 参考 逃逸分析优化性能的论文通过实例理解Go逃逸分析逃逸分析对性能的影响","link":"/2022/06/05/golang%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"title":"深入理解go map","text":"哈希函数哈希查找表一般会存在“碰撞”的问题，就是说不同的 key 被哈希到了同一个 bucket。一般有两种应对方法：链表法和开放地址法。链表法将一个 bucket 实现成一个链表，落在同一个 bucket 中的 key 都会插入这个链表。开放地址法则是碰撞发生后，通过一定的规律，在数组的后面挑选“空位”，用来放置新的 key。 1装载因子 := 元素数量 / 桶数量 与开放地址法一样，拉链法的装载因子越大，哈希的读写性能就越差，在一般情况下使用拉链法的哈希表装载因子都不会超过 1，当哈希表的装载因子较大时就会触发哈希的扩容，创建更多的桶来存储哈希中的元素，保证性能不会出现严重的下降。如果有 1000 个桶的哈希表存储了 10000 个键值对，它的性能是保存 1000 个键值对的 1/10，但是仍然比在链表中直接读写好 1000 倍。 Golang 使用的哈希算法 Golang 选择哈希算法时，根据 CPU 是否支持 AES 指令集进行判断 ，如果 CPU 支持 AES 指令集，则使用 Aes Hash，否则使用 memhash。 AES 指令集全称是高级加密标准指令集（或称英特尔高级加密标准新指令，简称AES-NI），是一个 x86指令集架构的扩展，用于 Intel 和 AMD 处理器。 利用 AES 指令集实现哈希算法性能很优秀，因为它能提供硬件加速。 查看 CPU 是否支持 AES 指令集： 123cat /proc/cpuinfo | grep aesflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt 处理哈希冲突 Golang 及多数编程语言都使用链地址法处理哈希冲突。 链地址法 链地址法链地址法是处理哈希冲突最常见的方法，它的实现比开放地址法稍微复杂一些，但平均查找长度较短，用于存储节点的内存是动态申请的，可以节省较多内存。 要将一个键值对 (Key6, Value6) 写入哈希表，需要经过两个步骤： 键值对中的键 Key6 先经过 Hash 算法计算，返回的哈希值定位到一个桶，选择桶的方式是对哈希值取模： 1index := hash(&quot;Key6&quot;) % array.len 遍历当前桶中的链表，在遍历链表的过程中会遇到以下两种情况： 121. 找到键相同的键值对，则更新键对应的值；2. 没有找到键相同的键值对，则在链表的末尾追加新键值对。 只有可比较的类型才能够作为Map中的key 数据结构Go中Map是一个KV对集合。底层使用hash table，用链表来解决冲突，出现冲突时，不是每一个Key都申请一个结构通过链表串起来，而是以bmap为最小粒度挂载，一个bmap可以放8个kv。 在哈希函数的选择上，会在程序启动时，检测 cpu 是否支持 aes，如果支持，则使用aes hash，否则使用memhash。 每个map的底层结构是hmap，是有若干个结构为bmap的bucket组成的数组。每个bucket底层都采用链表结构。 Go 语言运行时同时使用了多个数据结构组合表示哈希表，其中使用 hmap 结构体来表示哈希 12345678910111213141516171819202122232425262728293031323334type hmap struct { count int // 元素个数 flags uint8 // 用来标记状态 B uint8 // 扩容常量相关字段B是buckets数组的长度的对数 2^B noverflow uint16 // noverflow是溢出桶的数量，当B&lt;16时，为精确值,当B&gt;=16时，为估计值 hash0 uint32 // 是哈希的种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入 buckets unsafe.Pointer // 桶的地址 oldbuckets unsafe.Pointer // 旧桶的地址，用于扩容 nevacuate uintptr // 搬迁进度，扩容需要将旧数据搬迁至新数据，这里是利用指针来比较判断有没有迁移 extra *mapextra // 用于扩容的指针}type mapextra struct { overflow *[]*bmap oldoverflow *[]*bmap // nextOverflow holds a pointer to a free overflow bucket. nextOverflow *bmap}// A bucket for a Go map.type bmap struct { tophash [bucketCnt]uint8 // tophash用于记录8个key哈希值的高8位，这样在寻找对应key的时候可以更快，不必每次都对key做全等判断}//实际上编辑期间会动态生成一个新的结构体type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr} bmap 就是常说的“桶”，桶里面会最多装 8 个 key，这些 key之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果是“一类”的，在桶内，又会根据key计算出来的hash值的高8位来决定 key到底落入桶内的哪个位置（一个桶内最多有8个位置)。 当map的key和value都不是指针，并且 size都小于128字节的情况下，会把bmap标记为不含指针，这样可以避免gc时扫描整个hmap。 但是，bmap其实有一个overflow的字段，是指针类型的，破坏了 bmap 不含指针的设想，这时会把overflow移动到 hmap的extra 字段来。 如果初始化时生成了溢出桶,会放置到map的extra字段里去 12345678910111213141516171819func makemap(t *maptype, hint int, h *hmap) *hmap { ... B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h} 123456type mapextra struct { overflow *[]*bmap oldoverflow *[]*bmap // nextOverflow holds a pointer to a free overflow bucket. nextOverflow *bmap} 当 make 的 hint &lt;= 8 时，会直接在栈上分配一个 bucket，一个 bucket 可以存储8对 KV 当 make 的 hint &gt; 8 &amp;&amp; hint &lt;= 52 时，会在堆上分配 bucket，此时不会分配 overflow bucket 当 make 的 hint &gt; 52 时，会在堆上分配 bucket 和 overflow bucket bmap 是存放 k-v 的地方key 和 value 是各自放在一起的，并不是 key/value/key/value/... 这样的形式。源码里说明这样的好处是在某些情况下可以省略掉 padding 字段，节省内存空间。减少内存对齐的内存消耗 如果按照 key/value/key/value/... 这样的模式存储，那在每一个 key/value 对之后都要额外 padding 7 个字节；而将所有的 key，value 分别绑定到一起，这种形式 key/key/.../value/value/...，则只需要在最后添加 padding。 每个 bucket 设计成最多只能放 8 个 key-value 对，如果有第 9 个 key-value 落入当前的 bucket，那就需要再构建一个 bucket ，通过 overflow 指针连接起来。 这样随着哈希表存储的数据逐渐增多，会扩容哈希表或者使用额外的桶存储溢出的数据，不会让单个桶中的数据超过 8 个，不过溢出桶只是临时的解决方案，创建过多的溢出桶最终也会导致哈希的扩容。 插入过程12345678910111213141516func maplit(n *Node, m *Node, init *Nodes) { a := nod(OMAKE, nil, nil) a.Esc = n.Esc a.List.Set2(typenod(n.Type), nodintconst(int64(n.List.Len()))) litas(m, a, init) entries := n.List.Slice() if len(entries) &gt; 25 { ... return } // Build list of var[c] = expr. // Use temporaries so that mapassign1 can have addressable key, elem. ...} 当哈希表中的元素数量少于或者等于 25 个时，编译器会将字面量初始化的结构体转换成以下的代码，将所有的键值对一次加入到哈希表中： 1234hash := make(map[string]int, 3)hash[&quot;1&quot;] = 2hash[&quot;3&quot;] = 4hash[&quot;5&quot;] = 6 一旦哈希表中元素的数量超过了 25 个，编译器会创建两个数组分别存储键和值，这些键值对会通过如下所示的 for 循环加入哈希： 123456hash := make(map[string]int, 26)vstatk := []string{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, ... ， &quot;26&quot;}vstatv := []int{1, 2, 3, ... , 26}for i := 0; i &lt; len(vstak); i++ { hash[vstatk[i]] = vstatv[i]} 对 key 计算 hash 值，找到要赋值的位置（可能是插入新 key，也可能是更新老 key），对相应位置进行赋值。 函数首先会检查 map 的标志位 flags。如果 flags 的写标志位此时被置 1 了，说明有其他协程在执行“写”操作，进而导致程序 panic。这也说明了 map 对协程是不安全的。 不过因为 Go 语言哈希的扩容不是一个原子的过程，所以**mapassign**** 还需要判断当前哈希是否已经处于扩容状态，避免二次扩容造成混乱。** 在 B 不为 0 的情况下，会调用 makeBucketArray 函数初始化桶。 当 B &lt; 4 的时候，初始化 hmap 只会生成 8 个桶，不生成溢出桶，因为数据少几乎不可能用到溢出桶； 当 B &gt;= 4 的时候，会额外创建 2^(B−4) 个溢出桶。 Map有多种初始化的方式,如果指定了长度N,在初始化时会生成桶。桶的数量为log2(N).如果map的长度大于了2^4，则会在初始化的时候生成溢出桶。溢出桶的大小为2^(b-4),b为桶的大小。 遍历过程map 遍历的核心在于理解 2 倍扩容时，老 bucket 会分裂到 2 个新 bucket 中去。而遍历操作，会按照新 bucket 的序号顺序进行，碰到老 bucket 未搬迁的情况时，要在老 bucket 中找到将来要搬迁到新 bucket 来的 key。 查找keykey 经过 Hash 计算后得到 64 位哈希值（64位机器）； 用哈希值最后 B 个 bit 位计算它落在哪个桶； 用哈希值高 8 位计算它在桶中的索引位置。 删除过程mapdelete 函数。它首先会检查 h.flags 标志，如果发现写标位是 1，直接 panic，因为这表明有其他协程同时在进行写操作。 计算 key 的哈希，找到落入的 bucket。检查此 map 如果正在扩容的过程中，直接触发一次搬迁操作。 将 count 值减 1，将对应位置的 tophash 值置成 Empty。 同样需要计算出hash的前8位、指定的桶等。 如果在删除期间遇到了哈希表的扩容，就会分流桶中的元素，分流结束之后会找到桶中的目标元素完成键值对的删除工作。 如果查找到了指定的key,则会清空数据，hash位设置为emptyOne. 如果发现后面没有元素，则会设置为emptyRest,并循环向上检查前一个元素是否为空。 扩容过程1234567// 一个桶里最多可以装载的键值对数量：8对bucketCntBits = 3bucketCnt = 1 &lt;&lt; bucketCntBits// 触发扩容操作的装载因子临界值是：13 / 2 = 6.5loadFactorNum = 13loadFactorDen = 2 1loadFactor := count / (2^B) # count 就是 map 的元素个数，2^B 表示 bucket 数量。 触发 map 扩容的时机：在向 map 插入新 key 的时候，会进行条件检测，符合下面这 2 个条件，就会触发扩容： 装载因子超过阈值，源码里定义的阈值是 6.5。 翻倍扩容 哈希使用了太多溢出桶（造成这种现象的原因是不停地插入、删除元素） , overflow 的 bucket 数量过多：当 B 小于 15，也就是 bucket 总数 2^B 小于 2^15 时，如果 overflow 的 bucket 数量超过 2^B；当 B &gt;= 15，也就是 bucket 总数 2^B 大于等于 2^15，如果 overflow 的 bucket 数量超过 2^15。map的扩容不是一个原子的扩容，所以他虽然具备扩容条件，而先要判断该map是否处在扩容状态。 等量扩容 sameSizeGrow，等量扩容创建的新桶数量只是和旧桶一样，该函数中只是创建了新的桶，并没有对数据进行拷贝和转移 当溢出桶的数量过多,则会进行等量重建。新桶会会存储到buckets字段,旧桶会存储到oldbuckets字段。 map中extra字段的溢出桶也同理的进行了转移。 因为 Go 语言哈希的扩容不是一个原子的过程，所以 [runtime.mapassign](https://draveness.me/golang/tree/runtime.mapassign) 还需要判断当前哈希是否已经处于扩容状态，避免二次扩容造成混乱。 扩容的入口是 [runtime.hashGrow](https://draveness.me/golang/tree/runtime.hashGrow)： 1234567891011121314151617181920func hashGrow(t *maptype, h *hmap) { bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil h.extra.nextOverflow = nextOverflow} 哈希在扩容的过程中会通过 [runtime.makeBucketArray](https://draveness.me/golang/tree/runtime.makeBucketArray) 创建一组新桶和预创建的溢出桶，随后将原有的桶数组设置到 oldbuckets 上并将新的空桶设置到 buckets 上，溢出桶也使用了相同的逻辑更新 哈希在存储元素过多时会触发扩容操作，每次都会将桶的数量翻倍，扩容过程不是原子的，而是通过 [runtime.growWork](https://draveness.me/golang/tree/runtime.growWork) 增量触发的，在扩容期间访问哈希表时会使用旧桶，向哈希表写入数据时会触发旧桶元素的分流。除了这种正常的扩容之外，为了解决大量写入、删除造成的内存泄漏问题，哈希引入了 sameSizeGrow 这一机制，在出现较多溢出桶时会整理哈希的内存减少空间的占用。 扩容是渐进式的，如果 map 处在扩容的过程中，那么当 key 定位到了某个 bucket 后，需要确保这个 bucket 对应的老 bucket 完成了迁移过程。即老 bucket 里的 key 都要迁移到新的 bucket 中来（分裂到 2 个新 bucket），才能在新的 bucket 中进行插入或者更新的操作。 现在到了定位 key 应该放置的位置了，所谓找准自己的位置很重要。准备两个指针，一个（inserti）指向 key 的 hash 值在 tophash 数组所处的位置，另一个(insertk)指向 cell 的位置（也就是 key 最终放置的地址），当然，对应 value 的位置就很容易定位出来了。这三者实际上都是关联的，在 tophash 数组中的索引位置决定了 key 在整个 bucket 中的位置（共 8 个 key），而 value 的位置需要“跨过” 8 个 key 的长度。 在循环的过程中，inserti 和 insertk 分别指向第一个找到的空闲的 cell。如果之后在 map 没有找到 key 的存在，也就是说原来 map 中没有此 key，这意味着插入新 key。那最终 key 的安置地址就是第一次发现的“空位”（tophash 是 empty）。 如果这个 bucket 的 8 个 key 都已经放置满了，那在跳出循环后，发现 inserti 和 insertk 都是空，这时候需要在 bucket 后面挂上 overflow bucket。当然，也有可能是在 overflow bucket 后面再挂上一个 overflow bucket。这就说明，太多 key hash 到了此 bucket。 在正式安置 key 之前，还要检查 map 的状态，看它是否需要进行扩容。如果满足扩容的条件，就主动触发一次扩容操作。 这之后，整个之前的查找定位 key 的过程，还得再重新走一次。因为扩容之后，key 的分布都发生了变化。最后，会更新 map 相关的值，如果是插入新 key，map 的元素数量字段 count 值会加 1；在函数之初设置的 hashWriting 写标志出会清零。 再来看一下扩容具体是怎么做的。由于 map 扩容需要将原有的 key/value 重新搬迁到新的内存地址，如果有大量的 key/value 需要搬迁，会非常影响性能。因此 Go map 的扩容采取了一种称为“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket。 hashGrow() 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 growWork() 函数中，而调用 growWork() 函数的动作是在 mapassign 和 mapdelete 函数中。也就是插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil。 hashGrow() 函数所做的工作，再来看具体的搬迁 buckets 是如何进行的。 12345678910111213141516171819202122232425262728293031func hashGrow(t *maptype, h *hmap) { // B+1 相当于是原来 2 倍的空间 bigger := uint8(1) // 对应条件 2 if !overLoadFactor(int64(h.count), h.B) { // 进行等量的内存扩容，所以 B 不变 bigger = 0 h.flags |= sameSizeGrow } // 将老 buckets 挂到 buckets 上 oldbuckets := h.buckets // 申请新的 buckets 空间 newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger) flags := h.flags &amp;^ (iterator | oldIterator) if h.flags&amp;iterator != 0 { flags |= oldIterator } // 提交 grow 的动作 h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets // 搬迁进度为 0 h.nevacuate = 0 // overflow buckets 数为 0 h.noverflow = 0 // ……} 主要是申请到了新的 buckets 空间，把相关的标志位都进行了处理：例如标志 nevacuate 被置为 0， 表示当前搬迁进度为 0。 真正执行搬迁工作的 growWork() 函数。 123456789func growWork(t *maptype, h *hmap, bucket uintptr) { // 确认搬迁老的 bucket 对应正在使用的 bucket evacuate(t, h, bucket&amp;h.oldbucketmask()) // 再搬迁一个 bucket，以加快搬迁进程 if h.growing() { evacuate(t, h, h.nevacuate) }} map为什么是无序的map 在扩容后，会发生 key 的搬迁，原来落在同一个 bucket 中的 key，搬迁后，有些 key 就要远走高飞了（bucket 序号加上了 2^B）。而遍历的过程，就是按顺序遍历 bucket，同时按顺序遍历 bucket 中的 key。搬迁后，key 的位置发生了重大的变化，有些 key 飞上高枝，有些 key 则原地不动。这样，遍历 map 的结果就不可能按原来的顺序了。 在遍历 map 时，并不是固定地从 0 号 bucket 开始遍历，每次都是从一个随机值序号的 bucket 开始遍历，并且是从这个 bucket 的一个随机序号的 cell 开始遍历。这样，即使你是一个写死的 map，仅仅只是遍历它，也不太可能会返回一个固定序列的 key/value 对了。 “迭代 map 的结果是无序的”这个特性是从 go 1.0 开始加入的。 1234567891011...// decide where to startr := uintptr(fastrand())if h.B &gt; 31-bucketCntBits { r += uintptr(fastrand()) &lt;&lt; 31}it.startBucket = r &amp; bucketMask(h.B)it.offset = uint8(r &gt;&gt; h.B &amp; (bucketCnt - 1))// iterator stateit.bucket = it.startBucket 可以边遍历边删除吗map 并不是一个线程安全的数据结构。同时读写一个 map 是未定义的行为，如果被检测到，会直接 panic。 上面说的是发生在多个协程同时读写同一个 map 的情况下。 如果在同一个协程内边遍历边删除，并不会检测到同时读写，理论上是可以这样做的。但是，遍历的结果就可能不会是相同的了，有可能结果遍历结果集中包含了删除的 key，也有可能不包含，这取决于删除 key 的时间：是在遍历到 key 所在的 bucket 时刻前或者后。 一般而言，这可以通过读写锁来解决：sync.RWMutex。 读之前调用 RLock() 函数，读完之后调用 RUnlock() 函数解锁；写之前调用 Lock() 函数，写完之后，调用 Unlock() 解锁。 另外，sync.Map 是线程安全的 map，也可以使用。 可以对map元素取地址么不可以，因为一旦发生扩容，key 和 value 的位置就会改变，之前保存的地址也就失效了。 map是线程安全的吗在查找、赋值、遍历、删除的过程中都会检测写标志，一旦发现写标志置位（等于1），则直接 panic。赋值和删除函数在检测完写标志是复位之后，先将写标志位置位，才会进行之后的操作。 删除掉map中的元素是否会释放内存？ 不会，删除操作仅仅将对应的tophash[i]设置为empty，并非释放内存。若要释放内存只能等待指针无引用后被系统gc 参考 面向信仰编程深入Go的Map使用和实现原理Go中的map的实现map的实现原理","link":"/2020/07/11/go-map/"},{"title":"kafka 基本术语","text":"​ Apache Kafka 是一款开源的消息引擎系统，也是分布式流处理平台，使用的是纯二进制的字节序列。 ​ kafka术语​Topic: 发布订阅的对象是主题（Topic） 生产者程序通常持续不断地向一个或多个主题发送消息 Producer: 向主题发布消息的客户端应用程序称为生产者（Producer） Consumer: 订阅这些主题消息的客户端应用程序就被称为消费者（Consumer） Broker: Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果集群中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务。这其实就是 Kafka 提供高可用的手段之一。分区的leader副本只存在于其中一个broker中 实现高可用的另一个手段就是备份机制（Replication）。备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在 Kafka 中被称为副本（Replica）。 副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。 Kafka 定义了两类副本：领导者副本（Leader Replica）和追随者副本（Follower Replica）。前者对外提供服务，这里的对外指的是与客户端程序进行交互；而后者只是被动地追随领导者副本而已，不能与外界进行交互。 副本的工作机制：生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。通过副本选举实现故障转移。 分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。（修改分区数一定要比原有分区数大）一个topic 可以拥有若干个partition（从 0 开始标识partition ），分布在不同的broker 上， 实现发布与订阅时负载均衡。producer 通过自定义的规则将消息发送到对应topic 下某个partition，以offset标识一条消息在一个partition的唯一性。 一个partition拥有多个replica，提高容灾能力。 **Kafka 中的分区机制 **指的是将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。生产者生产的每条消息只会被发送到一个分区中​在Kafka中，一个Partition对应物理机器上的一个文件夹，文件夹命名会以Topic名称加序号表示。换句话说，Partition在Broker中以文件夹的形式存在。每个Partition文件夹中会有多个大小相等的日志段文件（Segment File），消息生产者生产的消息发送到Broker后就会以追加到日志文件末尾的方式持久化到Partition中。 如果在Kafka运行时调整Topic的Partition数量，会直接影响Message根据Key的顺序问题。如果调整Replication数量，会给集群带来较大的性能压力，因为涉及到Zookeeper要重新选举Leader一系列操作。 副本如何与这里的分区联系在一起呢？ 实际上，副本是在分区这个层级定义的。每个分区下可以配置若干个副本，其中只能有 1 个领导者副本和 N-1 个追随者副本。生产者向分区写入消息，每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表征。分区位移总是从 0 开始，假设一个生产者向一个空分区写入了 10 条消息，那么这 10 条消息的位移依次是 0、1、2、…、9。 ​消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。 ​Kafka 的三层消息架构： ​第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。 ​第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。 第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。 ​Kafka体系架构 = M个producer +N个broker +K个consumer+ZK集群 消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。 ​重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。 ​ 一个topic 可以让若干个consumer消费，若干个consumer组成一个 consumer group ，一条消息只能被consumer group 中一个consumer消费，若干个partition 被若干个consumer 同时消费，达到消费者高吞吐量 当创建topic的时候Kafka会保证所有副本均匀地在broker上保存。 ​两种消息模型，即点对点模型（Peer to Peer，P2P）和发布订阅模型。这里面的点对点指的是同一条消息只能被下游的一个消费者消费，其他消费者则不能染指。在 Kafka 中实现这种 P2P 模型的方法就是引入了消费者组（Consumer Group）。所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。为什么要引入消费者组呢？主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。另外这里的消费者实例可以是运行消费者应用的进程，也可以是一个线程，它们都称为一个消费者实例（Consumer Instance）。 消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且它们还能彼此协助。假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。 每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset）。注意，这和上面所说的位移完全不是一个概念。上面的“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。而消费者位移则不同，它可能是随时变化的，毕竟它是消费者消费进度的指示器嘛。另外每个消费者有着自己的消费者位移，因此一定要区分这两类位移的区别。消息在分区中的位移称为分区位移，而把消费者端的位移称为消费者位移。 ​ ​","link":"/2020/04/11/kafka%E5%9F%BA%E6%9C%AC/"},{"title":"go规范","text":"1 . 多个 if 语句可以折叠成 switch123456789101112131415161718// NOT BADif foo() { // ...} else if bar == baz { // ...} else { // ...}// BETTERswitch {case foo(): // ...case bar == baz: // ...default: // ...} 2 . 用 chan struct{} 来传递信号, chan bool 表达的不够清楚当你在结构中看到 chan bool 的定义时，有时不容易理解如何使用该值，例如： 123type Service struct { deleteCh chan bool // what does this bool mean? } 但是我们可以将其改为明确的 chan struct {} 来使其更清楚：我们不在乎值（它始终是 struct {}），我们关心可能发生的事件，例如： 123type Service struct { deleteCh chan struct{} // ok, if event than delete something.} 3 . time.Second 比 time.Duration(30) * time.Second 更好你不需要将无类型的常量包装成类型，编译器会找出来。另外最好将常量移到第一位： 12345// BADdelay := time.Second * 60 * 24 * 60// GOODdelay := 24 * 60 * 60 * time.Second 4 . 用 time.Duration 代替 int64 + 变量名12345// BADvar delayMillis int64 = 15000// GOODvar delay time.Duration = 15 * time.Second 5. 按类型分组 const 声明，按逻辑和/或类型分组 var12345678910111213141516171819// BADconst ( foo = 1 bar = 2 message = &quot;warn message&quot;)// MOSTLY BADconst foo = 1const bar = 2const message = &quot;warn message&quot;// GOODconst ( foo = 1 bar = 2)const message = &quot;warn message&quot; 6 要比较时间戳，请使用 time.Before 或 time.After ，不要使用 time.Sub 来获得 duration (持续时间)，然后检查它的值。7. 用 %+v 来打印数据的比较全的信息8. 在 Go 里面要小心使用 range12for i := range a and for i, v := range &amp;a ，都不是 a 的副本但是 for i, v := range a 里面的就是 a 的副本 9. 不要忘记停止 ticker12ticker := time.NewTicker(1 * time.Second)defer ticker.Stop() 10.所有代码都应该通过golint和go vet的检查并无错误。11. 零值 sync.Mutex 和 sync.RWMutex 是有效的。所以指向 mutex 的指针基本是不必要的。12var mu sync.Mutexmu.Lock() 12. Channel 的 size 要么是 1，要么是无缓冲的12c := make(chan int, 1)c := make(chan int) 13. 枚举从 1 开始1234567type Operation intconst ( Add Operation = iota + 1 Subtract Multiply) 14. 使用 time.Time 表达瞬时时间在处理时间的瞬间时使用 [time.Time](https://golang.org/pkg/time/#Time)，在比较、添加或减去时间时使用 time.Time 中的方法。 123func isActive(now, start, stop time.Time) bool { return (start.Before(now) || start.Equal(now)) &amp;&amp; now.Before(stop)} 15. 在尽可能的情况下，在初始化要追加的切片时为make()提供一个容量值。16. 优先使用 strconv 而不是 fmt17. 包命名 全部小写。没有大写或下划线。 大多数使用命名导入的情况下，不需要重命名。 简短而简洁。请记住，在每个使用的地方都完整标识了该名称。 不用复数。例如net/url，而不是net/urls。 不要用“common”，“util”，“shared”或“lib”。这些是不好的，信息量不足的名称。 18. 嵌入式类型（例如 mutex）应位于结构体内的字段列表的顶部，并且必须有一个空行将嵌入式字段与常规字段分隔开。19. 不应明确返回长度为零的切片。应该返回nil 来代替。20. 要检查切片是否为空，请始终使用len(s) == 0。而非 nil。21. time.After() 在某些情况下会发生泄露，替换为使用 Timer。22. 读写磁盘时，使用读写 buffer。23. 内存分配复用内存可以使用 sync.Pool24. 频繁的字符串拼接操作（+=），替换为 StringBuffer 或 StringBuilder25. 并发检测 race","link":"/2019/03/12/go%E8%A7%84%E8%8C%83/"},{"title":"vim技巧","text":"目录简介小技巧启动及关闭教程篇文本编辑文本编辑的高效命令other 简介得益于 vim 的指法，敲起代码来如行云流水。不管是不是写代码，学好vim 指法相当重要，当然最重要的还是为了效率，节省时间做更多其他的事。 小技巧“工欲善其事，必先利其器”。在 Vi/Vim 版本的选择上，原则是“能用 Vim 就不要使用 Vi”。Vim 提供的功能和特性要比 Vi 多得多，如语法加亮着色功能等。就使用效果及效率来说，编辑同样的文件，使用 Vim 更胜一筹；就版本来说，新版的往往会修复旧版的一些缺陷及不足。这就要求我们在可能的情况下一定要使用最新版的 Vim。 启动及关闭 退出 ZQ 无条件退出 q!无条件退出 ZZ 存盘并退出 :wq 存盘并退出 保存部分文件 :m,nw &lt; file&gt;将 m 行到 n 行部分的内容保存到文件 中 :m,nw &gt;&gt; 将 m 行到 n 行的内容添加到文件 的末尾 保存文件 :w 教程篇默认的 vim 是没有显示行数的，可自行在 vim 配置文件里开启(自行Google) Vi/Vim 中操作单位有很多，按从小到大的顺序为（括号内为相应的操作命令）：字符（h、l）→ 单词 (w、W、b、B、e) → 行 (j、k、0、^、$、:n) → 句子（(、)）→ 段落（{、}）→ 屏 (H、M、L) → 页（Ctrl-f、Ctrl-b、Ctrl-u、Ctrl-d) → 文件（G、gg、:0、:$）。 字符 h左移一位,l右移一位 单词 w/W 移动到下一单词的开头 b/B 移动到上一单词的开头 e/E 移动到光标所在单词的末尾 f 快速移动到下一个字符的位置 行 j 下移一行 k 上移一行 0 移到当前行开头 ^ 移到当前行的第一个非空字符 $ 移到当前行末尾 :n 移动到第 n 行 句子 ) 移动到当前句子的末尾 ( 移动到当前句子的开头 段落 } 移动当前段落的末尾 { 移到当前段落的开头 屏 H 移动到屏幕的第一行 M 移动到屏幕的中间一行 L 移动到屏幕的最后一行 页 Ctrl-f 向前滚动一页 Ctrl-b 向后滚动一页 Ctrl-u向前滚动半页 Ctrl-d 向后滚动半页 文件 G 移动到文件末尾 gg 移动到文件开头 :0移动到文件第一行 :$ 移动到文件最后一行 文本编辑 与光标移动一样，Vi/Vim 中关于编辑操作的命令也比较多，但操作单位要比移动光标少得多。按从小到大的顺序为（括号内为相应的操作命令）：字符 （x、c、s、r、i、a）→ 单词 (cw、cW、cb、cB、dw、dW、db、dB) → 行 (dd、d0、d$、I、A、o、O) → 句子（(、)）→ 段落（{、}）。这些操作单位有些可以加操作次数。操作对象的范围计算公式为：操作范围 = 操作次数 * 操作单位。比如：d3w 命令删除三个单词，10dd 命令删除十行。 字符 x 删除光标位置的字符 c 更改当前字符并进入插入模式 s 替换光标位置的字符并进入插入模式 r 替换光标位置的字符但不进入插入模式 i 在当前位置的字符之前进入插入模式 a 在当前位置的字符之后进入插入模式 单词 cw/cW 删除当前单词从光标开始的部分并进入插入模式 cb/cB 删除当前单词从光标所在位置至单词开始的部分并进入插入模式 dw/dW 删除当前单词从光标开始的部分但不进入插入模式 db/dB 删除当前单词从光标所在位置至单词开始的部分但不进入插入模式 行 dd 删除当前行 d0 删除从当前光标开始到行末的内容 d$ 删除从当前光标开始到行末的内容 I 在当前行的行首进入插入模式 A 在当前行的行尾进入插入模式 o 在当前行下方另起一行进入插入模式 O 在当前行上方另起一行进入插入模式 句子 d) 删除当前句子从光标位置开始到句末的内容 d( 删除当前句子从光标位置开始到句首的内容 段落 d} 删除当前段落从光标位置开始到段末的内容 d{ 删除当前段落从光标位置开始到段首的内容 文本编辑的高效命令 复制与粘贴 yw 复制当前单词从光标开始的部分 yy 复制光标所在行的所有字符 p 将最后一个删除或复制文本放在当前字符 P 将最后一个删除或复制文本放在当前字符之前 撤消与重做 u 撤消更改 Ctrl-R 重做更改 重复操作 .重复上次操作 交换相邻字符或行 xp 交换光标位置的字符和它右边的字符 ddp 交换光标位置的行和它的下一行 大小写转换 ~ 将光标下的字母大小写反向转换 guw 将光标所在的单词变为小写 guw 将光标所在的单词变为小写 gUw 将光标所在的单词变为大写 guu 光标所在的行所有字符变为小写 gUU 光标所在的行所有字符变为大写 g~~ 光标所在的行所有字符大小写反向转换 排序 :1,$!sort 将文件内的所有内容排序 other先定单位再定量 操作对象的范围计算公式为：操作范围 = 操作次数 * 操作单位。比如：5h 命令左移 5 个字符，8w 命令右移 8 个单词。","link":"/2019/06/01/vim%20%E6%8A%80%E5%B7%A7/"},{"title":"关于iframe跨域传输","text":"至于我为什么想写这篇文章是因为最近在项目中使用到了iframe，是的。生无可恋的又写上了一点js，可能是因为前端的人对单点登录啥的或者是页面跳转以及要和后端的逻辑处理起来不是很熟练吧。各大网站，包括淘宝，京东，这些大网站有很多自己的产品，至于前期是怎么样的不是很清楚，网易云至少是用的iframe。参考了一些博客，至于使用不使用iframe，我觉得能解决问题就好，而且如果考虑的多的话就考虑以后扩展以及拆分啥的，毕竟前端又不像后端这样。 因为要解决跨域问题。有很多方案，比如说iframe，jsonp(不过只支持get，对于一些铭感信息就不行了) 原本需求是登录在一个站点，而注册是另外一个站点。因为要实时反馈到iframe子页面，子页面在进行相应。 而在Windows对象下有个postMessage方法，是解决跨越问题的假设有两个不同源的页面，iframe.html和index.html 其中前者是后者的子页面。 123456789&lt;!-- index.html --&gt;&lt;body&gt; &lt;h1&gt;this is index&lt;/h1&gt; &lt;iframe src=&quot;./iframePage.html&quot; id='iframe'&gt;&lt;/iframe&gt;&lt;/body&gt; 1234567&lt;!-- iframePage --&gt;&lt;body&gt; &lt;h1&gt;this is iframePage&lt;/h1&gt;&lt;/body&gt; 现在这两个是无法通信的，因为是不同的站点，所以这个时候就要用到postMessage 123456789101112// idnex.html//获取iframe元素,当然也可以使用其他的js框架iFrame = document.getElementById('iframe')//iframe加载完毕后再发送消息，否则子页面接收不到messageiFrame.onload = function(){ //iframe加载完立即发送一条消息 iFrame.contentWindow.postMessage('MessageFromIndex1','*');} 我们知道postMessage是挂载在window对象上的，所以等iframe加载完毕后，用iFrame.contentWindow获取到iframe的window对象，然后调用postMessage方法，相当于给子页面发送了一条消息。 postMessage方法第二个参数可以设置要发送到哪个url，如果当前子页面的url和设置的不一致，则会发送失败，因为没啥限制就设置为*，代表所有url都允许发送。 消息发送到iframePage.html，我们来接收message 12345678910// iframePage.html//回调函数function receiveMessageFromIndex ( event ) { console.log( 'receiveMessageFromIndex', event )}//监听message事件window.addEventListener(&quot;message&quot;, receiveMessageFromIndex, false); 然后设置好回调函数，就可以了，data中或许还有其他的数值，所以在接受的时候判断一下。","link":"/2018/07/31/%E5%85%B3%E4%BA%8Eiframe%E8%B7%A8%E5%9F%9F%E4%BC%A0%E8%BE%93/"},{"title":"内存对齐","text":"内存对齐 内存CPU要想从内存读取数据，需要通过地址总线，把地址传输给内存，内存准备好数据，输出到数据总线若是32位地址总线，可以寻址[0,2的32次方-1]，占用内存4g有些CPU是能够支持访问任意地址的，它是做了很多处理，比如想从地址1读取8字节的数据，CPU会分2次读，第一次从0-7,只取后7字节，第二次从8-15，但只取第一字节。把2次结果拼接起来拿到所需数据。这样比较耗费性能，编译器会把各种类型的值安排到合适的位置，并占用合适的长度。每种类型的对齐边值就是它的对齐边界。int16（2），int32（4），内存对齐要求数据存储地址以及占用的字节数都是它对齐边界的倍数。 内存对齐的收益 提高代码平台兼容性 优化数据对内存的使用 避免一些内存不对齐带来的坑 有助于一些源码的阅读 为什么要对齐列举一些常见的单位 位 bit 计算机内存数据存储的最小单位 字节 byte 计算机数据处理的基本单位 机器字 machine word 计算机用来一次性处理事务的一个固定长度 平台原因 某些硬件平台只能在某些地址处取某些特定类似的数据 性能原因 数据结构应该尽可能地在自然边界上对齐，为了访问未对齐的内存，处理器需要作2次内存访问，而内存对齐就只需要一次访问 64位字的安全访问保证 在x86-32上，64位函数使用Pentium MMX之前不存在的指令。在非Linux ARM上，64位函数使用ARMv6k内核之前不可用的指令 在ARM、x86-32和32MIPS上，调用方有责任安排对原子访问的64位字对齐。变量或分配的结构、数组或切片中的第一个字(word)可以依赖当做是64位对齐的(摘抄的,不是太懂) 操作系统的cpu不是一个字节一个字节访问的，而是2，4，8这样的字长来访问的 处理器从存储器子系统读取数据至寄存器，或者，写寄存器数据到存储器，传送的数据长度通常是字长。 如何确定每种类型的对齐边界？ 和平台有关 go语言支持这些平台 archName PtrSize(指针宽度) RegSize(寄存器宽度) 386 4 8 amd64 8 8 arm 4 4 arm64 5 8 …… 被Go语言称为寄存器宽度的这个值，就可以理解为机器字长，也是平台对应的最大对齐边界，而数据类型的对齐边界是取类型大小与平台最大对齐边界中的较小的那个 类型 大小 RegSize int8 1 byte 8 byte int16 2 byte 8 byte int32 4 byte 8 byte int64 8 byte 8 byte string 16 byte 8 byte slice 24 byte 8 byte … … … 同一个类型在不同平台上的大小可能不同，不按照最大对齐边界或者最小对齐边界来考虑是为了减少浪费、提高性能如何确定一个结构体的对齐边界先确定每个成员的对齐边界，然后取最大值 123456789type T stract { a int8 1 byte b int64 8 byte c int32 4 byte 最大对齐 8 byte d int16 2 byte } 内存对齐的第一个要求、存储这个结构体的起始地址是对齐边界的整数倍第一个成员a,它要对齐到1字节，而这里是相对地址0，所以直接放这里，然后是第二个成员b,它要对齐到8字节，但是接下来的地址对8取模不等于0,所以要往后移。接下来是c，它要对齐到4字节。所有成员放好还不算完，内存对齐的第二个要求是结构体整体占用字节数需要是类型对齐边界的整数倍，不够的话要往后扩张。所以要扩充到相当地址23这里。最终这个结构体类型的大小就是24字节为啥要限制类型大小等于其对其边界的整数倍 ？假如不扩张到对齐边界的整数倍，这个结构体大小就是22字节，如果要使用长度为2的T类型数组，按照元素类型大小，会占用44字节，就会导致于第二个元素并没有内存对齐所以只有每个结构体的大小是对齐值的整数倍，才能保证数组中的每一个都是内存对齐的内存对齐的第二个要求：结构体整体占用字节数需要是类型对齐边界的倍数，不够的话要往后扩张一下举个特例 1234567891011121314151617type T1 struct { a struct{} x int64}type T2 struct { x int64 a struct{}}a1 := T1{}a2 := T2{}fmt.Printf(&quot;zone size struct{} of T1 size:%d,Ts(as final field) size:%d&quot;, unfafe.Sizeof(a1), // 8 unfafe.Sizeof(a2), // 64位，16；32位：12) T2可能做了一个Padding(填充)，因为在边界，可能会对一些边界的值进行引用等特殊：struct{} 和[0]T{} 的大小为0; 不同的大小为0的变量可能指向同一块地址。 零大小字段对齐零大小字段（zero sized field）是指struct{}大小为0，按理作为字段时不需要对齐，但当在作为结构体最后一个字段（final field）时需要对齐的。为什么？因为，如果有指针指向这个final zero field, 返回的地址将在结构体之外（即指向了别的内存），如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）使用 golangci-lint 检测对齐golangci-lint run –disable-all -E maligned 结论 内存对齐是为了cpu更高效的访问内存中的数据 结构体对齐依赖类型的大小保证和对齐保证 地址对齐保证是:如果类型t的对齐保证是n，那么类型t的每个值的地址在运行时必须是n的倍数 零大小字段要避免只作为struct最后一个字段，会有内存浪费 参考 【Golang】这个内存对齐呀！？ Golang 是否有必要内存对齐？ Go 的内存对齐和指针运算详解和实践","link":"/2020/08/11/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/"},{"title":"关于生成订单号规则的一些思考","text":"关于我为什么写这篇文章是因为今天在做订单模块的时候,看到之前的PRD上描述的订单生成规则是由 年月日＋用户id2位+企业id位＋四位自增长数。然后竟被我反驳的突然改成了精确时间＋4位自增长数，于是我更失望了。 我们考虑一下，据我所常见的订单基本都14-20位。(年月日时分秒和随机数)基本上就有14位了。虽然一般项目做不到淘宝双11这种支付峰值达到每秒10万笔订单.但是我觉得至少事先可以考虑到，想必当初淘宝或许也没意识到以后发展得这么好。 背景为了达到业务订单的生成。我觉得要至少要符合以下这三种, 全局唯一 一定不能重复 在复杂的分布式系统中，很多场景需要的都是全局唯一ID的场景，一般为了防止冲突可以考虑的有36位的UUID,twitter的snowflake等。 但是可以思考这些问题？ 是不是应该有一些其他意义的思考，比如说订单系统有买家的id(取固定几位) 是否有商品的标识,方便熟悉业务的排查问题或者查询也通过不去系统查找可以有个初步的认识，但是业务量大的话感觉就可以排除这个人为的去辨识了。 个人的看法是主要是唯一，其他关于业务方面的不是太太重要。 查阅了相关资料，主要有以下这几种 UUID, 组成：当前日期+时间+时钟序列+机器识别号（Mac地址或其他）没有mac网卡的话会有别的东西识别。在分布式系统中，所有元素（WEB服务器）都不需要通过中央控制端来判断数据唯一性。几十年之内可以达到全球唯一性。 snowflake的结构如下(每部分用-分开): Mysql通过AUTO_INCREMENT实现、Oracle通过Sequence序列实现。在数据库集群环境下，不同数据库节点可设置不同起步值、相同步长来实现集群下生产全局唯一、递增ID Snowflake算法 雪花算法 41位时间戳+10位机器ID+12位序列号（自增） 转化长度为18位的长整型。 Twitter为满足美秒上万条消息的创建，且ID需要趋势递增，方便客户端排序。 Snowflake虽然有同步锁，但是比uuid效率高。 Redis自增ID 实现了incr(key)用于将key的值递增1，并返回结果。如果key不存在，创建默认并赋值为0。 具有原子性，保证在并发的时候。 但是我在这主要想说的是雪花算法生成id,至于为什么，就测试了一下其他的，感觉这种生成方式个人比较喜欢。 Snowflake算法规则如下 使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 该算法实现基本是二进制操作。 一共加起来刚好64位，为一个Long型。(转换成字符串长度为18) snowflake生成的ID整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞（由datacenter和workerId作区分），并且效率较高。据说：snowflake每秒能够产生26万个ID。 以下是代码部分借鉴与网络100万个ID 耗时２秒 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130/** * Created by youze on 18-7-5 */public class IdWorker { /** * 起始的时间戳 */ private final static long START_STMP = 1530795377086L; /** * 每一部分占用的位数 */ /** * 序列号占用的位数 */ private final static long SEQUENCE_BIT = 12; /** * 机器标识占用的位数 */ private final static long MACHINE_BIT = 5; /** * 数据中心占用的位数 */ private final static long DATACENTER_BIT = 5; /** * 每一部分的最大值 */ private final static long MAX_DATACENTER_NUM = -1L ^ (-1L &lt;&lt; DATACENTER_BIT); private final static long MAX_MACHINE_NUM = -1L ^ (-1L &lt;&lt; MACHINE_BIT); private final static long MAX_SEQUENCE = -1L ^ (-1L &lt;&lt; SEQUENCE_BIT); /** * 每一部分向左的位移 */ private final static long MACHINE_LEFT = SEQUENCE_BIT; private final static long DATACENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT; private final static long TIMESTMP_LEFT = DATACENTER_LEFT + DATACENTER_BIT; /** * 数据中心 */ private long datacenterId; /** * 机器标识 */ private long machineId; /** * 序列号 */ private long sequence = 0L; /** * 上一次时间戳 */ private long lastStmp = -1L; public IdWorker(long datacenterId, long machineId) { if (datacenterId &gt; MAX_DATACENTER_NUM || datacenterId &lt; 0) { throw new IllegalArgumentException(&quot;datacenterId can't be greater than MAX_DATACENTER_NUM or less than 0&quot;); } if (machineId &gt; MAX_MACHINE_NUM || machineId &lt; 0) { throw new IllegalArgumentException(&quot;machineId can't be greater than MAX_MACHINE_NUM or less than 0&quot;); } this.datacenterId = datacenterId; this.machineId = machineId; } /** * 产生下一个ID * @return */ public synchronized long nextId() { long currStmp = getNewstmp(); if (currStmp &lt; lastStmp) { throw new RuntimeException(&quot;Clock moved backwards. Refusing to generate id&quot;); } if (currStmp == lastStmp) { //相同毫秒内，序列号自增 sequence = (sequence + 1) &amp; MAX_SEQUENCE; //同一毫秒的序列数已经达到最大 if (sequence == 0L) { currStmp = getNextMill(); } } else { //不同毫秒内，序列号置为0 sequence = 0L; } lastStmp = currStmp; return ( //时间戳部分 currStmp - START_STMP) &lt;&lt; TIMESTMP_LEFT //数据中心部分 | datacenterId &lt;&lt; DATACENTER_LEFT //机器标识部分 | machineId &lt;&lt; MACHINE_LEFT //序列号部分 | sequence; } private long getNextMill() { long mill = getNewstmp(); while (mill &lt;= lastStmp) { mill = getNewstmp(); } return mill; } private long getNewstmp() { return System.currentTimeMillis(); } public static void main(String[] args) { IdWorker snowFlake = new IdWorker(2, 3); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 1000000; i++) { System.out.println(snowFlake.nextId()); } System.out.println(System.currentTimeMillis() - start); }} 最后大家可以看这也有更详细的解释","link":"/2018/08/10/%E5%85%B3%E4%BA%8E%E7%94%9F%E6%88%90%E8%AE%A2%E5%8D%95%E5%8F%B7%E8%A7%84%E5%88%99%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"title":"分析MySQL中隐式转换导致查询结果错误及索引不可用","text":"以下是例子 1SELECT * FROM TABLE WHERE xxx = 11 如果列xxx确实只有11的，你是否就认为筛选出来的就一定只有xxx=11的呢？ 在过滤字段为数值类型的时候，数值类型有一种隐式转换，如果是以数字开头的，包含有字符，后面的字符会被截断，只取前面的数字值。 以下也均为测试数据 当执行 1explain select * from business_flow where business_flow_id = 268805964457574426 看输出会出现这段话 Cannot use ref access on index ‘xxx’ due to type or collation conversion on field ‘business_flow_id’ 当过滤的字段是字符类型的时候，没有使用到索引，走的全表扫描； 所以还是可以查询出结果来的，因为无法使用索引，所以查询出来的结果也是错的。 既然发现查询出来的结果是有误差的，所以猜测用字符串’xxx’和xxy比较应该是相等的。 1select '268805964457574426' =268805964457574421 果不其然，也能查询出 去查询了下其他的 过滤字段为浮点类型，也会比较近似的，将导致结果看起来不一致，也就是可能导致查询结果错误 当MySQL遇到字段类型不匹配的时候，会进行各种隐式转化 所以在查询过滤的时候，一定要注意过滤字段的类型。可能会导致查询慢，甚至会导致错误结果。 官方说是隐式转换 参考","link":"/2019/10/11/%E5%88%86%E6%9E%90MySQL%E4%B8%AD%E9%9A%90%E5%BC%8F%E8%BD%AC%E6%8D%A2%E5%AF%BC%E8%87%B4%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C%E9%94%99%E8%AF%AF%E5%8F%8A%E7%B4%A2%E5%BC%95%E4%B8%8D%E5%8F%AF%E7%94%A8/"},{"title":"我所读过的书","text":"这里记录一下关于我读过的书籍 2018年 Java JDK 7学习笔记 时间: 2018年1月18日 18:42:27 很久之前看的了。突然想标记一下。初学的话就花2h看一下吧。不太建议看的书 高效程序员的45个习惯：敏捷开发修炼之道 时间：2018年3月9日09:45:14 可能是现在还不是很注重，所以很快就浏览完了。我感觉工作半年内还是不读的好，这本书的价值不大 Mongo基础命令参考 时间：2018年3月18日23:11:02 一本野书，基本上就是熟悉一些Ｍｏｎｇｏｄｂ的命令，可以花１个小时浏览下就完了 JAVA编程思想 时间：2018年4月17日00:26:07 说实话，这本书真的是太长了，有精华的东西，同时也有淘汰的东西。距离上次记录书籍已经有一个月了，等再看的时候详细看一遍吧。 算法图解 时间：2018年5月14日00:41:01 Aditya Bhargava 作品，很不错的一本书，再加上是我非常喜欢的图灵教育出版的书。推荐读，而且讲的很形象。基础算法 人工智能 时间：2018年06月26日20:21:4５ 李开复的作品，对认知又多了一点，反正我是很相信人工智能带给社会的进步，以后必将是高科技与艺术的并存。工业上可以取代，但艺术不能取代。 Redis 入门指南 时间：2018年7月31日22:51:45 李子骅 编著 很好的一本基础书，命令很多。记了一些常用的。 Go语言编程 时间：2018年11月18日20:05:42 作者：许式伟 吕桂华 有点失望，给我的感觉就好像是Java一些所谓的“从入门到精通”一类的书，300页的书，看看目录其实有的人就会选择不看，但我还是看完了。深度也是点到为止，当然这其实是要自己去挖掘的。网络编程的那些其实我感觉就是翻译一些手册，也不是国外的文章。比较偏向于教科书方面的书 数学之美 时间：2018年12月06日09:22:58 作者：吴军 马尔可夫链是如此的熟悉，常见的新闻分类竟然是利用了余弦函数。其实大学阶段的知识真的是基础，比如说自然语言处理其实就可以抽象为比较简单的通信模型和统计学模型。利用一些概率公式然后再加上马尔科夫假设就可以做到机器翻译和语音识别。以及我现阶段最想做的搜索。其实布尔代数在支撑着搜索引擎索引的数学基础，当然要做好每个方向是要掌握本质以及精髓，做起事情来也会如诗般顺滑。 2017年 java解惑 这本书还好吧，反正让你会怀疑你的基础学的不扎实，新手老手都建议看一看，不过快速的看一下就好，花1天时间吧 图解HTTP 很好的一本书，值得一读 Java核心技术+卷1（原书第9版）》 这本书粗略过了，因为看的是pdf，打算再吧第十版看下 代码整洁之道 业界传闻的巴拉巴拉的必读书，同样建议看一看，好的代码格式，好的代码规范，以及注释等，也能体现一个人的水平。以前面试阿里的时候，就被问到代码规范之类的问题。建议多刻意练习。多看点源码，源码的规范就很好。","link":"/2018/10/10/%E6%88%91%E6%89%80%E8%AF%BB%E8%BF%87%E7%9A%84%E4%B9%A6/"},{"title":"反射","text":"反射来自元编程，指通过类型检查变量本身数据结构的方式，只有部分编程语言支持反射。反射是指一类应用，它们能够自描述和自控制。也就是说，这类应用通过采用某种机制来实现对自己行为的描述（self-representation）和监测（examination），并能根据自身行为的状态和结果，调整或修改应用所描述行为的状态和相关的语义。 Go 语言提供了一种机制在运行时更新变量和检查它们的值、调用它们的方法，但是在编译时并不知道这些变量的具体类型，这称为反射机制。 在什么情况下需要反射 不能明确接口调用哪个函数，需要根据传入的参数在运行时决定。 不能明确传入函数的参数类型，需要在运行时处理任意对象。 类型反射构建在类型系统之上，Go是静态类型语言，每一个变量都有静态类型，在编译时就确定下来了。 比如 1234type MyInt intvar i intvar j MyInt i和j的底层类型都是int，但i的静态类型是int，j的静态类型是MyInt，这两个是不同类型，是不能直接赋值的，需要类型强制转换。 动态类型 12345var A interface{} // 静态类型interface{}A = 10 // 静态类型为interface{} 动态为intA = &quot;String&quot; // 静态类型为interface{} 动态为stringvar M *intA = M // A的值可以改变 掌握reflect包的以下函数： reflect.ValueOf({}interface) reflect.Value：获取某个变量的值，但值是通过reflect.Value对象描述的。 reflect.TypeOf({}interface) reflect.Type：获取某个变量的静态类型，但值是通过reflect.Type对象描述的，是可以直接使用Println打印的。 reflect.Value.Kind() Kind：获取变量值的底层类型（类别），注意不是类型，是Int、Float，还是Struct，还是Slice，具体见此。 reflect.Value.Type() reflect.Type：获取变量值的类型，效果等同于reflect.TypeOf。 再解释下Kind和Type的区别 123type MyInt intvar x MyInt = 7v := reflect.ValueOf(x) v.Kind()得到的是Int，而Type得到是MyInt。 反射原理反射的意思是在运行时，能够动态知道给定数据对象的类型和结构，并有机会修改它！现在一个数据对象，如何判断它是什么结构？数据interface中保存有结构数据，只要想办法拿到该数据对应的内存地址，然后把该数据转成interface，通过查看interface中的类型结构，就可以知道该数据的结构了 反射三原则 从interface{}可以反射出反射对象 将 Go 语言的 interface{} 变量转换成反射对象。执行 reflect.ValueOf(1) 时，由于 reflect.TypeOf、reflect.ValueOf 两个方法的入参都是 interface{} 类型，所以在方法执行的过程中发生了类型转换。使用 reflect.TypeOf 和 reflect.ValueOf 能够获取 Go 语言中的变量对应的反射对象。一旦获取了反射对象，我们就能得到跟当前类型相关数据和操作，并可以使用这些运行时获取的结构执行方法。 从反射对象中可以获取到interface{} 既然能够将接口类型的变量转换成反射对象，那么一定需要其他方法将反射对象还原成接口类型的变量，reflect 中的 reflect.Value.Interface 就能完成这项工作：不是所有的变量都需要类型转换这一过程。如果变量本身就是 interface{} 类型的，那么它不需要类型转换，因为类型转换这一过程一般都是隐式的，所以我不太需要关心它，只有在我们需要将反射对象转换回基本类型时才需要显式的转换操作。 要修改反射对象, 其值必须可设置 Go 语言的函数调用都是传值的，所以得到的反射对象跟最开始的变量没有任何关系，那么直接修改反射对象无法改变原始变量，程序为了防止错误就会崩溃。先获取指针对应的 reflect.Value，再通过 reflect.Value.Elem 方法得到可以被设置的变量 interface{}本质上Go提供的一种数据类型, 与其他数据类型不同的是, interface{}会为我们提供变量的类型信息以及变量所在的内存地址。 通过反射修改原对象 原理： 因为给Go的函数、方法传递的都是形参的副本，同样的，反射一个对象时，形参被保存为一个接口对象并作为参数传递（复制），该接口变量是non-settable的，返回的Value也是non-settable的，对它调用Set方法会出现错误； Value的CanSet方法用于测试一个Value的Settablity性质，它有点像unaddressability，但是更加严格，描述的是一个反射对象能够修改创造它的那个实际存储的值的能力。settability由反射对象是否保存原始项而决定。 如果想通过反射来修改对象，必须先把该对象的指针传给reflect.ValueOf(&amp;x)，这样得到的Value对象内部就保存了原对象指针的副本，只有找到该指针指向的值才能修改原始对象，通过Elem()方法就可以获得一个保存了原对象的Value对象，此时的Value对象就是settable的； 对于一个settable的Value反射对象，如 d := reflect.ValueOf(&amp;x).Elem()： d.CanAddr()方法：判断它是否可被取地址 d.CanSet()方法：判断它是否可被取地址并可被修改 通过一个settable的Value反射对象来访问、修改其对应的变量的方式： 方式1：通过把反射对象转换回原对象类型的指针，然后直接修改该指针 px := d.Addr().Interface().(*int) 第一步是调用Addr()方法，它返回一个Value，里面保存了指向变量的指针。 然后是在Value上调用Interface()方法，也就是返回一个interface{}，里面通用包含指向变量的指针。 最后，如果知道变量的类型，可以使用类型的断言机制将得到的interface{}类型的接口强制环为普通的类型指针。这样就可以通过这个普通指针来更新变量了 方式2：可直接通过Set()方法来修改 d.Set(reflect.ValueOf(4)) SetInt、SetUint、SetString和SetFloat等方法：d.SetInt(3)，注意：虽然如SetInt()等方法只要参数变量的底层数据类型是有符号整数就可以工作，但不能是一个引用interface{}类型的reflect.Value 小结：Value反射对象为了修改它们所表示的东西必须要有这些东西的地址 1234567891011121314151617181920package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)func main() { var x float64 = 3.4 p := reflect.ValueOf(&amp;x) // 注意这里：把x地址传进去了！ fmt.Println(p.Type()) //*float64 fmt.Println(p.CanSet()) //false 这里的p只是指针，仍然是non-settable的 v := p.Elem() //此时的v保存了x fmt.Println(v.CanSet()) //true v.SetFloat(7.1) fmt.Println(v.Interface()) //7.1 fmt.Println(x) //7.1} 虽然反射可以越过Go语言的导出规则的限制读取结构体中未导出的成员，但不能修改这些未导出的成员。因为一个struct中只有被导出的字段才是settable的。 1234567891011121314151617181920212223242526272829package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)func main() { type T struct { A int B string } t := T{23, &quot;skidoo&quot;} s := reflect.ValueOf(&amp;t).Elem() typeOfT := s.Type() // 把s.Type()返回的Type对象复制给typeofT，typeofT也是一个反射。 for i := 0; i &lt; s.NumField(); i++ { f := s.Field(i) // 迭代s的各个域，注意每个域仍然是反射。 fmt.Printf(&quot;%d: %s %s = %v\\n&quot;, i, typeOfT.Field(i).Name, f.Type(), f.Interface()) // 提取了每个域的名字 } // 0: A int = 23 // 1: B string = skidoo s.Field(0).SetInt(77) // s.Field(0).Set(reflect.ValueOf(77)) s.Field(1).SetString(&quot;Sunset Strip&quot;) fmt.Println(&quot;t is now&quot;, t) // t is now {77 Sunset Strip}} 如何实现字符串和byte切片的零拷贝123456func string2bytes(s string) []byte { return *(*[]byte)(unsafe.Pointer(&amp;s))}func bytes2string(b []byte) string{ return *(*string)(unsafe.Pointer(&amp;b))} 原理上是利用指针的强转 反射慢的原因 发生堆逃逸 （比如ValueOf函数很简单，先将i主动逃逸到堆上，然后将 i 通过unpackEface函数转换成Value。） 逃逸到堆意味着将值拷贝一份到堆上，这也是反射慢的主要原因。 涉及到内存分配以及后续的GC； reflect实现里面有大量的枚举，也就是for循环，比如类型之类的。 建议 可以只使用reflect.TypeOf的话，就不要使用reflect.ValueOf 可以使用断言代替的话，就不要使用反射 如果有可能应当避免使用反射","link":"/2019/03/11/%E5%8F%8D%E5%B0%84/"},{"title":"构建自己高效的workflow","text":"喜欢去探索各种效率工具，自然离不开alfred。alfred可以完成很多事情，其中包括打开各种app，搜索文件，搜索引擎等太多了。 这篇文章主要是记录 关于 Alfred的workflow的开发 alfred 插件开发概述Workflow 是alfred2.0推出的最激动人心的特性, 通过与脚本语言的交互，workflow可以支持任意操作，把您日常的重复性事务封装在脚本中，大大的提高工作效率。 Workflow 支持php、bash、perl、ruby以及python作为脚本语言，并内置脚本语言解释器，并通过stdio的形式在各个脚本模块中传递参数。 在代码中插入 {query}块可以接收上一个脚本输出的内容。形成完整的控制链条。 最后由alfred输出至 Output 模块， 在Output模块中， 我们可以启动浏览器、将内容复制到剪切板、 启动通知中心、甚至执行bash脚本。在日常的使用中，我们通常通过关键字来调用某一模块，例如“find xxx” 即是调用find内建模块 query内容为xxx。 在workflow的开发中， 开发者可以自定义自己编写模块的关键字，只要不与其他模块冲突即可。在workflow的结构中，数据流通过alfred的控制线进行传递，每一个脚本模块的STDIO输出会被alfred替换到 下一个脚本的{query}块中。 创建一个新的workflow 首先点击workflow 创建一个workflow 然后图里的主要是Bundle Id ，主要就是唯一、description等这些看自己，都是一些无关键要的东西。可以简单对你的脚本进行描述或者是一个良好的命名或者也行了。 创建一个带有输入参数得workflow然后就是选中之前创建的workflow。在右侧选中input，如下图所示。比如我们这里是创建一个关于时间戳转换的脚本，可以选择input里的Script Filter 然后出来以下这个界面，keyword就是唤醒的关键键。 如果这里是Python脚本的话，language这里是要选择/bin/zsh的，然后如果你的脚本是需要输入参数的话。后面要跟上wtih input as {query}，如果你的脚步完全不依赖于外部库的话，也是可以直接在这里写的 然后 Script 这里的话是需要写你运行的脚本的路径 然后打开上图中 问号旁边的文件夹，会看到这样一个文件。接下来要做的事情就是要把python3有关的workflow代码放在这里去。 这里有一个不小的坑，然后网上大部分帖子都是粘贴复制，所以很多都还是n多年前复制过来的，因为原始仓库里只有python2的代码，python3不支持部分库了，所以我是根据 这里的一个仓库，clone下来后，其实只需要workflow里的代码就行。所以最终你会看到这样一个目录 另外附上t.py里的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import requestsimport reimport sysfrom datetime import datetimefrom workflow import Workflow3S = requests.Session()REGEXP_TIMESTAMP = r'^\\d+$'def convert_timestamp_to_datetime(timestamp): try: timestamp = int(timestamp) dt_object = datetime.utcfromtimestamp(timestamp) return dt_object.strftime('%Y-%m-%d %H:%M:%S') except ValueError: return &quot;Invalid timestamp&quot;def generate_feedback_results(judge_code, result): wf = Workflow3() if judge_code == 1: kwargs = { 'title': result, 'subtitle': '', &quot;valid&quot;: True, 'arg': result } else: kwargs = { 'title': result, 'subtitle': '', 'valid': False } wf.add_item(**kwargs) wf.send_feedback()def main(): timestamp = sys.argv[1] if len(re.findall(REGEXP_TIMESTAMP, timestamp)) &gt; 0: result = convert_timestamp_to_datetime(timestamp) generate_feedback_results(1, result) else: generate_feedback_results(0, &quot;Invalid timestamp&quot;)if __name__ == &quot;__main__&quot;: main() 然后效果大概就是这样了 其实类似于这些的话也能在python里通过参数来实现，也就是终端，但是如果是多方的一些东西的话，可能还是借助于该工具比较好 创建一个带有无参数得workflow然后可能也有会有这样的需求，比如根据python处理后的结果，然后需要自动把这个结果比如复制到粘贴板里面去。然后就这样这样做 选择一个outputs，然后再选择copy to clipboard 。 这样输入now的时候，就会自动显示时间戳还能复制到粘贴板里面去了 从debug里的日志也能看出来 debug 模式当然在创建workflow的过程中，还是比较顺畅的，如果要开启debug模式也很简单。 这里就能完美开启了 其他比如在项目中会经常用ide打开某一些开发的应用，也可以一套流程下来。一键启动打开。如果大家有啥好玩的workflow也可以交流交流","link":"/2023/11/05/%E6%88%91%E6%98%AF%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E6%88%91%E7%9A%84%E6%95%88%E7%8E%87%E7%9A%84/"},{"title":"数据删掉一半，表的大小不变","text":"数据库占用空间太大，把一个最大的表删掉了一半的数据，怎么表文件的大小还是没变？ 先来看看这块儿知识 一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。因为表结构定义占用的空间很小 其中有一个参数innodb_file_per_table，它的值有on和off，OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。 比如要删除ID=5的对应的数据(称为R1)，InnoDB 引擎只会把R1这个记录标记为删除。如果之后要再插入一个ID在4和6之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。InnoDB 的数据是按页存储的，如果删除一个数据页上所有的记录，整个数据页就可以被复用了。 数据页的复用跟记录的复用是不同的 记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R1 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。 而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID=50 的记录需要使用新页的时候，page A 是可以被复用的。 如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。 进一步地，如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。 delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。 不止是删除数据会造成空洞，插入数据也会。如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。 比如在乱序的时候插入ID=500的时候，然后就会去申请新的页面page B来保存数据了， 经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。 而重建表，就可以达到这样的目的。 可以使用 alter table A engine=InnoDB 命令来重建表。在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。(如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。) MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。 重建表的流程： 建立一个临时文件，扫描表 A 主键的所有数据页； 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中； 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态； 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态； 用临时文件替换表 A 的数据文件。","link":"/2019/12/17/%E6%95%B0%E6%8D%AE%E5%88%A0%E6%8E%89%E4%B8%80%E5%8D%8A%EF%BC%8C%E8%A1%A8%E7%9A%84%E5%A4%A7%E5%B0%8F%E4%B8%8D%E5%8F%98/"},{"title":"给字符串加索引","text":"MySQL是支持前缀索引的，前缀索引的优势就是占用的空间小，这同时带来的损失是，可能会增加额外的记录扫描次数。 比如一些用户表，登录账户是邮箱 如果要使用的是邮箱登录，所以代码中一定会有这种类似的语句 1select f1, f2 from tableName where email='xxx'; 如果email这个字段上没有索引的话，那这些语句就只能做全表扫描 MySQL 是支持前缀索引的，可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。 比如，这两个在 email 字段上创建索引的语句： 12alter table t add index index1(email);alter table t add index index2(email(6)); 第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串； 而第二个语句创建的 index2 索引里面，对于每个记录都是只取前 6 个字节。 其中email(6)这个索引结构中每个邮箱字段只取前6个字节，占用的空间会比较小，这是使用前缀索引的优势,但是带来的损失可能会增加额外的记录扫描次数 看看下面这个语句 1select id,name,email from SUser where email='zhangssxyz@xxx.com'; 如果使用的是这种索引index1（即 email 整个字符串的索引结构），执行顺序是这样的： 从 index1 索引树找到满足索引值是’zhangssxyz@xxx.com’的这条记录，取得 ID2 的值； 到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集； 取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 email=‘zhangssxyz@xxx.com’的条件了，循环结束。 这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。 如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的： 从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1； 到主键上查到主键值是 ID1 的行，判断出 email 的值不是’zhangssxyz@xxx.com’，这行记录丢弃； 取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集； 重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。 在这个过程中，要回主键索引取 4 次数据，也就是扫描了 4 行。 所以使用前缀索引有可能会使查询语句读数据的次数变多 使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。 如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，这种方法，既可以占用更小的空间，也能达到相同的查询效率。 有以下2中方式 就是使用倒序存储，比如身份证倒序，查询的时候再用函数转一下 以及使用hash字段，在表上创建一个整数字段，来保存身份证的校验码，同时在这个字段上加索引 这两种方式对比区别 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。","link":"/2020/02/11/%E7%BB%99%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8A%A0%E7%B4%A2%E5%BC%95/"},{"title":"由一行代码引发的变量分配思考","text":"整个包都只有一行有效代码，或许是一件值得思考的事情 闲逛GitHub的时候发现 Brad Fitzpatrick的iter包。仔细看了2遍。代码里确实只有一行有效代码 123func N(n int) []struct{} { return make([]struct{}, n)} 刚开始也是一扫而过，然后看了看注释 1It does not cause any allocations. 既然有这么多star还有几乎没提issue，我首先假定了他的注释是对的。立马想到空结构体 struct{} 是不占据空间的，典型的在写代码的时候，会经常这么写来判断某些值是否在之前出现过 1m := make(map[string]struct{}, 0) 以及 空结构体的切片只占用切片头的空间。 但是关于切片的印象是占据24个字节，在64位机器上 123var a []intfmt.Println(unsafe.Sizeof(a))// 这里会打印出来24 所以是否作者写的是错的，为什么说 函数 N 不会引发分配呢？ 为了解决这个疑惑，需要先弄清楚两个问题： 一个 Go 变量可能会被分配在哪里？ 如何确定一个 Go 变量最终会被分配在哪里？ 变量的分配 图片来自 这里 图 6-1 初始化的全局变量或静态变量，会被分配在 Data 段。 未初始化的全局变量或静态变量，会被分配在 BSS 段。 在函数中定义的局部变量，会被分配在堆（Heap 段）或栈（Stack 段）。 实际上，如果考虑到 编译器优化，局部变量还可能会被 分配在寄存器，或者直接被 优化去掉。 Go 内存分配 堆（heap） 由 GC 负责回收。 对应于进程地址空间的堆。 栈（stack） 不涉及 GC 操作。 每个 goroutine 都有自己的栈，初始时被分配在进程地址空间的栈上，扩容时被分配在进程地址空间的堆上。 Go 变量主要分为两种： 全局变量 会被 Go 编译器标记为一些特殊的 符号类型，分配在堆上还是栈上目前尚不清楚，不过不是本文讨论的重点。 局部变量 所以综上，对于在函数中定义的 Go 局部变量：要么被分配在堆上，要么被分配在栈上。 确定 Go 变量最终的分配位置按照官方 FAQ How do I know whether a variable is allocated on the heap or the stack? 的解释： Go 编译器会尽可能将变量分配在栈上 以下两种情况，Go 编译器会将变量分配在堆上 如果一个变量被取地址（has its address taken），并且被逃逸分析（escape analysis）识别为 “逃逸到堆”（escapes to heap） 如果一个变量很大（very large） 逃逸分析1234567package mainimport &quot;github.com/bradfitz/iter&quot;func main() { for range iter.N(4) {}} 12345678910go run -gcflags='-m -m' main.go# command-line-arguments./main.go:5:6: can inline main with cost 7 as: func() { for loop }./main.go:6:18: inlining call to iter.N./main.go:6:18: make([]struct {}, iter.n) escapes to heap:./main.go:6:18: flow: {heap} = &amp;{storage for make([]struct {}, iter.n)}:./main.go:6:18: from make([]struct {}, iter.n) (non-constant size) at ./main.go:6:18./main.go:6:18: make([]struct {}, iter.n) escapes to heap 按照前面的分析，从 “make([]struct {}, iter.n) escapes to heap” 的信息，推断：make([]struct {}, iter.n) 会被分配在堆上。到这里，最初的疑惑似乎已经有了答案：make([]struct {}, iter.n) 一定会引发堆分配，那是 Brad Fitzpatrick 的注释写错了吗？ 内存分配器追踪除了逃逸分析，Go 还提供了一种叫内存分配器追踪（Memory Allocator Trace）的方法，用于细粒度地分析由程序引发的所有堆分配（和释放）操作： 1GODEBUG=allocfreetrace=1 go run main.go 2&gt;&amp;1 | grep -C 10 因为进行内存分配器追踪时，很多由 runtime 引发的分配信息也会被打印出来，所以用 grep 进行过滤，只显示由用户代码（user code）引发的分配信息。然而这里的输出结果为空，表明 make([]struct {}, iter.n) 没有引发任何堆分配。内存分配器追踪的结论与逃逸分析的结论截然相反！那到底哪个结论是对的呢？ 汇编分析黔驴技穷之际，Go’s Memory Allocator - Overview 这篇文章给了提示：So, we know that i is going to be allocated on the heap. But how does the runtime set that up? With the compiler’s help! We can get an idea from reading the generated assembly. 1234567891011go tool compile -N -l -S main.go0x0014 00020 (escape/p10/main.go:8) MOVQ AX, main.n+88(SP)0x0019 00025 (escape/p10/main.go:8) MOVQ $0, main.~r0+24(SP)0x0022 00034 (escape/p10/main.go:8) MOVUPS X15, main.~r0+32(SP)0x0028 00040 (escape/p10/main.go:9) MOVQ main.n+88(SP), CX0x002d 00045 (escape/p10/main.go:9) MOVQ main.n+88(SP), BX0x0032 00050 (escape/p10/main.go:9) LEAQ type:struct {}(SB), AX0x0039 00057 (escape/p10/main.go:9) PCDATA $1, $00x0039 00057 (escape/p10/main.go:9) CALL runtime.makeslice(SB) 可以看到，其中有一处对 runtime.makeslice(SB) 的调用，显然是由 make([]struct{}, n) 引发的。 查看 runtime.makeslice 的源码： 12345func makeslice(et *_type, len, cap int) slice { ... p := mallocgc(et.size*uintptr(cap), et, true) return slice{p, len, cap}} 其中，mallocgc 的源码如下： 1234567891011func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer { ... if size == 0 { return unsafe.Pointer(&amp;zerobase) } ... if debug.allocfreetrace != 0 { tracealloc(x, size, typ) } ...} 结合上述几段源码，可以看出： makeslice 函数中：slice 结构体是 Go 切片 —— array 是指向数组片段的指针，len 是数组片段的长度，cap 是数组片段的最大长度。 makeslice 函数中：array 的值来自 p，而 p 则是一个指针，它指向由 mallocgc 分配得到的底层数组。 mallocgc 函数中：因为空结构体的 size 为 0，所以 mallocgc 并没有实际进行堆分配；由于没有执行到 tracealloc 的地方，所以进行内存分配器追踪时，不会采集到相关的分配信息。 makeslice 函数中：切片 slice 本身是以结构体的形式返回的，所以只会被分配在栈上。 总结经过一系列的探索和分析，至此，可以得出以下结论： make([]struct{}, n) 只会被分配在栈上，而不会被分配在堆上。 Brad Fitzpatrick 的注释是对的，并且他的意思是 “不会引发堆分配”。 逃逸分析识别出 escapes to heap，并不一定就是堆分配，也可能是栈分配。 进行内存分配器追踪时，如果采集不到堆分配信息，那一定只有栈分配。 最后，来解答文章标题提出的疑问 —— 如何确定一个 Go 变量会被分配在哪里？对此： 先对代码作逃逸分析。 如果该变量被识别为 escapes to heap，那么它十有八九是被分配在堆上。 如果该变量被识别为 does not escape，或者没有与之相关的分析结果，那么它一定是被分配在栈上。 如果对 escapes to heap 心存疑惑，就对代码作内存分配器追踪。 如果有采集到与该变量相关的分配信息，那么它一定是被分配在堆上。 否则，该变量一定是被分配在栈上。 此外，如果想知道 Go 编译器是如何将变量分配在堆上或者栈上的，可以去分析 Go 汇编（以及 runtime 源码）。 相关阅读 The empty struct Go Slices: usage and internals Escape analysis Go’s Memory Allocator - Overview Go internals, Chapter 1: Go assembly Five things that make Go fast","link":"/2022/04/05/%E7%94%B1%E4%B8%80%E8%A1%8C%E4%BB%A3%E7%A0%81%E5%BC%95%E5%8F%91%E7%9A%84%E5%8F%98%E9%87%8F%E5%88%86%E9%85%8D%E6%80%9D%E8%80%83/"},{"title":"初识Docker","text":"关于dockerdocker是一款以容器虚拟化技术为基础的软件 那么什么是虚拟化技术 ？ 虚拟化技术是一种将计算机物理资源进行抽象、转换为虚拟的计算机资源提供给程序使用的技术。 因为要配置各种环境等，给开发造成了很多困扰。 虚拟化还有一种作用，就是将虚拟化应用于资源管理。 假想一下，你要装mysql，redis等等，跑起一个服务端就比较费资源，虚拟化就可以很好地解决这件事情。就会有一种效果，那就是1+1&lt;2. 虚拟化技术通过资源隔离的方式，无形地也可以把这些程序隔离在不同的虚拟环境中，既然虚拟环境不同，自然运行在不同环境中的程序就不会互相干扰或争抢资源了。 docker的优势 基于容器技术的Docker拥有很高的跨平台性。Docker 的容器能够很轻松的运行在开发者本地的电脑，数据中心的物理机或虚拟机，云服务商提供的云服务器，甚至是混合环境中。 Docker 的轻量性和高可移植性能够很好的帮助我们完成应用的动态伸缩，我们可以通过一些手段近实时的对基于 Docker 运行的应用进行弹性伸缩，这能够大幅提高应用的健壮性。 不管是交付市场时间， 增加开发生产力，提高开发效率，节约基础设施成本，提升运维效率，以及加速问题解决时间。docker都有一个很好的作用。 关于docker的技术实现 Docker的实现，主要归结于三大技术，命令空间，控制组以及联合文件系统。大家可以更深入的去了解下。说到了Docker，就不得不先说说Docker的体系了。它有四个对象：镜像，容器，网络，数据卷。* 镜像：大概可以理解为一个只读的文件包。其中包含了虚拟环境运行最原始文件系统的内容。镜像是对容器运行环境进行持久化存储的结果。* 容器：容器就是用来隔离虚拟环境的基础设施，而在 Docker 里，它也被引申为隔离出来的虚拟环境。如果把镜像理解为编程中的类，那么容器就可以理解为类的实例。镜像内存放的是不可变化的东西，当以它们为基础的容器启动后，容器内也就成为了一个“活”的空间。 用更官方的定义来讲，Docker容器应该有三项内容组成。 一个Docker镜像 一个程序运行环境 一个指令集合 网络 对于大部分程序来说，它们的运行都不会是孤立的，而是要与外界或者更准确的说是与其他程序进行交互的，这里的交互绝大多数情况下指的就是数据信息的交换。网络通讯是目前最常用的一种程序间的数据交换方式了。 在 Docker 中，实现了强大的网络功能，我们不但能够十分轻松的对每个容器的网络进行配置，还能在容器间建立虚拟网络，将数个容器包裹其中，同时与其他网络环境隔离。 利用一些技术，Docker 能够在容器中营造独立的域名解析环境，这使得我们可以在不修改代码和配置的前提下直接迁移容器，Docker 会为我们完成新环境的网络适配。对于这个功能，我们甚至能够在不同的物理服务器间实现，让处在两台物理机上的两个 Docker 所提供的容器，加入到同一个虚拟网络中，形成完全屏蔽硬件的效果。 数据卷 在以往的虚拟机中，我们通常直接采用虚拟机的文件系统作为应用数据等文件的存储位置。然而这种方式其实并非完全安全的，当虚拟机或者容器出现问题导致文件系统无法使用时，虽然我们可以很快的通过镜像重置文件系统使得应用快速恢复运行，但是之前存放的数据也就消失了。 为了保证数据的独立性，我们通常会单独挂载一个文件系统来存放数据。这种操作在虚拟机中是繁琐的，因为我们不但要搞定挂载在不同宿主机中实现的方法，还要考虑挂载文件系统兼容性，虚拟操作系统配置等问题。值得庆幸的是，这些在 Docker 里都已经为我们轻松的实现了，我们只需要简单的一两个命令或参数，就能完成文件系统目录的挂载。","link":"/2018/05/11/%E5%85%B3%E4%BA%8Edocker/"},{"title":"高阶函数编程技巧","text":"函数是 Go 语言的一等公民，如何利用好其高级用法特性，是一件值得思考和实践的事情 背景在日常业务开发中，对于一些表的不同字段做筛选查询，是基础的功能。而且大部分可能是在根据不同条件去查询。就像这样 123456type XXXRepo interface { GetXXXByIdOrName(ctx context.Context, id int, name string) (o []admin.XXX, err error) GetXXXInfoList(ctx context.Context, req *GetXXXRequest) (total int64, o []admin.XXX, err error) GetXXXInfo(ctx context.Context, columnId, gradeId int) (o []admin.XXX, err error) GetXXXByIdList(ctx context.Context, idList []int) (o []admin.XXX, err error)} 这也还只是少许的一些条件，如果一张表有十多个字段配合查询呢 ？ dao层也会有非常多的冗余代码，可能也就改变了一下入参而已。 假设有一张订单表，简化结构如下 12345678CREATE TABLE `order` ( `id` bigint unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键', `order_id` bigint NOT NULL COMMENT '订单id', `shop_id` varchar NOT NULL COMMENT '店铺id', `product_id` int NOT NULL DEFAULT '0' COMMENT '商品id', `status` int NOT NULL DEFAULT '0' COMMENT '状态', PRIMARY KEY (`id`),) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='订单表'; 举例说明用以下这些字段的不同组合来查询 1order_id, shop_id, produce_id,status 会在dao层来编写类似于这样的代码 根据orderId来查询 12345678func GetOrderInfoByOrderId(ctx context.Context, orderId int64) ([]*resource.Order) { db := GetDB(ctx) db = db.Table(resource.Order{}.TableName()) var infos []*resource.Order db = db.Where(&quot;order_id = ?&quot;, orderId) db.Find(&amp;infos) return infos} 根据shopId来查询 12345678func GetOrderInfoByShopId(ctx context.Context, shopId int64) ([]*resource.Order) { db := GetDB(ctx) db = db.Table(resource.Order{}.TableName()) var infos []*resource.Order db = db.Where(&quot;shop_id = ?&quot;, shopId) db.Find(&amp;infos) return infos} 可以看到，两个方法的代码极度相似，除了入参和命名不一样，如果再需要按照 produce_id 或者 status 查询，那需要再写几个类似的方法，导致相似的方法非常多。当然很容易想到，如果参数是传多个，传多个不就好了，可能就是这样的写法 12345678func GetOrderInfo(ctx context.Context,orderId, shopId int64) ([]*resource.Order) { db := GetDB(ctx) db = db.Table(resource.Order{}.TableName()) var infos []*resource.Order db = db.Where(&quot;shop_id = ? and order_id = ?&quot;, shopId,orderId) db.Find(&amp;infos) return infos} 如果什么时候业务有变化，需要改条件。也许就会变为这样 12345678910111213func GetOrderInfo(ctx context.Context,orderId, shopId int64) ([]*resource.Order) { db := GetDB(ctx) db = db.Table(resource.Order{}.TableName()) var infos []*resource.Order if orderId != 0 { db = db.Where(&quot;order_id = ?&quot;,orderId) } if shopId != 0 { db = db.Where(&quot;shop_id = ?&quot;,shopId) } db.Find(&amp;infos) return infos} 调用方的代码大概是这样的 12345// 根据shopId 查询infos := GetOrderInfo(ctx, 0, 1)// 根据orderId 查询infos := GetOrderInfo(ctx, 1, 0) 相当于其他不关心的查询字段用对应类型默认的零值来替换了。 当然也可以用结构体来作为一个参数 123456func GetOrderInfo(ctx context.Context,order Order) ([]*resource.Order) { db := GetDB(ctx) db = db.Table(resource.Order{}.TableName()) db.Where(&amp;order).find(&amp;infos) return infos} 但是估计有的人遇到过这样的坑，那就是如果当字段是int,int64等，有0时，不清楚到底是传入了0，还是没有传值，是区分不了的。因为go语言默认的类型零值。如果是类型的0值也想作为参数来查询，则默认是忽略的，可以参考 gorm 官方有这样一句话 1NOTE When querying with struct, GORM will only query with non-zero fields, that means if your field’s value is 0, '', false or other zero values, it won’t be used to build query conditions, for example: 针对这种情况可以选择转化为map或者像以下这种方式来判断 123456789101112131415func GetOrderInfoInfo(ctx context.Context, o Order) ([]*resource.Order) { db := GetDB(ctx) db = db.Table(resource.Order{}.TableName()) var infos []*resource.Order if o.orderId &gt; 0 { db = db.Where(&quot;order_id = ?&quot;, o.orderId) } if o.shopId != &quot;&quot; { db = db.Where(&quot;shop_id = ?&quot;, o.shop_id) } // 后面就先省略了 if xxxx db.Find(&amp;infos) return infos} 这里还只是简短几个字段，如果是十几个字段来组合查询，则要写非常多if判断。 基于以上这种所有情况，有必要来优化一下 可以利用函数式编程来优化 定义如下 1type Option func(*gorm.DB) 定义 Option 是一个函数，这个函数的入参类型是*gorm.DB，返回值为空。 然后针对 表中需要筛选查询的字段定义一个函数，赋值 123456789101112func OrderID(orderID int64) Option { return func(db *gorm.DB) { db.Where(&quot;`order_id` = ?&quot;, userID) }}func ShopID(shopID int64) Option { return func(db *gorm.DB) { db.Where(&quot;`shop_id` = ?&quot;, shopID) }} 所以需要为可能得字段来创建不同的函数，返回一个Option函数，该函数是把入参赋值给【db *gorm.DB】对象 所以基于以上，要改写dao层就很方便了。 12345678910func GetOrderInfo(ctx context.Context, options ...func(option *gorm.DB)) ([]*resource.OrderInfo) { db := GetDB(ctx) db = db.Table(resource.OrderInfo{}.TableName()) for _, option := range options { option(db) } var infos []*resource.OrderInfo db.Find(&amp;infos) return infos} 这样底层的逻辑就不用写很多if判断了，用 for循环来代替 调用者知道自己需要根据什么参数来查询，则就用上面写好的参数函数来作为入参 12345// orderID 查询infos := GetOrderInfo(ctx, OrderID(orderID))// orderID，shopID 组合查询infos := GetOrderInfo(ctx, OrderID(orderID), ShopID(shopID)) 当然还根据其他 in 等条件查询，再写一个函数即可 经过优化之后，简化了逻辑。相当于配置类的Option就生成了，代码优雅了不少。这里只提到了查询，更新也是类似的道理，删除和写入就没太大必要这样了。 参考Self-referential functions and the design of options Using functional options instead of method chaining in Go","link":"/2023/05/05/%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/"},{"title":"python钉钉机器人自定义回复","text":"大概有这样的需求 达到xxx条件。比如是到了某个时刻。机器人自动在群里通知，并@相关的人 比如在群里回复一个关键词、然后期望得到想要的信息，以达到解放双手的目的。这一块儿就需要自己对接钉钉API来实现了。比如这种问答式的 明白这样的需求后就去 官网 找文档去了。 其实官网文档说的很清楚了。没啥需要补充的。 分析 需要部署到服务器 除了定时还需要自定义回复 不需要性能太高，简单便捷就好。所以在go和Python之间选择了Python 使用Flash启动 主要逻辑代码 12345678910111213from flask import Flask # http://flask.pocoo.org/docs/0.12/api/#flask.Flaskapp = Flask(__name__) @app.route('/HelloWorld')def hello_world(): return &quot;Hello World!&quot; if __name__ == &quot;__main__&quot;: # http://flask.pocoo.org/docs/0.12/quickstart/#a-minimal-application app.run(host='0.0.0.0', port='5000') 用python开启flask web服务时， 你只需要本机访问，那ip只要不设置为0.0.0.0就可以，正常访问就好 如果你需要外网访问，ip需要设置为0.0.0.0，此时，在本机上访问需要使用默认的127.0.0.1（也就是你不设置ip时默认的ip）,在外网上访问则需要使用你本机的ip，不要使用0.0.0.0 也可以这样的方式来启动 123456789if __name__ == &quot;__main__&quot;: server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) server_socket.bind((&quot;&quot;, 8083)) server_socket.listen(120) while True: client_socket, client_address = server_socket.accept() handle_client_process = Process(target=handle_client, args=(client_socket,)) handle_client_process.start() client_socket.close() 然后去实现handle_client 就好了。篇幅有限。完整的代码关注公众号 罗尔街 即可获取 架构图 流程 用户通过django admin来添加消息配置，即关键字与回复内容。 用户通过钉钉企业内部群中@机器人 + 关键字。 企业机器人收到后，由socket监听服务接收，并根据消息类型进行处理后返回。 企业机器人收到返回的消息后，通过内网穿透工具给的外网映射地址进行回复。 企业内部群显示回复的消息，用户看见回复的消息。 实践 针对定时、或者达到xxx条件触发的，在智能群助手里面添加机器人就好了 选择 自定义机器人 然后配置其中一种安全方式即可 得到webhook地址。 也可以先构建一个curl来测试一下 123curl 'https://oapi.dingtalk.com/robot/send?access_token=381c2f405e0f906fd556b27cea9f66864120860b5d8b117bb046e10b6599b050&amp;timestamp=1613211530113&amp;secret=SEC2e67120c5e4affa1177ac25fe8dc77ba1c5b49284a9dc7e1888770bc3b76b1fc' \\ -H 'Content-Type: application/json' \\ -d '{&quot;msgtype&quot;: &quot;text&quot;,&quot;text&quot;: {&quot;content&quot;: &quot;test&quot;}}' 主要逻辑代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import base64import hashlibimport hmacimport jsonimport timeimport urllibimport urllib.parseimport requestsdef sign(): timestamp = str(round(time.time() * 1000)) secret = &quot;SECe5d17dac6060b76c01ea60aec260fe76c6e0644394b932bfffa963342bb630a1&quot; secret_enc = secret.encode('utf-8') string_to_sign = '{}\\n{}'.format(timestamp, secret) string_to_sign_enc = string_to_sign.encode('utf-8') hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest() sign_res = urllib.parse.quote_plus(base64.b64encode(hmac_code)) return timestamp, sign_resdef send_ding_message(text_info): webhook = &quot;https://oapi.dingtalk.com/robot/send?access_token=f069339ad1fcb9410d0e96fd947d9a2bf3416451d01dc97e3ef4256c1fdb2b7a&quot; header = { &quot;Content-Type&quot;: &quot;application/json&quot;, &quot;Charset&quot;: &quot;UTF-8&quot; } text = text_info message = { &quot;msgtype&quot;: &quot;text&quot;, &quot;text&quot;: { &quot;content&quot;: text }, &quot;at&quot;: { # &quot;isAtAll&quot;: False # &quot;atMobiles&quot;: [ # &quot;18512345678&quot; # ] &quot;atUserIds&quot;: [ &quot;lbkgv8q&quot; ] } } message_json = json.dumps(message) timestamp, sign_res = sign() webhook += &quot;&amp;timestamp=&quot; + timestamp + &quot;&amp;sign=&quot; + sign_res info = requests.post(url=webhook, data=message_json, headers=header)def usage(): send_ding_message('test 1')if __name__ == &quot;__main__&quot;: usage() 效果 针对自定义回复消息的官方链接 按照链接先添加就好了 既然是需要钉钉回调我们服务的 ，所以要校验token、sign的合法性 1234timestamp = request.headers.get('Timestamp')sign = request.headers.get('Sign')if sign(timestamp) == sign: 生成规则，官方给了示例 123456789def sign(): timestamp = str(round(time.time() * 1000)) secret = &quot;SECe5d17dac6060b76c01ea60aec260fe76c6e0644394b932bfffa963342bb630a1&quot; secret_enc = secret.encode('utf-8') string_to_sign = '{}\\n{}'.format(timestamp, secret) string_to_sign_enc = string_to_sign.encode('utf-8') hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest() sign_res = urllib.parse.quote_plus(base64.b64encode(hmac_code)) return timestamp, sign_res 当然也可以用ip段来做安全的校验 如果是企业内部网络、并非是公网，则需要用内网穿透。官方也给了示例，这里就不再重复了。 一些可能会遇到的坑 在使用Python的Flask时、报错 “POST / HTTP/1.1” 405 - 可能是没有允许请求本身的方法 解决方法: 添加method @app.route(‘/‘, methods=[‘GET’, ‘POST’]) 钉钉机器人的webhook是固定的、如果是多个群想用同一个机器人、则需要用app_secret来解决","link":"/2019/07/11/%E9%92%89%E9%92%89%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9B%9E%E5%A4%8D/"}],"tags":[{"name":"杂谈","slug":"杂谈","link":"/tags/%E6%9D%82%E8%B0%88/"},{"name":"go","slug":"go","link":"/tags/go/"},{"name":"context","slug":"context","link":"/tags/context/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"字符串","slug":"字符串","link":"/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"golang","slug":"golang","link":"/tags/golang/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/tags/elasticsearch/"},{"name":"kafka","slug":"kafka","link":"/tags/kafka/"},{"name":"vim","slug":"vim","link":"/tags/vim/"},{"name":"跨域","slug":"跨域","link":"/tags/%E8%B7%A8%E5%9F%9F/"},{"name":"iframe","slug":"iframe","link":"/tags/iframe/"},{"name":"内存对齐","slug":"内存对齐","link":"/tags/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/"},{"name":"订单号","slug":"订单号","link":"/tags/%E8%AE%A2%E5%8D%95%E5%8F%B7/"},{"name":"规则","slug":"规则","link":"/tags/%E8%A7%84%E5%88%99/"},{"name":"读书","slug":"读书","link":"/tags/%E8%AF%BB%E4%B9%A6/"},{"name":"个人","slug":"个人","link":"/tags/%E4%B8%AA%E4%BA%BA/"},{"name":"索引","slug":"索引","link":"/tags/%E7%B4%A2%E5%BC%95/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Python","slug":"Python","link":"/tags/Python/"}],"categories":[{"name":"杂谈","slug":"杂谈","link":"/categories/%E6%9D%82%E8%B0%88/"},{"name":"panic","slug":"panic","link":"/categories/panic/"},{"name":"golang","slug":"golang","link":"/categories/golang/"},{"name":"MySQL","slug":"MySQL","link":"/categories/MySQL/"},{"name":"gin","slug":"gin","link":"/categories/gin/"},{"name":"string","slug":"string","link":"/categories/string/"},{"name":"内存逃逸","slug":"内存逃逸","link":"/categories/%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/"},{"name":"map","slug":"map","link":"/categories/map/"},{"name":"kafka","slug":"kafka","link":"/categories/kafka/"},{"name":"规范","slug":"规范","link":"/categories/%E8%A7%84%E8%8C%83/"},{"name":"vim","slug":"vim","link":"/categories/vim/"},{"name":"反射","slug":"反射","link":"/categories/%E5%8F%8D%E5%B0%84/"},{"name":"效率","slug":"效率","link":"/categories/%E6%95%88%E7%8E%87/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"函数","slug":"函数","link":"/categories/%E5%87%BD%E6%95%B0/"},{"name":"Python","slug":"Python","link":"/categories/Python/"}],"pages":[]}